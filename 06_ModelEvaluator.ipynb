{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from misc.visualizer import *\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "from data.data_loader import Dataset\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.run_configuration import get_default_params, OutputLayerType, LearningSchedulerType, OptimizerType, hyperOpt_goodParams, default_params\n",
    "from misc import utils\n",
    "\n",
    "from optimizer import get_optimizer\n",
    "from criterion import NllLoss, LossCombiner\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.jointAspectTagger import JointAspectTagger\n",
    "from trainer.train import Trainer\n",
    "import pprint\n",
    "from data.germeval2017 import germeval2017_dataset as dsl\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "import torchtext\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(dataset, rc, experiment_name):\n",
    "    loss = LossCombiner(4, dataset.class_weights, NllLoss)\n",
    "    transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                     hyperparameters=rc)\n",
    "    model = JointAspectTagger(transformer, rc, 4, 20, dataset.target_names)\n",
    "    optimizer = get_optimizer(model, rc)\n",
    "    trainer = Trainer(\n",
    "                        model,\n",
    "                        loss,\n",
    "                        optimizer,\n",
    "                        rc,\n",
    "                        dataset,\n",
    "                        experiment_name,\n",
    "                        enable_tensorboard=False,\n",
    "                        verbose=False)\n",
    "    return trainer\n",
    "\n",
    "def load_dataset(rc, logger, task):\n",
    "    dataset = Dataset(\n",
    "        task,\n",
    "        logger,\n",
    "        rc,\n",
    "        source_index=PREFERENCES.source_index,\n",
    "        target_vocab_index=PREFERENCES.target_vocab_index,\n",
    "        data_path=PREFERENCES.data_root,\n",
    "        train_file=PREFERENCES.data_train,\n",
    "        valid_file=PREFERENCES.data_validation,\n",
    "        test_file=PREFERENCES.data_test,\n",
    "        file_format=PREFERENCES.file_format,\n",
    "        init_token=None,\n",
    "        eos_token=None\n",
    "    )\n",
    "    dataset.load_data(dsl, verbose=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/data/germeval2017',\n",
    "    data_train='train_v1.4.tsv',    \n",
    "    data_validation='dev_v1.4.tsv',\n",
    "    data_test='test_TIMESTAMP1.tsv',\n",
    "    source_index=0,\n",
    "    target_vocab_index=2,\n",
    "    file_format='csv'\n",
    ")\n",
    "main_experiment_name = 'GermEval7_Experiments'\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'att_d_k': 300,\n",
      "  'att_d_v': 300,\n",
      "  'batch_size': 12,\n",
      "  'clip_comments_to': 113,\n",
      "  'dropout_rate': 0.302424,\n",
      "  'early_stopping': 5,\n",
      "  'embedding_dim': 300,\n",
      "  'embedding_name': '6B',\n",
      "  'embedding_type': 'fasttext',\n",
      "  'harmonize_bahn': True,\n",
      "  'language': 'de',\n",
      "  'learning_rate_scheduler': { 'noam_learning_rate_factor': 1.418,\n",
      "                               'noam_learning_rate_warmup': 8000},\n",
      "  'learning_rate_scheduler_type': <LearningSchedulerType.Noam: 1>,\n",
      "  'log_every_xth_iteration': -1,\n",
      "  'model_size': 300,\n",
      "  'num_encoder_blocks': 2,\n",
      "  'num_epochs': 25,\n",
      "  'num_heads': 1,\n",
      "  'optimizer': { 'adam_beta1': 0.81,\n",
      "                 'adam_beta2': 0.7173,\n",
      "                 'adam_eps': 0.000814,\n",
      "                 'learning_rate': 7.2e-05},\n",
      "  'optimizer_type': <OptimizerType.Adam: 1>,\n",
      "  'organic_text_cleaning': False,\n",
      "  'output_dropout_rate': 0.79602089766246,\n",
      "  'output_layer': { 'output_conv_kernel_size': 5,\n",
      "                    'output_conv_num_filters': 300,\n",
      "                    'output_conv_padding': 0,\n",
      "                    'output_conv_stride': 1},\n",
      "  'output_layer_type': <OutputLayerType.LinearSum: 1>,\n",
      "  'pointwise_layer_size': 405,\n",
      "  'task': 'absa',\n",
      "  'use_stop_words': True}\n",
      "Current commit: b'08f808a'\n"
     ]
    }
   ],
   "source": [
    "baseline = {**default_params, **hyperOpt_goodParams}\n",
    "print(pprint.pformat(baseline, indent=2))\n",
    "utils.get_current_git_commit()\n",
    "print('Current commit: ' + utils.get_current_git_commit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\GermEval7_Experiments\\20190411\\1\n"
     ]
    }
   ],
   "source": [
    "experiment_name = utils.create_loggers(experiment_name=main_experiment_name)\n",
    "logger = logging.getLogger(__name__)\n",
    "dataset_logger = logging.getLogger('data_loader')\n",
    "rc = get_default_params(use_cuda=True, overwrite={}, from_default=baseline)\n",
    "\n",
    "dataset = load_dataset(rc, dataset_logger, rc.task)\n",
    "logger.debug('dataset loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0947688b67d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Load model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\\\Users\\\\felix\\\\OneDrive\\\\Studium\\\\Studium\\\\6. Semester\\\\MA\\\\Project\\\\ABSA-Transformer\\\\logs\\\\GermEval7_Experiments\\\\20190401\\\\0\\\\checkpoints'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_final_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_test_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "logger.debug('Load model')\n",
    "trainer.load_model(custom_path='C:\\\\Users\\\\felix\\\\OneDrive\\\\Studium\\\\Studium\\\\6. Semester\\\\MA\\\\Project\\\\ABSA-Transformer\\\\logs\\\\GermEval7_Experiments\\\\20190401\\\\0\\\\checkpoints')\n",
    "trainer.set_cuda(True)\n",
    "result = trainer.perform_final_evaluation(use_test_set=True, verbose=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_test_gold_labels(iterator: torchtext.data.Iterator, dataset: Dataset, filename='evaluation_output.xml'):\n",
    "\n",
    "    fields = dataset.fields\n",
    "    with torch.no_grad():\n",
    "        iterator.init_epoch()\n",
    "        \n",
    "        tree = ET.ElementTree()\n",
    "        root = ET.Element('Documents')\n",
    "\n",
    "        for batch in iterator:\n",
    "            doc_id, comment, relevance, aspect_sentiment, general_sentiment = batch.id, batch.comments, batch.relevance, batch.aspect_sentiments, batch.general_sentiments\n",
    "            doc_id = fields['id'].reverse(doc_id.unsqueeze(1))\n",
    "            comment = fields['comments'].reverse(comment)\n",
    "            relevance = ['false' if r == 0 else 'true' for r in relevance]\n",
    "            general_sentiment = fields['general_sentiments'].reverse(general_sentiment.unsqueeze(1))\n",
    "            aspect_sentiment = fields['aspect_sentiments'].reverse(aspect_sentiment, detokenize=False)\n",
    "\n",
    "            for i in range(len(doc_id)):\n",
    "                docuement_elem = ET.SubElement(root, 'Document', {'id': doc_id[i]})\n",
    "\n",
    "                rel_field = ET.SubElement(docuement_elem, 'relevance')\n",
    "                rel_field.text = relevance[i]\n",
    "\n",
    "                sen_field = ET.SubElement(docuement_elem, 'sentiment')\n",
    "                sen_field.text = general_sentiment[i]\n",
    "\n",
    "                text_field = ET.SubElement(docuement_elem, 'text')\n",
    "                text_field.text = comment[i]\n",
    "\n",
    "                # don't add aspects if field not relevant\n",
    "                if relevance[i] == 'false':\n",
    "                    continue\n",
    "                options_elem = ET.SubElement(docuement_elem, 'Opinions')\n",
    "\n",
    "                # add aspects\n",
    "                for sentiment, a_name in zip(aspect_sentiment[i], dataset.target_names):\n",
    "                    if sentiment == 'n/a':\n",
    "                        continue\n",
    "\n",
    "                    asp_field = ET.SubElement(options_elem, 'Opinion', {\n",
    "                        'category': a_name,\n",
    "                        'polarity': sentiment\n",
    "                    })\n",
    "\n",
    "        #print(BeautifulSoup(ET.tostring(tree), \"xml\").prettify())\n",
    "        tree._setroot(root)\n",
    "        tree.write(filename, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "produce_test_gold_labels(dataset.test_iter, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
