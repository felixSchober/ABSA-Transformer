{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\misc\\run_configuration.py:406: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(config.model_size % config.n_heads == 0, f'number of heads {config.n_heads} is not a valid number of heads for model size {config.model_size}.')\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, STATUS_FAIL, Trials, base\n",
    "from hyperopt.plotting import *\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "from data.data_loader import Dataset\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.run_configuration import from_hyperopt, OutputLayerType, LearningSchedulerType, OptimizerType\n",
    "from misc import utils\n",
    "from misc.hyperopt_space import *\n",
    "\n",
    "from optimizer import get_optimizer\n",
    "from criterion import NllLoss, LossCombiner\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.jointAspectTagger import JointAspectTagger\n",
    "from trainer.train import Trainer\n",
    "import pprint\n",
    "from data.organic2019 import organic_dataset as dsl\n",
    "from data.organic2019 import ORGANIC_TASK_ALL, ORGANIC_TASK_ENTITIES, ORGANIC_TASK_ATTRIBUTES, ORGANIC_TASK_ENTITIES_COMBINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Functions\n",
    "\n",
    "These functions will load the dataset and the model. The run configuration will determine the architecture and hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(dataset, rc, experiment_name):\n",
    "    loss = LossCombiner(4, dataset.class_weights, NllLoss)\n",
    "    transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                     hyperparameters=rc)\n",
    "    model = JointAspectTagger(transformer, rc, 4, 20, dataset.target_names)\n",
    "    optimizer = get_optimizer(model, rc)\n",
    "    trainer = Trainer(\n",
    "                        model,\n",
    "                        loss,\n",
    "                        optimizer,\n",
    "                        rc,\n",
    "                        dataset,\n",
    "                        experiment_name,\n",
    "                        enable_tensorboard=False,\n",
    "                        verbose=False)\n",
    "    return trainer\n",
    "\n",
    "def load_dataset(rc, logger, task):\n",
    "    dataset = Dataset(\n",
    "        task,\n",
    "        logger,\n",
    "        rc,\n",
    "        source_index=0,\n",
    "        target_vocab_index=1,\n",
    "        data_path=PREFERENCES.data_root,\n",
    "        train_file=PREFERENCES.data_train,\n",
    "        valid_file=PREFERENCES.data_validation,\n",
    "        test_file=PREFERENCES.data_test,\n",
    "        file_format='.tsv',\n",
    "        init_token=None,\n",
    "        eos_token=None\n",
    "    )\n",
    "    dataset.load_data(dsl, verbose=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble - Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190331\\0\n"
     ]
    }
   ],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/data/organic2019',\n",
    "    data_train='train.csv',    \n",
    "    data_validation='validation.csv',\n",
    "    data_test='test.csv',\n",
    "    early_stopping='highest_5_F1'\n",
    ")\n",
    "main_experiment_name = 'Organic_HyperOpt'\n",
    "use_cuda = True\n",
    "\n",
    "# get general logger just for search\n",
    "experiment_name = utils.create_loggers(experiment_name=main_experiment_name)\n",
    "logger = logging.getLogger(__name__)\n",
    "dataset_logger = logging.getLogger('data_loader')\n",
    "logger.info('Run hyper parameter random grid search for experiment with name ' + main_experiment_name)\n",
    "\n",
    "num_optim_iterations = 100\n",
    "logger.info('num_optim_iterations: ' + str(num_optim_iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current commit: b'90a21c6'\n"
     ]
    }
   ],
   "source": [
    "utils.get_current_git_commit()\n",
    "logger.info('Current commit: ' + utils.get_current_git_commit())\n",
    "print('Current commit: ' + utils.get_current_git_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Spaces\n",
    "\n",
    "- BatchSize:\n",
    "    How big should each batch be?\n",
    "- Num Encoder Blocks\n",
    "    How many encoder blocks should be replicated?\n",
    "    AYNIA: 2-8\n",
    "    \n",
    "- Pointwise Layer Size\n",
    "    How big should the layer between attention heads be?\n",
    "    AYNIA: 1024 - 4096\n",
    "    This: 64 - 2048\n",
    "    \n",
    "    64: Prev. Experiments have shown that a smaller size can be beneficial because a smaller layer contains less parameters.\n",
    "    2048: This model has about a third of the AYNIA model size (1000 vs. 300). Going to big, therefore doesn't make much sense.\n",
    "\n",
    "- Clip Comments to \n",
    "    How long should comments be\n",
    "    This: 30 - 500\n",
    "    \n",
    "- Initial Learning Rate\n",
    "    What is the initial learning rate\n",
    "- Optimizer:\n",
    "    - Noam:\n",
    "        (FROM: https://github.com/tensorflow/tensor2tensor/issues/280#issuecomment-359477755)\n",
    "        decreasing the learning rate aka learning rate decay (usually exponential, piecewise-constant or inverse-time) is a standard practice in ML for decades. Increasing the learning rate in the early stages with a warmup (usually linear or exponential growth) is a more recent practice, popular esp. in deep learning on ImageNet, see e.g. He et al. 2016 or Goyal et al. 2017.\n",
    "        The \"noam\" scheme is just a particular way how to put the warmup and decay together (linear warmup for a given number of steps followed by exponential decay).\n",
    "\n",
    "        Learning rate schedules is an active research area. See e.g. papers on cyclical learning rate (corresponding to learning_rate_decay_scheme=cosine available in tensor2tensor) and super-convergence, which provide also more insights into the theory behind the learning rate, batch size, gradient noise etc.\n",
    "    \n",
    "        - learning rate factor\n",
    "        - learning rate warmup (steps)\n",
    "            AYNIA: 4000\n",
    "            THIS: 100 - 8000\n",
    "    - Adam:\n",
    "        - Beta 1\n",
    "            AYNIA: 0.9\n",
    "\n",
    "        - Beta 2\n",
    "            AYNIA: 0.98\n",
    "\n",
    "\n",
    "    - ?\n",
    "- Transformer Dropout Rate\n",
    "    Dropout rate for the transformer layers.\n",
    "    AYNIA: 0.1\n",
    "    THIS: 0.1 - 0.8\n",
    "- Number of Transformer Heads\n",
    "    How many attention heads should be used:\n",
    "    AYNIA: 8\n",
    "    THIS: [1, 2, 3, 4, 5, 6, 10, 12, 15, 20] (Have to be divide 300)\n",
    "    \n",
    "- Last Layer Dropout Rate\n",
    "    Dropout rate right before the last layer\n",
    "    AYNIA: -\n",
    "    This 0.0 - 0.8\n",
    "- Last Layer Types\n",
    "    - Sum\n",
    "    - Convolutions:\n",
    "        - num conv filters\n",
    "        - kernel size\n",
    "        - stride\n",
    "        - padding\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#search_space = hp\n",
    "search_space = {\n",
    "    'batch_size': hp.quniform('batch_size', 10, 64, 1),\n",
    "    'num_encoder_blocks': hp.quniform('num_encoder_blocks', 1, 4, 1),\n",
    "    'pointwise_layer_size': hp.quniform('pointwise_layer_size', 32, 350, 1),\n",
    "    'clip_comments_to': hp.quniform('clip_comments_to', 45, 180, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.8),\n",
    "    'output_dropout_rate': hp.uniform('last_layer_dropout', 0.0, 0.8),\n",
    "    'num_heads': hp.choice('num_heads', [1, 2, 3, 4, 5]),\n",
    "    'transformer_use_bias': hp_bool('transformer_use_bias'),\n",
    "    'output_layer': hp.choice('output_layer', [\n",
    "        {\n",
    "            'type': OutputLayerType.Convolutions,\n",
    "            'output_conv_num_filters': hp.quniform('output_conv_num_filters', 10, 400, 1),\n",
    "            'output_conv_kernel_size': hp.quniform('output_conv_kernel_size', 1, 10, 1),\n",
    "            'output_conv_stride': hp.quniform('output_conv_stride', 1, 10, 1),\n",
    "            'output_conv_padding': hp.quniform('output_conv_padding', 0, 5, 1),\n",
    "        },\n",
    "        {\n",
    "            'type': OutputLayerType.LinearSum\n",
    "        }\n",
    "    ]),\n",
    "    'learning_rate_scheduler': hp.choice('learning_rate_scheduler', [\n",
    "        {\n",
    "            'type': LearningSchedulerType.Noam,\n",
    "            'noam_learning_rate_warmup': hp.quniform('noam_learning_rate_warmup', 1000, 9000, 1),\n",
    "            'noam_learning_rate_factor': hp.uniform('noam_learning_rate_factor', 0.01, 4)\n",
    "        }\n",
    "    ]),\n",
    "    'optimizer': hp.choice('optimizer', [\n",
    "        {\n",
    "            'type': OptimizerType.Adam,\n",
    "            'adam_beta1': hp.uniform('adam_beta1', 0.7, 0.999),\n",
    "            'adam_beta2': hp.uniform('adam_beta2', 0.7, 0.999),\n",
    "            'adam_eps': hp.loguniform('adam_eps', np.log(1e-10), np.log(1)),\n",
    "            'learning_rate': hp.lognormal('adam_learning_rate', np.log(0.01), np.log(10)),\n",
    "            'adam_weight_decay': 1*10**hp.quniform('adam_weight_decay', -8, -3, 1)\n",
    "        },\n",
    "        #{\n",
    "        #    'type': OptimizerType.SGD,\n",
    "        #    'sgd_momentum': hp.uniform('sgd_momentum', 0.4, 1),\n",
    "        #    'sgd_weight_decay': hp.loguniform('sgd_weight_decay', np.log(1e-4), np.log(1)),\n",
    "        #    'sgd_nesterov': hp_bool('sgd_nesterov'),\n",
    "        #    'learning_rate': hp.lognormal('sgd_learning_rate', np.log(0.01), np.log(10))\n",
    "    ]),\n",
    "    'task': hp.choice('task', [\n",
    "        ORGANIC_TASK_ENTITIES,\n",
    "        ORGANIC_TASK_ENTITIES_COMBINE\n",
    "    ]),\n",
    "    'use_spell_checker': hp_bool('use_spell_checker'),\n",
    "    'embedding_type': hp.choice('embedding_type', ['fasttext', 'glove'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(parameters):\n",
    "    run_time = time.time()\n",
    "    \n",
    "    utils.reset_loggers()\n",
    "    experiment_name = utils.create_loggers(experiment_name=main_experiment_name)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    dataset_logger = logging.getLogger('data_loader')\n",
    "\n",
    "    # generate hp's from parameters\n",
    "    try:\n",
    "        rc = from_hyperopt(parameters, use_cuda, model_size=300, early_stopping=5, num_epochs=35, log_every_xth_iteration=-1, language='en')\n",
    "    except Exception as err:\n",
    "        print('Could not convert params: ' + str(err))\n",
    "        logger.exception(\"Could not load parameters from hyperopt configuration: \" + parameters)\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "    logger.info('New Params:')\n",
    "    logger.info(rc)\n",
    "    print('\\n\\n#########################################################################')\n",
    "    print(rc)\n",
    "\n",
    "    logger.debug('Load dataset')\n",
    "    try:\n",
    "        dataset = load_dataset(rc, dataset_logger, rc.task)\n",
    "    except Exception as err:\n",
    "        print('Could not load dataset: ' + str(err))\n",
    "        logger.exception(\"Could not load dataset\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "    logger.debug('dataset loaded')\n",
    "    logger.debug('Load model')\n",
    "\n",
    "    try:\n",
    "        trainer = load_model(dataset, rc, experiment_name)\n",
    "    except Exception as err:\n",
    "        print('Could not load model: ' + str(err))\n",
    "        logger.exception(\"Could not load model\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "\n",
    "    logger.debug('model loaded')\n",
    "\n",
    "    logger.debug('Begin training')\n",
    "    model = None\n",
    "    try:\n",
    "        result = trainer.train(use_cuda=rc.use_cuda, perform_evaluation=False)\n",
    "        model = result['model']\n",
    "    except Exception as err:\n",
    "        print('Exception while training: ' + str(err))\n",
    "        logger.exception(\"Could not complete iteration\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "\n",
    "    if math.isnan(trainer.get_best_loss()):\n",
    "        print('Loss is nan')\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "\n",
    "    # perform evaluation and log results\n",
    "    result = None\n",
    "    try:\n",
    "        result = trainer.perform_final_evaluation(use_test_set=True, verbose=False)\n",
    "    except Exception as err:\n",
    "        logger.exception(\"Could not complete iteration evaluation.\")\n",
    "        print('Could not complete iteration evaluation: ' + str(err))\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "    print(f'VAL f1\\t{trainer.get_best_f1()} - ({result[1][1]})')\n",
    "    print(f'VAL loss\\t{trainer.get_best_loss()}')\n",
    "    \n",
    "    print(f\"       .---.\\n \\\n",
    "         /     \\\\\\n\\\n",
    "          \\\\.@-@./\\n\\\n",
    "          /`\\\\_/`\\\\\\n\\\n",
    "         //  _  \\\\\\\\\\tLoss: {trainer.get_best_loss()}\\n\\\n",
    "        | \\\\     )|_\\tf1: {trainer.get_best_f1()}\\n\\\n",
    "       /`\\\\_`>  <_/ \\\\\\n\\\n",
    "       \\\\__/'---'\\\\__/\\n\")\n",
    "    \n",
    "    return {\n",
    "            'loss': result[1][0],\n",
    "            'status': STATUS_OK,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1(),\n",
    "            'sample_iterations': trainer.get_num_samples_seen(),\n",
    "            'iterations': trainer.get_num_iterations(),\n",
    "            'rc': rc,\n",
    "            'results': {\n",
    "                'train': {\n",
    "                    'loss': result[0][0],\n",
    "                    'f1': result[0][1]\n",
    "                },\n",
    "                'validation': {\n",
    "                    'loss': result[1][0],\n",
    "                    'f1': result[1][1]\n",
    "                },\n",
    "                'test': {\n",
    "                    'loss': result[2][0],\n",
    "                    'f1': result[2][1]\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_objective(params):\n",
    "    rc = from_hyperopt(params, use_cuda, 300, 4, 35, -1, 'de')\n",
    "    #print(rc)\n",
    "\n",
    "    return {\n",
    "        'loss': params['x'] ** 2,\n",
    "        'status': STATUS_OK\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190331\\1       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 26.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         26                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.011373937121708375               |\n",
      "|  noam_learning_rate_warmup   |                        8615                       |\n",
      "|  noam_learning_rate_factor   |                 1.2108504677212306                |\n",
      "|          adam_beta1          |                 0.9445929769407753                |\n",
      "|          adam_beta2          |                 0.9962624542543754                |\n",
      "|           adam_eps           |               1.4063993968374772e-10              |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2254452300907043                |\n",
      "|     pointwise_layer_size     |                        218                        |\n",
      "|      last_layer_dropout      |                0.013717986236493474               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        173                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  0%|                                                                            | 0/100 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728225e73115442ba1012e9c2a9aa413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.44\t\t0.30\t\t0.068\t\t0.865\t\t0.53m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.35\t\t0.28\t\t0.167\t\t0.835\t\t0.51m - 1.1m / 18.4m                                                                    \n",
      "3\t13k\t0.33\t\t0.27\t\t0.213\t\t0.832\t\t0.51m - 1.6m / 17.9m                                                                   \n",
      "4\t17k\t0.30\t\t0.27\t\t0.253\t\t0.814\t\t0.51m - 2.2m / 18.0m                                                                   \n",
      "5\t22k\t0.29\t\t0.27\t\t0.257\t\t0.810\t\t0.51m - 2.7m / 17.9m                                                                   \n",
      "6\t26k\t0.27\t\t0.28\t\t0.236\t\t0.773\t\t0.51m - 3.3m / 18.1m                                                                   \n",
      "7\t30k\t0.26\t\t0.27\t\t0.239\t\t0.772\t\t0.51m - 3.8m / 18.0m                                                                   \n",
      "8\t35k\t0.25\t\t0.28\t\t0.259\t\t0.784\t\t0.51m - 4.4m / 18.1m                                                                   \n",
      "9\t39k\t0.24\t\t0.28\t\t0.236\t\t0.772\t\t0.51m - 4.9m / 18.1m                                                                   \n",
      "10\t43k\t0.23\t\t0.30\t\t0.249\t\t0.776\t\t0.51m - 5.5m / 18.2m                                                                  \n",
      "11\t48k\t0.22\t\t0.28\t\t0.250\t\t0.793\t\t0.51m - 6.0m / 18.1m                                                                  \n",
      "12\t52k\t0.20\t\t0.30\t\t0.242\t\t0.796\t\t0.51m - 6.5m / 18.3m                                                                  \n",
      "13\t56k\t0.19\t\t0.32\t\t0.239\t\t0.777\t\t0.51m - 7.1m / 18.2m                                                                  \n",
      "VAL f1\t0.2593320235756385 - (0.2593320235756385)                                                                       \n",
      "VAL loss\t0.2696492700181769                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.2696492700181769\n",
      "        | \\     )|_\tf1: 0.2593320235756385\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\0       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 53.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         53                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.05885812652186355                |\n",
      "|  noam_learning_rate_warmup   |                        4458                       |\n",
      "|  noam_learning_rate_factor   |                 1.8894447021807392                |\n",
      "|          adam_beta1          |                 0.9782625518192796                |\n",
      "|          adam_beta2          |                 0.7568297979537542                |\n",
      "|           adam_eps           |               0.0028008623649272875               |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.2891384940310971                |\n",
      "|     pointwise_layer_size     |                         35                        |\n",
      "|      last_layer_dropout      |                 0.5697493758512432                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         70                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  1%|▍                                             | 1/100 [55:13<91:06:49, 3313.23s/it, best loss: 0.2809624544967561]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029ce53a9e0a4f3185dfb5ad2def4927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.24\t\t0.17\t\t0.026\t\t0.878\t\t0.15m - 0.1m / 0.0m                                                                     \n",
      "2\t9k\t0.20\t\t0.16\t\t0.022\t\t0.883\t\t0.15m - 0.3m / 5.2m                                                                     \n",
      "3\t13k\t0.19\t\t0.16\t\t0.000\t\t0.884\t\t0.14m - 0.5m / 5.2m                                                                    \n",
      "4\t17k\t0.19\t\t0.16\t\t0.114\t\t0.831\t\t0.15m - 0.7m / 5.2m                                                                    \n",
      "5\t22k\t0.18\t\t0.15\t\t0.115\t\t0.866\t\t0.15m - 0.9m / 5.2m                                                                    \n",
      "6\t26k\t0.17\t\t0.15\t\t0.186\t\t0.871\t\t0.15m - 1.1m / 5.5m                                                                    \n",
      "7\t30k\t0.16\t\t0.14\t\t0.233\t\t0.787\t\t0.15m - 1.3m / 5.3m                                                                    \n",
      "8\t35k\t0.15\t\t0.14\t\t0.244\t\t0.832\t\t0.14m - 1.4m / 5.4m                                                                    \n",
      "9\t39k\t0.14\t\t0.15\t\t0.279\t\t0.828\t\t0.14m - 1.6m / 5.4m                                                                    \n",
      "10\t43k\t0.14\t\t0.14\t\t0.242\t\t0.814\t\t0.15m - 1.8m / 5.4m                                                                   \n",
      "11\t48k\t0.13\t\t0.16\t\t0.242\t\t0.829\t\t0.14m - 2.0m / 5.5m                                                                   \n",
      "12\t52k\t0.13\t\t0.15\t\t0.280\t\t0.825\t\t0.15m - 2.2m / 5.4m                                                                   \n",
      "13\t56k\t0.12\t\t0.15\t\t0.273\t\t0.820\t\t0.14m - 2.3m / 5.6m                                                                   \n",
      "14\t61k\t0.11\t\t0.15\t\t0.244\t\t0.808\t\t0.14m - 2.5m / 5.5m                                                                   \n",
      "15\t65k\t0.11\t\t0.16\t\t0.259\t\t0.793\t\t0.14m - 2.7m / 5.6m                                                                   \n",
      "16\t70k\t0.11\t\t0.16\t\t0.285\t\t0.816\t\t0.15m - 2.9m / 5.6m                                                                   \n",
      "17\t74k\t0.10\t\t0.17\t\t0.274\t\t0.813\t\t0.14m - 3.1m / 5.7m                                                                   \n",
      "18\t78k\t0.09\t\t0.17\t\t0.286\t\t0.798\t\t0.15m - 3.3m / 5.7m                                                                   \n",
      "19\t83k\t0.09\t\t0.18\t\t0.290\t\t0.814\t\t0.14m - 3.4m / 5.8m                                                                   \n",
      "20\t87k\t0.08\t\t0.18\t\t0.255\t\t0.774\t\t0.14m - 3.6m / 5.8m                                                                   \n",
      "21\t91k\t0.08\t\t0.18\t\t0.292\t\t0.804\t\t0.14m - 3.8m / 5.8m                                                                   \n",
      "22\t96k\t0.07\t\t0.18\t\t0.282\t\t0.814\t\t0.14m - 4.0m / 5.9m                                                                   \n",
      "23\t100k\t0.07\t\t0.20\t\t0.284\t\t0.812\t\t0.14m - 4.2m / 5.9m                                                                  \n",
      "24\t104k\t0.07\t\t0.21\t\t0.276\t\t0.801\t\t0.15m - 4.4m / 5.9m                                                                  \n",
      "25\t109k\t0.07\t\t0.22\t\t0.292\t\t0.805\t\t0.14m - 4.5m / 6.0m                                                                  \n",
      "26\t113k\t0.06\t\t0.23\t\t0.301\t\t0.807\t\t0.14m - 4.7m / 6.0m                                                                  \n",
      "27\t117k\t0.06\t\t0.22\t\t0.287\t\t0.811\t\t0.14m - 4.9m / 6.1m                                                                  \n",
      "28\t122k\t0.06\t\t0.24\t\t0.280\t\t0.788\t\t0.14m - 5.1m / 6.1m                                                                  \n",
      "29\t126k\t0.06\t\t0.27\t\t0.276\t\t0.802\t\t0.15m - 5.3m / 6.1m                                                                  \n",
      "30\t130k\t0.06\t\t0.25\t\t0.301\t\t0.798\t\t0.15m - 5.5m / 6.2m                                                                  \n",
      "31\t135k\t0.06\t\t0.26\t\t0.273\t\t0.807\t\t0.14m - 5.6m / 6.2m                                                                  \n",
      "VAL f1\t0.3014256619144603 - (0.3014256619144603)                                                                       \n",
      "VAL loss\t0.1408801798550588                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.1408801798550588\n",
      "        | \\     )|_\tf1: 0.3014256619144603\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\1       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.4064336263773139                |\n",
      "|  noam_learning_rate_warmup   |                        4192                       |\n",
      "|  noam_learning_rate_factor   |                 0.7298541794536337                |\n",
      "|          adam_beta1          |                 0.8959999680208219                |\n",
      "|          adam_beta2          |                 0.8145913328985508                |\n",
      "|           adam_eps           |               5.144538910722893e-06               |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7408066343692895                |\n",
      "|     pointwise_layer_size     |                        234                        |\n",
      "|      last_layer_dropout      |                0.10095943998334933                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        111                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      "  2%|▉                                           | 2/100 [1:47:25<88:42:59, 3258.97s/it, best loss: 0.2340029372037903]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb64353f9eb94340b4b1fec5a76eac20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.60\t\t0.54\t\t0.174\t\t0.841\t\t0.69m - 0.7m / 0.0m                                                                     \n",
      "2\t9k\t0.52\t\t0.50\t\t0.167\t\t0.867\t\t0.67m - 1.4m / 24.2m                                                                    \n",
      "3\t13k\t0.51\t\t0.53\t\t0.158\t\t0.752\t\t0.68m - 2.1m / 23.7m                                                                   \n",
      "4\t17k\t0.49\t\t0.59\t\t0.231\t\t0.751\t\t0.68m - 2.8m / 23.9m                                                                   \n",
      "5\t22k\t0.46\t\t0.60\t\t0.219\t\t0.742\t\t0.71m - 3.6m / 23.8m                                                                   \n",
      "6\t26k\t0.46\t\t0.55\t\t0.217\t\t0.732\t\t0.67m - 4.3m / 24.9m                                                                   \n",
      "7\t30k\t0.46\t\t0.58\t\t0.224\t\t0.750\t\t0.68m - 5.0m / 23.8m                                                                   \n",
      "8\t35k\t0.46\t\t0.53\t\t0.228\t\t0.782\t\t0.67m - 5.7m / 24.0m                                                                   \n",
      "9\t39k\t0.46\t\t0.50\t\t0.221\t\t0.772\t\t0.67m - 6.4m / 23.8m                                                                   \n",
      "VAL f1\t0.23050259965337955 - (0.23050259965337955)                                                                     \n",
      "VAL loss\t0.4956557869911194                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.4956557869911194\n",
      "        | \\     )|_\tf1: 0.23050259965337955\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\2       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 34.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         34                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.021194328274870427               |\n",
      "|  noam_learning_rate_warmup   |                        1550                       |\n",
      "|  noam_learning_rate_factor   |                0.43604155382292187                |\n",
      "|          adam_beta1          |                 0.7319482021045924                |\n",
      "|          adam_beta2          |                 0.8645243529092789                |\n",
      "|           adam_eps           |                0.052344058321333514               |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.37337160754637133                |\n",
      "|     pointwise_layer_size     |                        158                        |\n",
      "|      last_layer_dropout      |                 0.7103900954505882                |\n",
      "|   output_conv_num_filters    |                        355                        |\n",
      "|   output_conv_kernel_size    |                         9                         |\n",
      "|      output_conv_stride      |                         2                         |\n",
      "|     output_conv_padding      |                         5                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         71                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  3%|█▎                                          | 3/100 [2:40:30<87:12:39, 3236.70s/it, best loss: 0.2340029372037903]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfe4c52f6344f78a4e7129c795d1f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while training: size mismatch, m1: [12070 x 3], m2: [355 x 4] at c:\\a\\w\\1\\s\\tmp_conda_3.6_105809\\conda\\conda-bld\\pytorch_1544094150554\\work\\aten\\src\\thc\\generic/THCTensorMathBlas.cu:266\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\3       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.022790664537627337               |\n",
      "|  noam_learning_rate_warmup   |                        3839                       |\n",
      "|  noam_learning_rate_factor   |                 3.6731370866777566                |\n",
      "|          adam_beta1          |                 0.8491382891408863                |\n",
      "|          adam_beta2          |                 0.9965162223661524                |\n",
      "|           adam_eps           |                0.025952048770043173               |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.551244149290593                 |\n",
      "|     pointwise_layer_size     |                         37                        |\n",
      "|      last_layer_dropout      |                 0.4289626015394598                |\n",
      "|   output_conv_num_filters    |                         97                        |\n",
      "|   output_conv_kernel_size    |                         5                         |\n",
      "|      output_conv_stride      |                         10                        |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        139                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  4%|█▊                                          | 4/100 [3:27:10<82:49:08, 3105.72s/it, best loss: 0.2340029372037903]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0355b05e7f42efb4ddb1cb1a21f5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.54\t\t0.45\t\t0.215\t\t0.760\t\t0.57m - 0.6m / 0.0m                                                                     \n",
      "2\t9k\t0.48\t\t0.43\t\t0.174\t\t0.771\t\t0.57m - 1.2m / 20.1m                                                                    \n",
      "3\t13k\t0.46\t\t0.42\t\t0.213\t\t0.780\t\t0.58m - 1.8m / 20.2m                                                                   \n",
      "4\t17k\t0.45\t\t0.41\t\t0.215\t\t0.791\t\t0.57m - 2.4m / 20.3m                                                                   \n",
      "5\t22k\t0.44\t\t0.41\t\t0.270\t\t0.824\t\t0.58m - 3.0m / 20.2m                                                                   \n",
      "6\t26k\t0.44\t\t0.43\t\t0.224\t\t0.779\t\t0.58m - 3.6m / 20.4m                                                                   \n",
      "7\t30k\t0.44\t\t0.41\t\t0.242\t\t0.805\t\t0.58m - 4.3m / 20.4m                                                                   \n",
      "8\t35k\t0.43\t\t0.43\t\t0.240\t\t0.820\t\t0.59m - 4.9m / 20.5m                                                                   \n",
      "9\t39k\t0.43\t\t0.41\t\t0.255\t\t0.832\t\t0.58m - 5.5m / 20.8m                                                                   \n",
      "10\t43k\t0.42\t\t0.39\t\t0.267\t\t0.823\t\t0.58m - 6.1m / 20.5m                                                                  \n",
      "VAL f1\t0.2702702702702703 - (0.2702702702702703)                                                                       \n",
      "VAL loss\t0.3874725902781767                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.3874725902781767\n",
      "        | \\     )|_\tf1: 0.2702702702702703\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\4       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 20.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         20                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.001225456123026824               |\n",
      "|  noam_learning_rate_warmup   |                        5328                       |\n",
      "|  noam_learning_rate_factor   |                 2.4481280122690787                |\n",
      "|          adam_beta1          |                 0.8832456561708852                |\n",
      "|          adam_beta2          |                 0.718038415942557                 |\n",
      "|           adam_eps           |               2.9374655172151836e-07              |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.4149784109071103                |\n",
      "|     pointwise_layer_size     |                         39                        |\n",
      "|      last_layer_dropout      |                 0.5351542847410896                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        177                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  5%|██▏                                         | 5/100 [4:19:44<82:20:24, 3120.26s/it, best loss: 0.2340029372037903]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9fade2442e4e53a0aab32e84ac2508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.51\t\t0.40\t\t0.058\t\t0.876\t\t0.37m - 0.4m / 0.0m                                                                     \n",
      "2\t9k\t0.42\t\t0.35\t\t0.173\t\t0.845\t\t0.37m - 0.8m / 13.1m                                                                    \n",
      "3\t13k\t0.37\t\t0.37\t\t0.213\t\t0.819\t\t0.37m - 1.2m / 13.2m                                                                   \n",
      "4\t17k\t0.34\t\t0.41\t\t0.239\t\t0.800\t\t0.37m - 1.6m / 13.1m                                                                   \n",
      "5\t22k\t0.30\t\t0.41\t\t0.261\t\t0.814\t\t0.37m - 2.0m / 13.2m                                                                   \n",
      "6\t26k\t0.25\t\t0.45\t\t0.230\t\t0.787\t\t0.38m - 2.4m / 13.2m                                                                   \n",
      "7\t30k\t0.22\t\t0.47\t\t0.242\t\t0.775\t\t0.37m - 2.8m / 13.4m                                                                   \n",
      "8\t35k\t0.19\t\t0.54\t\t0.247\t\t0.774\t\t0.40m - 3.3m / 13.2m                                                                   \n",
      "9\t39k\t0.16\t\t0.58\t\t0.272\t\t0.805\t\t0.38m - 3.7m / 14.1m                                                                   \n",
      "10\t43k\t0.15\t\t0.58\t\t0.230\t\t0.795\t\t0.37m - 4.1m / 13.5m                                                                  \n",
      "11\t48k\t0.14\t\t0.65\t\t0.251\t\t0.798\t\t0.38m - 4.5m / 13.5m                                                                  \n",
      "12\t52k\t0.14\t\t0.68\t\t0.216\t\t0.767\t\t0.37m - 4.9m / 13.6m                                                                  \n",
      "13\t56k\t0.13\t\t0.68\t\t0.221\t\t0.794\t\t0.37m - 5.3m / 13.5m                                                                  \n",
      "14\t60k\t0.13\t\t0.74\t\t0.221\t\t0.782\t\t0.38m - 5.8m / 13.5m                                                                  \n",
      "VAL f1\t0.2719665271966527 - (0.2719665271966527)                                                                       \n",
      "VAL loss\t0.35372842900893264                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.35372842900893264\n",
      "        | \\     )|_\tf1: 0.2719665271966527\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\5       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 40.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         40                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0005531554485546543               |\n",
      "|  noam_learning_rate_warmup   |                        8495                       |\n",
      "|  noam_learning_rate_factor   |                 2.5415854551496655                |\n",
      "|          adam_beta1          |                 0.800564021183262                 |\n",
      "|          adam_beta2          |                 0.9568824655075192                |\n",
      "|           adam_eps           |               7.474841091943888e-05               |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         4                         |\n",
      "|             d_k              |                         75                        |\n",
      "|             d_v              |                         75                        |\n",
      "|         dropout_rate         |                0.38834316086906306                |\n",
      "|     pointwise_layer_size     |                        269                        |\n",
      "|      last_layer_dropout      |                0.34702488058982434                |\n",
      "|   output_conv_num_filters    |                        336                        |\n",
      "|   output_conv_kernel_size    |                         9                         |\n",
      "|      output_conv_stride      |                         7                         |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         58                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  6%|██▋                                         | 6/100 [5:12:34<81:51:53, 3135.24s/it, best loss: 0.2340029372037903]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a412954e4ab845e18178693e33f54542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.25\t\t0.21\t\t0.130\t\t0.869\t\t0.28m - 0.3m / 0.0m                                                                     \n",
      "2\t9k\t0.22\t\t0.20\t\t0.217\t\t0.780\t\t0.28m - 0.6m / 9.9m                                                                     \n",
      "3\t13k\t0.20\t\t0.18\t\t0.223\t\t0.740\t\t0.28m - 0.9m / 9.9m                                                                    \n",
      "4\t17k\t0.19\t\t0.18\t\t0.249\t\t0.749\t\t0.28m - 1.2m / 10.0m                                                                   \n",
      "5\t22k\t0.19\t\t0.18\t\t0.242\t\t0.746\t\t0.28m - 1.6m / 10.0m                                                                   \n",
      "6\t26k\t0.18\t\t0.17\t\t0.256\t\t0.755\t\t0.28m - 1.9m / 9.9m                                                                    \n",
      "7\t30k\t0.17\t\t0.18\t\t0.240\t\t0.758\t\t0.28m - 2.2m / 10.0m                                                                   \n",
      "8\t35k\t0.16\t\t0.21\t\t0.203\t\t0.704\t\t0.28m - 2.5m / 10.1m                                                                   \n",
      "9\t39k\t0.14\t\t0.20\t\t0.240\t\t0.751\t\t0.28m - 2.8m / 10.1m                                                                   \n",
      "10\t43k\t0.14\t\t0.19\t\t0.234\t\t0.766\t\t0.28m - 3.2m / 10.2m                                                                  \n",
      "11\t48k\t0.12\t\t0.20\t\t0.241\t\t0.776\t\t0.28m - 3.5m / 10.2m                                                                  \n",
      "VAL f1\t0.2564991334488735 - (0.2564991334488735)                                                                       \n",
      "VAL loss\t0.17273471355438233                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.17273471355438233\n",
      "        | \\     )|_\tf1: 0.2564991334488735\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\6       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0007492859246231735               |\n",
      "|  noam_learning_rate_warmup   |                        3911                       |\n",
      "|  noam_learning_rate_factor   |                 0.5864213252289621                |\n",
      "|          adam_beta1          |                 0.8365971395039524                |\n",
      "|          adam_beta2          |                 0.7826636885013534                |\n",
      "|           adam_eps           |               7.018461972029566e-10               |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         4                         |\n",
      "|             d_k              |                         75                        |\n",
      "|             d_v              |                         75                        |\n",
      "|         dropout_rate         |                 0.3576705941131289                |\n",
      "|     pointwise_layer_size     |                        161                        |\n",
      "|      last_layer_dropout      |                 0.6016471467813159                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         53                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  7%|███                                        | 7/100 [6:03:15<80:15:36, 3106.84s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1c08179a9f46ed9a0d09bd39cd6978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.60\t\t0.43\t\t0.160\t\t0.844\t\t0.51m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.50\t\t0.39\t\t0.212\t\t0.862\t\t0.52m - 1.1m / 18.0m                                                                    \n",
      "3\t13k\t0.46\t\t0.41\t\t0.227\t\t0.813\t\t0.51m - 1.6m / 18.4m                                                                   \n",
      "4\t17k\t0.44\t\t0.44\t\t0.232\t\t0.769\t\t0.52m - 2.2m / 18.0m                                                                   \n",
      "5\t22k\t0.43\t\t0.42\t\t0.265\t\t0.797\t\t0.51m - 2.7m / 18.3m                                                                   \n",
      "6\t26k\t0.42\t\t0.39\t\t0.279\t\t0.817\t\t0.52m - 3.3m / 18.1m                                                                   \n",
      "7\t30k\t0.41\t\t0.39\t\t0.254\t\t0.795\t\t0.51m - 3.8m / 18.3m                                                                   \n",
      "8\t35k\t0.41\t\t0.39\t\t0.278\t\t0.831\t\t0.51m - 4.4m / 18.1m                                                                   \n",
      "9\t39k\t0.41\t\t0.40\t\t0.254\t\t0.825\t\t0.51m - 4.9m / 18.2m                                                                   \n",
      "10\t43k\t0.40\t\t0.40\t\t0.261\t\t0.836\t\t0.51m - 5.5m / 18.1m                                                                  \n",
      "11\t47k\t0.40\t\t0.42\t\t0.254\t\t0.787\t\t0.50m - 6.0m / 18.3m                                                                  \n",
      "VAL f1\t0.27932960893854747 - (0.27932960893854747)                                                                     \n",
      "VAL loss\t0.3885979308801539                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.3885979308801539\n",
      "        | \\     )|_\tf1: 0.27932960893854747\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\7       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 46.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         46                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.016905458111584858               |\n",
      "|  noam_learning_rate_warmup   |                        2650                       |\n",
      "|  noam_learning_rate_factor   |                 3.6152208470563667                |\n",
      "|          adam_beta1          |                 0.9709388232071698                |\n",
      "|          adam_beta2          |                 0.8785149109819769                |\n",
      "|           adam_eps           |               4.838072274086381e-07               |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         5                         |\n",
      "|             d_k              |                         60                        |\n",
      "|             d_v              |                         60                        |\n",
      "|         dropout_rate         |                 0.5415349423558736                |\n",
      "|     pointwise_layer_size     |                        209                        |\n",
      "|      last_layer_dropout      |                0.17548584007324264                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        145                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  8%|███▍                                       | 8/100 [6:56:11<79:55:52, 3127.74s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124c26bd1f294bdea9b8e1d689999ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.24\t\t0.22\t\t0.051\t\t0.665\t\t0.15m - 0.2m / 0.0m                                                                     \n",
      "2\t9k\t0.21\t\t0.18\t\t0.187\t\t0.827\t\t0.15m - 0.3m / 5.3m                                                                     \n",
      "3\t13k\t0.19\t\t0.19\t\t0.231\t\t0.739\t\t0.15m - 0.5m / 5.3m                                                                    \n",
      "4\t17k\t0.16\t\t0.22\t\t0.212\t\t0.708\t\t0.15m - 0.7m / 5.4m                                                                    \n",
      "5\t22k\t0.13\t\t0.23\t\t0.235\t\t0.745\t\t0.15m - 0.9m / 5.4m                                                                    \n",
      "6\t26k\t0.10\t\t0.26\t\t0.233\t\t0.749\t\t0.15m - 1.1m / 5.5m                                                                    \n",
      "7\t30k\t0.08\t\t0.28\t\t0.245\t\t0.767\t\t0.15m - 1.3m / 5.5m                                                                    \n",
      "8\t35k\t0.07\t\t0.30\t\t0.269\t\t0.792\t\t0.15m - 1.5m / 5.5m                                                                    \n",
      "9\t39k\t0.06\t\t0.32\t\t0.256\t\t0.796\t\t0.15m - 1.7m / 5.6m                                                                    \n",
      "10\t43k\t0.05\t\t0.36\t\t0.250\t\t0.781\t\t0.15m - 1.9m / 5.7m                                                                   \n",
      "11\t48k\t0.04\t\t0.40\t\t0.274\t\t0.836\t\t0.15m - 2.0m / 5.6m                                                                   \n",
      "12\t52k\t0.04\t\t0.40\t\t0.262\t\t0.815\t\t0.15m - 2.2m / 5.7m                                                                   \n",
      "13\t56k\t0.04\t\t0.42\t\t0.247\t\t0.802\t\t0.15m - 2.4m / 5.7m                                                                   \n",
      "14\t61k\t0.03\t\t0.45\t\t0.237\t\t0.798\t\t0.15m - 2.6m / 5.8m                                                                   \n",
      "15\t65k\t0.03\t\t0.52\t\t0.268\t\t0.828\t\t0.15m - 2.8m / 5.8m                                                                   \n",
      "16\t69k\t0.04\t\t0.44\t\t0.250\t\t0.810\t\t0.15m - 3.0m / 5.9m                                                                   \n",
      "VAL f1\t0.27383863080684595 - (0.27383863080684595)                                                                     \n",
      "VAL loss\t0.18084426548170007                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.18084426548170007\n",
      "        | \\     )|_\tf1: 0.27383863080684595\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\8       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 19.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         19                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00084207812111664                |\n",
      "|  noam_learning_rate_warmup   |                        8009                       |\n",
      "|  noam_learning_rate_factor   |                 0.7300135205483417                |\n",
      "|          adam_beta1          |                 0.7575115801720074                |\n",
      "|          adam_beta2          |                 0.7826585386996145                |\n",
      "|           adam_eps           |               9.018161437438328e-10               |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.04994730061818364                |\n",
      "|     pointwise_layer_size     |                        153                        |\n",
      "|      last_layer_dropout      |                 0.2987404019390425                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        143                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  9%|███▊                                       | 9/100 [7:46:01<78:00:47, 3086.24s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb29d9935f54baaa21ffd900bb344a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.58\t\t0.40\t\t0.005\t\t0.876\t\t0.48m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.46\t\t0.37\t\t0.066\t\t0.865\t\t0.49m - 1.0m / 17.0m                                                                    \n",
      "3\t13k\t0.43\t\t0.35\t\t0.195\t\t0.853\t\t0.49m - 1.5m / 17.2m                                                                   \n",
      "4\t17k\t0.40\t\t0.33\t\t0.236\t\t0.859\t\t0.49m - 2.1m / 17.3m                                                                   \n",
      "5\t22k\t0.37\t\t0.32\t\t0.260\t\t0.842\t\t0.49m - 2.6m / 17.3m                                                                   \n",
      "6\t26k\t0.35\t\t0.32\t\t0.276\t\t0.842\t\t0.48m - 3.1m / 17.2m                                                                   \n",
      "7\t30k\t0.33\t\t0.34\t\t0.256\t\t0.798\t\t0.49m - 3.7m / 17.1m                                                                   \n",
      "8\t35k\t0.31\t\t0.33\t\t0.277\t\t0.820\t\t0.50m - 4.2m / 17.5m                                                                   \n",
      "9\t39k\t0.29\t\t0.36\t\t0.287\t\t0.830\t\t0.49m - 4.7m / 17.6m                                                                   \n",
      "10\t43k\t0.27\t\t0.35\t\t0.288\t\t0.849\t\t0.49m - 5.2m / 17.5m                                                                  \n",
      "11\t48k\t0.25\t\t0.38\t\t0.258\t\t0.823\t\t0.48m - 5.8m / 17.4m                                                                  \n",
      "12\t52k\t0.23\t\t0.36\t\t0.260\t\t0.827\t\t0.49m - 6.3m / 17.4m                                                                  \n",
      "13\t56k\t0.22\t\t0.41\t\t0.277\t\t0.831\t\t0.49m - 6.8m / 17.5m                                                                  \n",
      "14\t61k\t0.20\t\t0.41\t\t0.294\t\t0.835\t\t0.48m - 7.3m / 17.6m                                                                  \n",
      "15\t65k\t0.19\t\t0.40\t\t0.266\t\t0.832\t\t0.49m - 7.9m / 17.5m                                                                  \n",
      "16\t69k\t0.17\t\t0.43\t\t0.297\t\t0.828\t\t0.49m - 8.4m / 17.8m                                                                  \n",
      "17\t74k\t0.16\t\t0.45\t\t0.264\t\t0.829\t\t0.49m - 8.9m / 17.7m                                                                  \n",
      "18\t78k\t0.16\t\t0.48\t\t0.275\t\t0.837\t\t0.49m - 9.5m / 17.8m                                                                  \n",
      "19\t82k\t0.15\t\t0.52\t\t0.250\t\t0.832\t\t0.49m - 10.0m / 17.7m                                                                 \n",
      "20\t87k\t0.14\t\t0.53\t\t0.247\t\t0.812\t\t0.49m - 10.5m / 17.9m                                                                 \n",
      "21\t91k\t0.13\t\t0.52\t\t0.275\t\t0.834\t\t0.51m - 11.1m / 17.8m                                                                 \n",
      "VAL f1\t0.2968036529680365 - (0.2968036529680365)                                                                       \n",
      "VAL loss\t0.32335697419462156                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.32335697419462156\n",
      "        | \\     )|_\tf1: 0.2968036529680365\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\9       \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 11.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         11                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04807425282381034                |\n",
      "|  noam_learning_rate_warmup   |                        1870                       |\n",
      "|  noam_learning_rate_factor   |                 2.2613847755289727                |\n",
      "|          adam_beta1          |                 0.8972436313381147                |\n",
      "|          adam_beta2          |                 0.720047235933861                 |\n",
      "|           adam_eps           |               1.556669343219266e-08               |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.3536724774970659                |\n",
      "|     pointwise_layer_size     |                        187                        |\n",
      "|      last_layer_dropout      |               0.0010076686262597613               |\n",
      "|   output_conv_num_filters    |                        191                        |\n",
      "|   output_conv_kernel_size    |                         3                         |\n",
      "|      output_conv_stride      |                         3                         |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        159                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 10%|████▏                                     | 10/100 [8:43:57<80:04:41, 3203.13s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb59a9a00ef54d73a11f60db8af02f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t2.03\t\t0.95\t\t0.012\t\t0.778\t\t1.00m - 1.0m / 0.0m                                                                     \n",
      "2\t9k\t1.31\t\t0.64\t\t0.000\t\t0.885\t\t1.01m - 2.0m / 35.1m                                                                    \n",
      "3\t13k\t3.16\t\t0.71\t\t0.000\t\t0.885\t\t1.00m - 3.1m / 35.3m                                                                   \n",
      "4\t17k\t1.18\t\t0.73\t\t0.000\t\t0.885\t\t1.05m - 4.2m / 35.1m                                                                   \n",
      "5\t22k\t2.00\t\t0.70\t\t0.000\t\t0.885\t\t1.03m - 5.2m / 36.7m                                                                   \n",
      "6\t26k\t1.10\t\t0.63\t\t0.000\t\t0.885\t\t0.99m - 6.3m / 36.2m                                                                   \n",
      "VAL f1\t0.011747430249632892 - (0.011747430249632892)                                                                   \n",
      "VAL loss\t0.6269693039029924                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.6269693039029924\n",
      "        | \\     )|_\tf1: 0.011747430249632892\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\10      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 12.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         12                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.002084641396489217               |\n",
      "|  noam_learning_rate_warmup   |                        1364                       |\n",
      "|  noam_learning_rate_factor   |                 1.7613383821863733                |\n",
      "|          adam_beta1          |                 0.8422135786279819                |\n",
      "|          adam_beta2          |                 0.7382472161154832                |\n",
      "|           adam_eps           |               0.0018293626500184884               |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5829547664832726                |\n",
      "|     pointwise_layer_size     |                        342                        |\n",
      "|      last_layer_dropout      |                 0.6440972893763268                |\n",
      "|   output_conv_num_filters    |                        370                        |\n",
      "|   output_conv_kernel_size    |                         8                         |\n",
      "|      output_conv_stride      |                         9                         |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        156                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 11%|████▌                                     | 11/100 [9:37:47<79:23:31, 3211.37s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a375161f83b14a2b931605a75b16bbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.82\t\t0.75\t\t0.119\t\t0.739\t\t0.85m - 0.8m / 0.0m                                                                     \n",
      "2\t9k\t0.77\t\t0.72\t\t0.184\t\t0.734\t\t0.85m - 1.7m / 29.7m                                                                    \n",
      "3\t13k\t0.80\t\t0.78\t\t0.128\t\t0.730\t\t0.85m - 2.6m / 29.9m                                                                   \n",
      "4\t17k\t0.79\t\t0.73\t\t0.126\t\t0.811\t\t0.85m - 3.5m / 30.0m                                                                   \n",
      "5\t22k\t0.76\t\t0.74\t\t0.000\t\t0.885\t\t0.85m - 4.4m / 30.0m                                                                   \n",
      "6\t26k\t0.76\t\t0.67\t\t0.000\t\t0.885\t\t0.85m - 5.3m / 30.0m                                                                   \n",
      "7\t30k\t0.76\t\t0.68\t\t0.000\t\t0.885\t\t0.85m - 6.2m / 30.0m                                                                   \n",
      "VAL f1\t0.1837270341207349 - (0.1837270341207349)                                                                       \n",
      "VAL loss\t0.6729711719921657                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.6729711719921657\n",
      "        | \\     )|_\tf1: 0.1837270341207349\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\11      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.2145242502843251                |\n",
      "|  noam_learning_rate_warmup   |                        7239                       |\n",
      "|  noam_learning_rate_factor   |                 3.846201634429372                 |\n",
      "|          adam_beta1          |                 0.9047777950177712                |\n",
      "|          adam_beta2          |                 0.9227868305141633                |\n",
      "|           adam_eps           |               0.0002853611190062122               |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.46196950779055046                |\n",
      "|     pointwise_layer_size     |                        152                        |\n",
      "|      last_layer_dropout      |                 0.3786834201412441                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        117                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 12%|████▉                                    | 12/100 [10:31:15<78:28:19, 3210.23s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc6d00dd5444cfcbd57a6a4d4194e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.55\t\t0.43\t\t0.164\t\t0.832\t\t0.54m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.47\t\t0.41\t\t0.226\t\t0.779\t\t0.55m - 1.1m / 18.9m                                                                    \n",
      "3\t13k\t0.43\t\t0.41\t\t0.255\t\t0.779\t\t0.53m - 1.7m / 19.2m                                                                   \n",
      "4\t17k\t0.42\t\t0.43\t\t0.261\t\t0.793\t\t0.54m - 2.3m / 18.8m                                                                   \n",
      "5\t22k\t0.41\t\t0.40\t\t0.274\t\t0.811\t\t0.53m - 2.8m / 19.2m                                                                   \n",
      "6\t26k\t0.40\t\t0.41\t\t0.276\t\t0.794\t\t0.54m - 3.4m / 18.8m                                                                   \n",
      "7\t30k\t0.39\t\t0.39\t\t0.284\t\t0.826\t\t0.53m - 4.0m / 19.3m                                                                   \n",
      "8\t35k\t0.39\t\t0.40\t\t0.299\t\t0.851\t\t0.54m - 4.6m / 18.9m                                                                   \n",
      "9\t39k\t0.38\t\t0.42\t\t0.268\t\t0.800\t\t0.53m - 5.2m / 19.3m                                                                   \n",
      "10\t43k\t0.37\t\t0.45\t\t0.278\t\t0.830\t\t0.54m - 5.7m / 19.1m                                                                  \n",
      "11\t47k\t0.36\t\t0.47\t\t0.270\t\t0.822\t\t0.53m - 6.3m / 19.2m                                                                  \n",
      "12\t52k\t0.35\t\t0.47\t\t0.234\t\t0.805\t\t0.53m - 6.9m / 19.1m                                                                  \n",
      "13\t56k\t0.35\t\t0.48\t\t0.257\t\t0.809\t\t0.53m - 7.4m / 19.2m                                                                  \n",
      "VAL f1\t0.29873417721518986 - (0.29873417721518986)                                                                     \n",
      "VAL loss\t0.38922219486797555                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.38922219486797555\n",
      "        | \\     )|_\tf1: 0.29873417721518986\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\12      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 26.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         26                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.5269465283599728                |\n",
      "|  noam_learning_rate_warmup   |                        2488                       |\n",
      "|  noam_learning_rate_factor   |                 2.301598820601101                 |\n",
      "|          adam_beta1          |                 0.9878891697649208                |\n",
      "|          adam_beta2          |                 0.9934384128508251                |\n",
      "|           adam_eps           |                0.15686084165923017                |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.0172567480573548                |\n",
      "|     pointwise_layer_size     |                        144                        |\n",
      "|      last_layer_dropout      |                0.03350339080072642                |\n",
      "|   output_conv_num_filters    |                        277                        |\n",
      "|   output_conv_kernel_size    |                         5                         |\n",
      "|      output_conv_stride      |                         6                         |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        163                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 13%|█████▎                                   | 13/100 [11:26:00<78:07:24, 3232.69s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f36dd23a5d34499b41bb053d0363c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.38\t\t0.31\t\t0.000\t\t0.885\t\t0.48m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.34\t\t0.28\t\t0.171\t\t0.853\t\t0.48m - 1.0m / 17.0m                                                                    \n",
      "3\t13k\t0.30\t\t0.28\t\t0.171\t\t0.815\t\t0.48m - 1.5m / 16.9m                                                                   \n",
      "4\t17k\t0.27\t\t0.27\t\t0.276\t\t0.829\t\t0.48m - 2.0m / 17.1m                                                                   \n",
      "5\t22k\t0.24\t\t0.28\t\t0.250\t\t0.840\t\t0.48m - 2.6m / 17.0m                                                                   \n",
      "6\t26k\t0.22\t\t0.28\t\t0.221\t\t0.825\t\t0.48m - 3.1m / 17.0m                                                                   \n",
      "7\t30k\t0.19\t\t0.28\t\t0.291\t\t0.837\t\t0.48m - 3.6m / 17.0m                                                                   \n",
      "8\t35k\t0.16\t\t0.29\t\t0.257\t\t0.829\t\t0.48m - 4.1m / 17.2m                                                                   \n",
      "9\t39k\t0.12\t\t0.31\t\t0.236\t\t0.837\t\t0.49m - 4.7m / 17.3m                                                                   \n",
      "10\t43k\t0.09\t\t0.33\t\t0.233\t\t0.846\t\t0.48m - 5.2m / 17.3m                                                                  \n",
      "11\t48k\t0.07\t\t0.33\t\t0.252\t\t0.856\t\t0.50m - 5.7m / 17.3m                                                                  \n",
      "12\t52k\t0.05\t\t0.36\t\t0.294\t\t0.861\t\t0.49m - 6.2m / 17.6m                                                                  \n",
      "13\t56k\t0.04\t\t0.38\t\t0.240\t\t0.865\t\t0.48m - 6.8m / 17.5m                                                                  \n",
      "14\t61k\t0.03\t\t0.41\t\t0.223\t\t0.866\t\t0.48m - 7.3m / 17.4m                                                                  \n",
      "15\t65k\t0.02\t\t0.46\t\t0.241\t\t0.864\t\t0.48m - 7.8m / 17.3m                                                                  \n",
      "16\t69k\t0.02\t\t0.45\t\t0.230\t\t0.865\t\t0.48m - 8.3m / 17.5m                                                                  \n",
      "17\t74k\t0.01\t\t0.48\t\t0.213\t\t0.867\t\t0.48m - 8.8m / 17.4m                                                                  \n",
      "Could not complete iteration evaluation: Dimension out of range (expected to be in range of [-1, 0], but got 1)        \n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\13      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 47.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         47                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.009170065643247297               |\n",
      "|  noam_learning_rate_warmup   |                        7317                       |\n",
      "|  noam_learning_rate_factor   |                 1.2263570321933546                |\n",
      "|          adam_beta1          |                 0.8290723867434261                |\n",
      "|          adam_beta2          |                 0.8886034809409266                |\n",
      "|           adam_eps           |               2.6004494213547024e-07              |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         4                         |\n",
      "|             d_k              |                         75                        |\n",
      "|             d_v              |                         75                        |\n",
      "|         dropout_rate         |                0.21669700616108978                |\n",
      "|     pointwise_layer_size     |                        167                        |\n",
      "|      last_layer_dropout      |                0.13615884996871763                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         49                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 14%|█████▋                                   | 14/100 [12:21:50<78:04:10, 3268.03s/it, best loss: 0.17273471355438233]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bc698212774e7dbbe8390020d5e117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.29\t\t0.20\t\t0.177\t\t0.803\t\t0.16m - 0.2m / 0.0m                                                                     \n",
      "2\t9k\t0.21\t\t0.18\t\t0.062\t\t0.872\t\t0.16m - 0.4m / 5.8m                                                                     \n",
      "3\t13k\t0.20\t\t0.17\t\t0.088\t\t0.876\t\t0.16m - 0.6m / 5.8m                                                                    \n",
      "4\t17k\t0.20\t\t0.16\t\t0.173\t\t0.851\t\t0.16m - 0.8m / 5.8m                                                                    \n",
      "5\t22k\t0.19\t\t0.16\t\t0.221\t\t0.835\t\t0.16m - 1.0m / 5.9m                                                                    \n",
      "6\t26k\t0.17\t\t0.16\t\t0.255\t\t0.822\t\t0.16m - 1.2m / 6.0m                                                                    \n",
      "7\t30k\t0.17\t\t0.15\t\t0.274\t\t0.834\t\t0.16m - 1.4m / 5.9m                                                                    \n",
      "8\t35k\t0.16\t\t0.16\t\t0.257\t\t0.803\t\t0.16m - 1.6m / 5.9m                                                                    \n",
      "9\t39k\t0.15\t\t0.15\t\t0.265\t\t0.823\t\t0.16m - 1.8m / 6.0m                                                                    \n",
      "10\t43k\t0.14\t\t0.15\t\t0.256\t\t0.813\t\t0.16m - 2.0m / 6.0m                                                                   \n",
      "11\t48k\t0.14\t\t0.15\t\t0.301\t\t0.826\t\t0.17m - 2.2m / 6.1m                                                                   \n",
      "12\t52k\t0.13\t\t0.17\t\t0.245\t\t0.773\t\t0.16m - 2.4m / 6.2m                                                                   \n",
      "13\t56k\t0.13\t\t0.15\t\t0.276\t\t0.803\t\t0.16m - 2.6m / 6.2m                                                                   \n",
      "14\t61k\t0.12\t\t0.16\t\t0.317\t\t0.817\t\t0.16m - 2.8m / 6.2m                                                                   \n",
      "15\t65k\t0.12\t\t0.16\t\t0.282\t\t0.800\t\t0.16m - 3.0m / 6.3m                                                                   \n",
      "16\t69k\t0.11\t\t0.16\t\t0.273\t\t0.785\t\t0.17m - 3.2m / 6.3m                                                                   \n",
      "17\t74k\t0.11\t\t0.17\t\t0.299\t\t0.801\t\t0.16m - 3.4m / 6.4m                                                                   \n",
      "18\t78k\t0.10\t\t0.16\t\t0.285\t\t0.793\t\t0.16m - 3.6m / 6.3m                                                                   \n",
      "19\t82k\t0.10\t\t0.17\t\t0.297\t\t0.800\t\t0.16m - 3.8m / 6.4m                                                                   \n",
      "VAL f1\t0.31670281995661603 - (0.31670281995661603)                                                                     \n",
      "VAL loss\t0.1531297729370442                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.1531297729370442\n",
      "        | \\     )|_\tf1: 0.31670281995661603\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\14      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 27.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         27                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.1932259171436165                |\n",
      "|  noam_learning_rate_warmup   |                        6717                       |\n",
      "|  noam_learning_rate_factor   |                  3.91372883262602                 |\n",
      "|          adam_beta1          |                 0.8514449769714676                |\n",
      "|          adam_beta2          |                 0.9700387980336964                |\n",
      "|           adam_eps           |               1.4968797693413032e-08              |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.08809327710069673                |\n",
      "|     pointwise_layer_size     |                         71                        |\n",
      "|      last_layer_dropout      |                 0.5679055156588737                |\n",
      "|   output_conv_num_filters    |                        204                        |\n",
      "|   output_conv_kernel_size    |                         5                         |\n",
      "|      output_conv_stride      |                         9                         |\n",
      "|     output_conv_padding      |                         2                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        173                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 15%|██████▎                                   | 15/100 [13:13:54<76:08:12, 3224.62s/it, best loss: 0.1608786659037813]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5c45d5266e4a4d84e5ccc4aaf9e4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.35\t\t0.32\t\t0.218\t\t0.827\t\t0.26m - 0.3m / 0.0m                                                                     \n",
      "2\t9k\t0.29\t\t0.27\t\t0.233\t\t0.822\t\t0.26m - 0.6m / 9.1m                                                                     \n",
      "3\t13k\t0.25\t\t0.26\t\t0.260\t\t0.813\t\t0.26m - 0.9m / 9.3m                                                                    \n",
      "4\t17k\t0.21\t\t0.27\t\t0.260\t\t0.797\t\t0.27m - 1.2m / 9.1m                                                                    \n",
      "5\t22k\t0.18\t\t0.25\t\t0.237\t\t0.794\t\t0.27m - 1.5m / 9.4m                                                                    \n",
      "6\t26k\t0.14\t\t0.25\t\t0.249\t\t0.818\t\t0.27m - 1.8m / 9.6m                                                                    \n",
      "7\t30k\t0.12\t\t0.26\t\t0.236\t\t0.799\t\t0.26m - 2.1m / 9.7m                                                                    \n",
      "8\t35k\t0.11\t\t0.28\t\t0.241\t\t0.821\t\t0.25m - 2.4m / 9.3m                                                                    \n",
      "9\t39k\t0.10\t\t0.33\t\t0.201\t\t0.786\t\t0.26m - 2.7m / 9.3m                                                                    \n",
      "VAL f1\t0.26006191950464397 - (0.26006191950464397)                                                                     \n",
      "VAL loss\t0.25294282293727255                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.25294282293727255\n",
      "        | \\     )|_\tf1: 0.26006191950464397\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\15      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 25.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         25                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04864265799855249                |\n",
      "|  noam_learning_rate_warmup   |                        5921                       |\n",
      "|  noam_learning_rate_factor   |                 3.5515305536641026                |\n",
      "|          adam_beta1          |                 0.9932297004671162                |\n",
      "|          adam_beta2          |                 0.9889900603474672                |\n",
      "|           adam_eps           |               0.0028200184476833974               |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         4                         |\n",
      "|             d_k              |                         75                        |\n",
      "|             d_v              |                         75                        |\n",
      "|         dropout_rate         |                 0.7218908417177126                |\n",
      "|     pointwise_layer_size     |                        153                        |\n",
      "|      last_layer_dropout      |                0.33787958842447896                |\n",
      "|   output_conv_num_filters    |                         51                        |\n",
      "|   output_conv_kernel_size    |                         10                        |\n",
      "|      output_conv_stride      |                         3                         |\n",
      "|     output_conv_padding      |                         0                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        117                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 16%|██████▋                                   | 16/100 [14:04:15<73:48:56, 3163.53s/it, best loss: 0.1608786659037813]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd09ea1fa41c487e9577ceb8456ceccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.42\t\t0.42\t\t0.079\t\t0.556\t\t0.47m - 0.5m / 0.0m                                                                     \n",
      "2\t9k\t0.38\t\t0.43\t\t0.063\t\t0.517\t\t0.44m - 0.9m / 16.4m                                                                    \n",
      "3\t13k\t0.38\t\t0.42\t\t0.096\t\t0.513\t\t0.45m - 1.4m / 15.4m                                                                   \n",
      "4\t17k\t0.37\t\t0.39\t\t0.154\t\t0.550\t\t0.44m - 1.9m / 15.8m                                                                   \n",
      "5\t22k\t0.36\t\t0.40\t\t0.142\t\t0.577\t\t0.44m - 2.4m / 15.6m                                                                   \n",
      "6\t26k\t0.36\t\t0.43\t\t0.136\t\t0.499\t\t0.44m - 2.9m / 15.6m                                                                   \n",
      "7\t30k\t0.36\t\t0.51\t\t0.130\t\t0.448\t\t0.44m - 3.3m / 15.7m                                                                   \n",
      "8\t35k\t0.37\t\t0.51\t\t0.140\t\t0.504\t\t0.44m - 3.8m / 15.7m                                                                   \n",
      "9\t39k\t0.36\t\t0.75\t\t0.120\t\t0.387\t\t0.44m - 4.3m / 15.9m                                                                   \n",
      "VAL f1\t0.1537591859807801 - (0.1537591859807801)                                                                       \n",
      "VAL loss\t0.38799956321716306                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.38799956321716306\n",
      "        | \\     )|_\tf1: 0.1537591859807801\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\16      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 39.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                  entities_combine                 |\n",
      "|          batch_size          |                         39                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.010818546062876109               |\n",
      "|  noam_learning_rate_warmup   |                        3368                       |\n",
      "|  noam_learning_rate_factor   |                 1.6393316571346608                |\n",
      "|          adam_beta1          |                 0.752910373382914                 |\n",
      "|          adam_beta2          |                 0.7838029047465876                |\n",
      "|           adam_eps           |               6.246047720793416e-07               |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5832847477219238                |\n",
      "|     pointwise_layer_size     |                        166                        |\n",
      "|      last_layer_dropout      |                 0.3061304018844679                |\n",
      "|   output_conv_num_filters    |                        172                        |\n",
      "|   output_conv_kernel_size    |                         3                         |\n",
      "|      output_conv_stride      |                         8                         |\n",
      "|     output_conv_padding      |                         4                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         81                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 17%|███████▏                                  | 17/100 [14:56:00<72:32:09, 3146.14s/it, best loss: 0.1608786659037813]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d839d11d4d824673b82357da327fba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.26\t\t0.22\t\t0.120\t\t0.845\t\t0.28m - 0.3m / 0.0m                                                                     \n",
      "2\t9k\t0.24\t\t0.25\t\t0.150\t\t0.637\t\t0.28m - 0.6m / 9.9m                                                                     \n",
      "3\t13k\t0.22\t\t0.20\t\t0.224\t\t0.733\t\t0.27m - 0.9m / 9.9m                                                                    \n",
      "4\t17k\t0.21\t\t0.20\t\t0.213\t\t0.737\t\t0.27m - 1.2m / 9.6m                                                                    \n",
      "5\t22k\t0.22\t\t0.20\t\t0.225\t\t0.726\t\t0.27m - 1.5m / 9.7m                                                                    \n",
      "6\t26k\t0.21\t\t0.20\t\t0.194\t\t0.718\t\t0.27m - 1.8m / 9.8m                                                                    \n",
      "7\t30k\t0.21\t\t0.19\t\t0.244\t\t0.794\t\t0.27m - 2.1m / 9.7m                                                                    \n",
      "8\t35k\t0.21\t\t0.19\t\t0.241\t\t0.763\t\t0.27m - 2.5m / 9.7m                                                                    \n",
      "9\t39k\t0.21\t\t0.21\t\t0.212\t\t0.729\t\t0.27m - 2.8m / 9.9m                                                                    \n",
      "10\t43k\t0.21\t\t0.22\t\t0.181\t\t0.700\t\t0.27m - 3.1m / 9.7m                                                                   \n",
      "11\t48k\t0.21\t\t0.20\t\t0.222\t\t0.746\t\t0.27m - 3.4m / 9.8m                                                                   \n",
      "12\t52k\t0.21\t\t0.21\t\t0.219\t\t0.726\t\t0.27m - 3.7m / 9.9m                                                                   \n",
      "VAL f1\t0.24390243902439024 - (0.24390243902439024)                                                                     \n",
      "VAL loss\t0.18687651979277956                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.18687651979277956\n",
      "        | \\     )|_\tf1: 0.24390243902439024\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\17      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.009746181033014962               |\n",
      "|  noam_learning_rate_warmup   |                        5499                       |\n",
      "|  noam_learning_rate_factor   |                 2.5284759918290827                |\n",
      "|          adam_beta1          |                 0.9206513739703951                |\n",
      "|          adam_beta2          |                 0.9392212929536975                |\n",
      "|           adam_eps           |               1.310503828425855e-05               |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.28274825963453676                |\n",
      "|     pointwise_layer_size     |                        129                        |\n",
      "|      last_layer_dropout      |                0.39743837844774793                |\n",
      "|   output_conv_num_filters    |                        387                        |\n",
      "|   output_conv_kernel_size    |                         10                        |\n",
      "|      output_conv_stride      |                         3                         |\n",
      "|     output_conv_padding      |                         1                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        169                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 18%|███████▌                                  | 18/100 [15:46:55<71:02:16, 3118.74s/it, best loss: 0.1608786659037813]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b62be889e54219b7f425eeceb2543d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.24\t\t0.20\t\t0.182\t\t0.857\t\t0.43m - 0.4m / 0.0m                                                                     \n",
      "2\t9k\t0.20\t\t0.19\t\t0.199\t\t0.688\t\t0.43m - 0.9m / 15.0m                                                                    \n",
      "3\t13k\t0.19\t\t0.19\t\t0.217\t\t0.733\t\t0.43m - 1.4m / 15.0m                                                                   \n",
      "4\t17k\t0.18\t\t0.20\t\t0.194\t\t0.672\t\t0.43m - 1.8m / 15.0m                                                                   \n",
      "5\t22k\t0.16\t\t0.18\t\t0.214\t\t0.731\t\t0.43m - 2.3m / 15.1m                                                                   \n",
      "6\t26k\t0.14\t\t0.18\t\t0.250\t\t0.766\t\t0.43m - 2.8m / 15.2m                                                                   \n",
      "7\t30k\t0.12\t\t0.18\t\t0.272\t\t0.783\t\t0.43m - 3.2m / 15.2m                                                                   \n",
      "8\t35k\t0.11\t\t0.19\t\t0.312\t\t0.828\t\t0.43m - 3.7m / 15.3m                                                                   \n",
      "9\t39k\t0.10\t\t0.22\t\t0.269\t\t0.803\t\t0.43m - 4.2m / 15.3m                                                                   \n",
      "10\t43k\t0.08\t\t0.20\t\t0.261\t\t0.807\t\t0.43m - 4.6m / 15.4m                                                                  \n",
      "11\t48k\t0.08\t\t0.23\t\t0.255\t\t0.803\t\t0.43m - 5.1m / 15.4m                                                                  \n",
      "12\t52k\t0.07\t\t0.27\t\t0.239\t\t0.801\t\t0.43m - 5.6m / 15.4m                                                                  \n",
      "13\t56k\t0.06\t\t0.25\t\t0.245\t\t0.814\t\t0.43m - 6.0m / 15.5m                                                                  \n",
      "VAL f1\t0.3115124153498871 - (0.3115124153498871)                                                                       \n",
      "VAL loss\t0.17783869283143863                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.17783869283143863\n",
      "        | \\     )|_\tf1: 0.3115124153498871\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\18      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 29.0, 'clip_comments_to':[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         29                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |            OutputLayerType.Convolutions           |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.07312055271496927                |\n",
      "|  noam_learning_rate_warmup   |                        2773                       |\n",
      "|  noam_learning_rate_factor   |                 3.923626358727649                 |\n",
      "|          adam_beta1          |                 0.9619832255408785                |\n",
      "|          adam_beta2          |                 0.8988030080129403                |\n",
      "|           adam_eps           |               0.00024824133818616127              |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.07019407040441941                |\n",
      "|     pointwise_layer_size     |                        146                        |\n",
      "|      last_layer_dropout      |                 0.1706891086519442                |\n",
      "|   output_conv_num_filters    |                        208                        |\n",
      "|   output_conv_kernel_size    |                         2                         |\n",
      "|      output_conv_stride      |                         3                         |\n",
      "|     output_conv_padding      |                         2                         |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         73                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 19%|███████▉                                  | 19/100 [16:40:37<70:52:04, 3149.69s/it, best loss: 0.1608786659037813]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05c2c43755e4be89e96597964ce260b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t4k\t0.32\t\t0.25\t\t0.214\t\t0.842\t\t0.32m - 0.3m / 0.0m                                                                     \n",
      "2\t9k\t0.27\t\t0.24\t\t0.221\t\t0.823\t\t0.31m - 0.7m / 11.1m                                                                    \n",
      "3\t13k\t0.25\t\t0.24\t\t0.249\t\t0.810\t\t0.31m - 1.0m / 11.1m                                                                   \n",
      "4\t17k\t0.24\t\t0.24\t\t0.252\t\t0.805\t\t0.31m - 1.4m / 11.1m                                                                   \n",
      "5\t22k\t0.24\t\t0.26\t\t0.214\t\t0.789\t\t0.31m - 1.7m / 11.1m                                                                   \n",
      "6\t26k\t0.23\t\t0.28\t\t0.204\t\t0.811\t\t0.31m - 2.1m / 11.0m                                                                   \n",
      "7\t30k\t0.22\t\t0.28\t\t0.262\t\t0.809\t\t0.32m - 2.4m / 11.2m                                                                   \n",
      "8\t35k\t0.22\t\t0.26\t\t0.240\t\t0.804\t\t0.31m - 2.8m / 11.4m                                                                   \n",
      "9\t39k\t0.20\t\t0.25\t\t0.215\t\t0.788\t\t0.31m - 3.2m / 11.3m                                                                   \n",
      "10\t43k\t0.20\t\t0.27\t\t0.234\t\t0.790\t\t0.31m - 3.5m / 11.4m                                                                  \n",
      "11\t48k\t0.18\t\t0.25\t\t0.241\t\t0.788\t\t0.31m - 3.9m / 11.3m                                                                  \n",
      "12\t52k\t0.17\t\t0.27\t\t0.213\t\t0.776\t\t0.31m - 4.2m / 11.4m                                                                  \n",
      "VAL f1\t0.2621145374449339 - (0.2621145374449339)                                                                       \n",
      "VAL loss\t0.24340692744857964                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.24340692744857964\n",
      "        | \\     )|_\tf1: 0.2621145374449339\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Organic_HyperOpt\\20190401\\19      \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 61.0, 'clip_comments_to':[...]lse} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                      entities                     |\n",
      "|          batch_size          |                         61                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |             OutputLayerType.LinearSum             |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               2.5644854050578387e-05              |\n",
      "|  noam_learning_rate_warmup   |                        8613                       |\n",
      "|  noam_learning_rate_factor   |                 2.9606624769178644                |\n",
      "|          adam_beta1          |                 0.7959807348354458                |\n",
      "|          adam_beta2          |                 0.838842687956118                 |\n",
      "|           adam_eps           |               1.4694592958564777e-05              |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                       False                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         4                         |\n",
      "|             d_k              |                         75                        |\n",
      "|             d_v              |                         75                        |\n",
      "|         dropout_rate         |                 0.1653362289431286                |\n",
      "|     pointwise_layer_size     |                        266                        |\n",
      "|      last_layer_dropout      |                0.22571660138553545                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                         47                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                        True                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                        True                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 20%|████████▍                                 | 20/100 [17:31:48<69:28:13, 3126.17s/it, best loss: 0.1608786659037813]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-46c1a1b99a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_optim_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     trials=trials)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         )\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6f09920b1057>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Load dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_logger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not load dataset: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-efa5e5dc13fb>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(rc, logger, task)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0meos_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     )\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(self, loader, custom_preprocessing, verbose)\u001b[0m\n\u001b[0;32m    128\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m \t\t\tself.verbose)\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vocabs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\organic2019.py\u001b[0m in \u001b[0;36morganic_dataset\u001b[1;34m(task, pretrained_vectors, hyperparameters, batch_size, root, train_file, validation_file, test_file, use_cuda, verbose)\u001b[0m\n\u001b[0;32m    143\u001b[0m                                                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                                                                         \u001b[0mhp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m \t\t\t\t\t\t\t\t\ttask=task)\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \t\ttrain, val, test = CustomCommentWiseBioDataset.splits(\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\torchtext\\custom_datasets.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m \t\ttrain_data = None if train is None else cls(\n\u001b[1;32m--> 623\u001b[1;33m \t\t\tos.path.join(path, train), length=lengths[0], **kwargs)\n\u001b[0m\u001b[0;32m    624\u001b[0m                 \u001b[1;31m# make sure, we use exactly the same fields across all splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m                 \u001b[0mtrain_aspects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maspects\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\torchtext\\custom_datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, fields, a_sentiment, separator, task, hp, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                         \u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_sentiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\torchtext\\custom_datasets.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self, path, filename, fields, a_sentiment, separator, verbose, hp, task, length, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m                                 \u001b[0mcomment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_text_cleaner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m                                         \u001b[0mcomment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_cleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m                                 \u001b[0mlast_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\torchtext\\custom_datasets.py\u001b[0m in \u001b[0;36mtext_cleaner\u001b[1;34m(text, language, spellChecker)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_contraction_removal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m         \u001b[0mspacy_nlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m         \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mfinal_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# in data dir / shortcut\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# installed as package\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_link\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE051\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, **overrides)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(self, path, disable)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m             \u001b[0mexclude\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vocab'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m'meta.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             ('vocab', lambda p: (\n\u001b[1;32m--> 635\u001b[1;33m                 self.vocab.from_disk(p) and _fix_pretrained_vectors_name(self))),\n\u001b[0m\u001b[0;32m    636\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         ))\n",
      "\u001b[1;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36m__truediv__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__truediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rtruediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "# domain = base.Domain(test_objective, search_space) \n",
    "\n",
    "best = fmin(objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=num_optim_iterations,\n",
    "    trials=trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Studium\\\\Studium\\\\6. Semester\\\\MA\\\\Project\\\\ABSA-Transformer\\\\logs\\\\Organic_HyperOpt\\\\20190327\\\\0\\\\trials.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(trials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 10), dpi=80)\n",
    "main_plot_history(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [t['result']['loss'] for t in trials.trials if t['result']['status'] == STATUS_OK]\n",
    "range(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(20, 10), dpi=80)\n",
    "fig.suptitle('Loss over time')\n",
    "plt.scatter(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_histogram(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(25, 15), dpi=80)\n",
    "main_plot_vars(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
