{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentiment = 20000\n",
    "def process_df(df, aspect):\n",
    "    df = df.drop(['reviewerID', 'asin', 'reviewerName', 'unixReviewTime', 'reviewTime'], axis=1)\n",
    "        \n",
    "    # add sentiment col\n",
    "    df['sentiment'] = df.apply(process_sentiment, axis=1)\n",
    "    \n",
    "    # balance dataset \n",
    "    df = balance_dataset(df)\n",
    "    \n",
    "    # add aspect col\n",
    "    df['aspect'] = df.apply(lambda r: aspect, axis=1)\n",
    "    return df\n",
    "    \n",
    "def process_sentiment(row):\n",
    "    if row['overall'] >= 4.0:\n",
    "        return 'positive'\n",
    "    if row['overall'] <= 2.0:\n",
    "        return 'negative'\n",
    "    return 'neutral'\n",
    "\n",
    "\n",
    "def balance_dataset(df):\n",
    "    pos_series = df['sentiment']=='positive'\n",
    "    neu_series = df['sentiment']=='neutral'\n",
    "    neg_series = df['sentiment']=='negative'\n",
    "    \n",
    "    pos_diff = df[pos_series]['sentiment'].count() - max_sentiment\n",
    "    neu_diff = df[neu_series]['sentiment'].count() - max_sentiment\n",
    "    neg_diff = df[neg_series]['sentiment'].count() - max_sentiment\n",
    "    \n",
    "    diffs = [pos_diff, neu_diff, neg_diff]\n",
    "    print(diffs)\n",
    "\n",
    "    \n",
    "    # if the sum of all divs is negative, we can not balance the dataset\n",
    "    if sum(diffs) < 0:\n",
    "        print('No balancing possible')\n",
    "        return df\n",
    "    \n",
    "    pos_sel = None\n",
    "    neg_sel = None\n",
    "    neu_sel = None\n",
    "    \n",
    "    remaining = pd.DataFrame()\n",
    "    \n",
    "    # pos has enough \n",
    "    if pos_diff >= 0:\n",
    "        pos_sel = df[pos_series][:max_sentiment]\n",
    "        remaining = remaining.append(df[pos_series][max_sentiment:], ignore_index=True)\n",
    "        print(f'Pos enough: Remaining Count: {remaining[\"overall\"].count()}')\n",
    "    \n",
    "    if neu_diff >= 0:\n",
    "        neu_sel = df[neu_series][:max_sentiment]\n",
    "        remaining = remaining.append(df[neu_series][max_sentiment:], ignore_index=True)\n",
    "        print(f'Neutral enough: Remaining Count: {remaining[\"overall\"].count()}')\n",
    "\n",
    "        \n",
    "    if neg_diff >= 0:\n",
    "        neg_sel = df[neg_series][:max_sentiment]\n",
    "        remaining = remaining.append(df[neg_series][max_sentiment:], ignore_index=True)\n",
    "        print(f'Neg enough: Remaining Count: {remaining[\"overall\"].count()}')\n",
    "\n",
    "    \n",
    "    # pos. has not enough\n",
    "    cur_remaining_idx = 0\n",
    "    if pos_diff < 0:\n",
    "        pos_sel = df[pos_series]\n",
    "        pos_sel = pos_sel.append(remaining[cur_remaining_idx:(-pos_diff)+cur_remaining_idx])\n",
    "        cur_remaining_idx += -pos_diff\n",
    "        print(f'Fill positive - Pos Selection: {pos_sel[\"overall\"].count()} - Remainin Idx: {cur_remaining_idx}')\n",
    "        \n",
    "    if neu_diff < 0:\n",
    "        neu_sel = df[neu_series]\n",
    "        neu_sel = neu_sel.append(remaining[cur_remaining_idx:(-neu_diff)+cur_remaining_idx])\n",
    "        cur_remaining_idx += -neu_diff\n",
    "        print(f'Fill Neutral - Neu Selection: {neu_sel[\"overall\"].count()} - Remainin Idx: {cur_remaining_idx}')\n",
    "\n",
    "        \n",
    "    if neg_diff < 0:\n",
    "        neg_sel = df[neg_series]\n",
    "        neg_sel = neg_sel.append(remaining[cur_remaining_idx:(-neg_diff)+cur_remaining_idx])\n",
    "        cur_remaining_idx += -neg_diff\n",
    "        print(f'Fill Negative - Neg Selection: {neg_sel[\"overall\"].count()} - Remainin Idx: {cur_remaining_idx}')\n",
    "\n",
    "        \n",
    "    df = pos_sel.append(neu_sel).append(neg_sel)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.getcwd(), 'data', 'data', 'amazon')\n",
    "\n",
    "aspects = [\n",
    "    'Apps_for_Android',\n",
    "    'Baby',\n",
    "    'Beauty',\n",
    "    'CDs_and_Vinyl',\n",
    "    'Cell_Phones_and_Accessories',\n",
    "    'Clothing_Shoes_and_Jewelry',\n",
    "    'Digital_Music',\n",
    "    'Electronics',\n",
    "    'Grocery_and_Gourmet_Food',\n",
    "    'Health_and_Personal_Care',\n",
    "    'Home_and_Kitchen',\n",
    "    'Kindle_Store',\n",
    "    'Movies_and_TV',\n",
    "    'Office_Products',\n",
    "    'Pet_Supplies',\n",
    "    'Sports_and_Outdoors',\n",
    "    'Tools_and_Home_Improvement',\n",
    "    'Toys_and_Games',\n",
    "    'Video_Games',\n",
    "    'Books'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc55a9c53f84f08b47ad2ebcb3ecc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Apps_for_Android_5.json.gz\n",
      "[524718, 65121, 103098]\n",
      "Pos enough: Remaining Count: 524718\n",
      "Neutral enough: Remaining Count: 589839\n",
      "Neg enough: Remaining Count: 692937\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Baby_5.json.gz\n",
      "[106525, -2745, -2988]\n",
      "Pos enough: Remaining Count: 106525\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 2745\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 5733\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Beauty_5.json.gz\n",
      "[134272, 2248, 1982]\n",
      "Pos enough: Remaining Count: 134272\n",
      "Neutral enough: Remaining Count: 136520\n",
      "Neg enough: Remaining Count: 138502\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_CDs_and_Vinyl_5.json.gz\n",
      "[883002, 81824, 72766]\n",
      "Pos enough: Remaining Count: 883002\n",
      "Neutral enough: Remaining Count: 964826\n",
      "Neg enough: Remaining Count: 1037592\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Cell_Phones_and_Accessories_5.json.gz\n",
      "[128657, 1439, 4343]\n",
      "Pos enough: Remaining Count: 128657\n",
      "Neutral enough: Remaining Count: 130096\n",
      "Neg enough: Remaining Count: 134439\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Clothing_Shoes_and_Jewelry_5.json.gz\n",
      "[201597, 10425, 6655]\n",
      "Pos enough: Remaining Count: 201597\n",
      "Neutral enough: Remaining Count: 212022\n",
      "Neg enough: Remaining Count: 218677\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Digital_Music_5.json.gz\n",
      "[32116, -13211, -14199]\n",
      "Pos enough: Remaining Count: 32116\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 13211\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 27410\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Electronics_5.json.gz\n",
      "[1336067, 122257, 170864]\n",
      "Pos enough: Remaining Count: 1336067\n",
      "Neutral enough: Remaining Count: 1458324\n",
      "Neg enough: Remaining Count: 1629188\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Grocery_and_Gourmet_Food_5.json.gz\n",
      "[100044, -2486, -6304]\n",
      "Pos enough: Remaining Count: 100044\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 2486\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 8790\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Health_and_Personal_Care_5.json.gz\n",
      "[259801, 13254, 13300]\n",
      "Pos enough: Remaining Count: 259801\n",
      "Neutral enough: Remaining Count: 273055\n",
      "Neg enough: Remaining Count: 286355\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Home_and_Kitchen_5.json.gz\n",
      "[435204, 25059, 31419]\n",
      "Pos enough: Remaining Count: 435204\n",
      "Neutral enough: Remaining Count: 460263\n",
      "Neg enough: Remaining Count: 491682\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Kindle_Store_5.json.gz\n",
      "[809277, 76194, 37148]\n",
      "Pos enough: Remaining Count: 809277\n",
      "Neutral enough: Remaining Count: 885471\n",
      "Neg enough: Remaining Count: 922619\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Movies_and_TV_5.json.gz\n",
      "[1269602, 181302, 186629]\n",
      "Pos enough: Remaining Count: 1269602\n",
      "Neutral enough: Remaining Count: 1450904\n",
      "Neg enough: Remaining Count: 1637533\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Office_Products_5.json.gz\n",
      "[25342, -14940, -17144]\n",
      "No balancing possible\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Pet_Supplies_5.json.gz\n",
      "[104248, -4067, -2345]\n",
      "Pos enough: Remaining Count: 104248\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 4067\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 6412\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Sports_and_Outdoors_5.json.gz\n",
      "[233017, 4071, -751]\n",
      "Pos enough: Remaining Count: 233017\n",
      "Neutral enough: Remaining Count: 237088\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 751\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Tools_and_Home_Improvement_5.json.gz\n",
      "[93602, -9231, -9895]\n",
      "Pos enough: Remaining Count: 93602\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 9231\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 19126\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Toys_and_Games_5.json.gz\n",
      "[120235, -3643, -8995]\n",
      "Pos enough: Remaining Count: 120235\n",
      "Fill Neutral - Neu Selection: 20000 - Remainin Idx: 3643\n",
      "Fill Negative - Neg Selection: 20000 - Remainin Idx: 12638\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Video_Games_5.json.gz\n",
      "[154989, 8275, 8516]\n",
      "Pos enough: Remaining Count: 154989\n",
      "Neutral enough: Remaining Count: 163264\n",
      "Neg enough: Remaining Count: 171780\n",
      "Parse C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\data\\data\\amazon\\reviews_Books_5.json.gz\n",
      "[7183909, 935189, 718943]\n",
      "Pos enough: Remaining Count: 7183909\n",
      "Neutral enough: Remaining Count: 8119098\n",
      "Neg enough: Remaining Count: 8838041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "\n",
    "for a in tqdm(aspects):\n",
    "    fn = f'reviews_{a}_5.json.gz'\n",
    "    path = os.path.join(root_path, fn)\n",
    "    print('Parse ' + path)\n",
    "    \n",
    "    a_df = getDF(path)\n",
    "    a_df = process_df(a_df, a)\n",
    "    a_df.to_pickle(os.path.join(root_path, a + '_processed.pkl'))\n",
    "    if df is None:\n",
    "        df = a_df\n",
    "    else:\n",
    "        df = df.append(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(root_path, 'dataset_processed.csv'))\n",
    "df.to_pickle(os.path.join(root_path, 'dataset_processed.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apps_for_Android</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baby</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDs_and_Vinyl</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_Phones_and_Accessories</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothing_Shoes_and_Jewelry</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital_Music</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronics</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grocery_and_Gourmet_Food</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_and_Personal_Care</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home_and_Kitchen</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kindle_Store</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movies_and_TV</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Office_Products</th>\n",
       "      <td>53258</td>\n",
       "      <td>53258</td>\n",
       "      <td>53258</td>\n",
       "      <td>53258</td>\n",
       "      <td>53258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pet_Supplies</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports_and_Outdoors</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tools_and_Home_Improvement</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toys_and_Games</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video_Games</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             helpful  reviewText  overall  summary  sentiment\n",
       "aspect                                                                       \n",
       "Apps_for_Android               60000       60000    60000    60000      60000\n",
       "Baby                           60000       60000    60000    60000      60000\n",
       "Beauty                         60000       60000    60000    60000      60000\n",
       "Books                          60000       60000    60000    60000      60000\n",
       "CDs_and_Vinyl                  60000       60000    60000    60000      60000\n",
       "Cell_Phones_and_Accessories    60000       60000    60000    60000      60000\n",
       "Clothing_Shoes_and_Jewelry     60000       60000    60000    60000      60000\n",
       "Digital_Music                  60000       60000    60000    60000      60000\n",
       "Electronics                    60000       60000    60000    60000      60000\n",
       "Grocery_and_Gourmet_Food       60000       60000    60000    60000      60000\n",
       "Health_and_Personal_Care       60000       60000    60000    60000      60000\n",
       "Home_and_Kitchen               60000       60000    60000    60000      60000\n",
       "Kindle_Store                   60000       60000    60000    60000      60000\n",
       "Movies_and_TV                  60000       60000    60000    60000      60000\n",
       "Office_Products                53258       53258    53258    53258      53258\n",
       "Pet_Supplies                   60000       60000    60000    60000      60000\n",
       "Sports_and_Outdoors            60000       60000    60000    60000      60000\n",
       "Tools_and_Home_Improvement     60000       60000    60000    60000      60000\n",
       "Toys_and_Games                 60000       60000    60000    60000      60000\n",
       "Video_Games                    60000       60000    60000    60000      60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('aspect').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.sentiment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 80 - 20 - 10 Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'data', 'data', 'amazon')\n",
    "df = pd.read_pickle(os.path.join(path, 'dataset_processed.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42, stratify=df[['aspect']])\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42, stratify=train[['aspect']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18000046930336944"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.count()['overall']/df.count()['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apps_for_Android</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baby</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDs_and_Vinyl</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_Phones_and_Accessories</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothing_Shoes_and_Jewelry</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital_Music</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronics</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grocery_and_Gourmet_Food</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health_and_Personal_Care</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home_and_Kitchen</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kindle_Store</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movies_and_TV</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Office_Products</th>\n",
       "      <td>38345</td>\n",
       "      <td>38345</td>\n",
       "      <td>38345</td>\n",
       "      <td>38345</td>\n",
       "      <td>38345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pet_Supplies</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports_and_Outdoors</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tools_and_Home_Improvement</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toys_and_Games</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video_Games</th>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             helpful  reviewText  overall  summary  sentiment\n",
       "aspect                                                                       \n",
       "Apps_for_Android               43200       43200    43200    43200      43200\n",
       "Baby                           43200       43200    43200    43200      43200\n",
       "Beauty                         43200       43200    43200    43200      43200\n",
       "Books                          43200       43200    43200    43200      43200\n",
       "CDs_and_Vinyl                  43200       43200    43200    43200      43200\n",
       "Cell_Phones_and_Accessories    43200       43200    43200    43200      43200\n",
       "Clothing_Shoes_and_Jewelry     43200       43200    43200    43200      43200\n",
       "Digital_Music                  43200       43200    43200    43200      43200\n",
       "Electronics                    43200       43200    43200    43200      43200\n",
       "Grocery_and_Gourmet_Food       43200       43200    43200    43200      43200\n",
       "Health_and_Personal_Care       43200       43200    43200    43200      43200\n",
       "Home_and_Kitchen               43200       43200    43200    43200      43200\n",
       "Kindle_Store                   43200       43200    43200    43200      43200\n",
       "Movies_and_TV                  43200       43200    43200    43200      43200\n",
       "Office_Products                38345       38345    38345    38345      38345\n",
       "Pet_Supplies                   43200       43200    43200    43200      43200\n",
       "Sports_and_Outdoors            43200       43200    43200    43200      43200\n",
       "Tools_and_Home_Improvement     43200       43200    43200    43200      43200\n",
       "Toys_and_Games                 43200       43200    43200    43200      43200\n",
       "Video_Games                    43200       43200    43200    43200      43200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('aspect').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_path = os.path.join(path, 'splits')\n",
    "train.to_pickle(os.path.join(split_path, 'train.pkl'))\n",
    "test.to_pickle(os.path.join(split_path, 'test.pkl'))\n",
    "val.to_pickle(os.path.join(split_path, 'val.pkl'))\n",
    "\n",
    "train.to_csv(os.path.join(split_path, 'train.csv'))\n",
    "test.to_csv(os.path.join(split_path, 'test.csv'))\n",
    "val.to_csv(os.path.join(split_path, 'val.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing & Spell Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hunspell\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_contraction_removal(text: str) -> str:\n",
    "    apostrophe_handled = re.sub(\"’\", \"'\", text)\n",
    "    # from https://gist.githubusercontent.com/tthustla/74e99a00541264e93c3bee8b2b49e6d8/raw/599100471e8127d6efad446717dc951a10b69777/yatwapart1_01.py\n",
    "    contraction_mapping = {\n",
    "                    \"i.e.\": 'for example',\n",
    "                    \"e.g.\": 'for example',\n",
    "                    \"youre\": \"you are\",\n",
    "                    \"youll\": \"you will\",\n",
    "                    \"theyre\": \"they are\", \"theyll\": \"they will\",\n",
    "                    \"weve\": \"we have\",\n",
    "                    \"shouldnt\": \"should not\",\n",
    "                    \"dont\": \"do not\",\n",
    "                    \"doesnt\": \"does not\", \"doesn\": \"does not\",\n",
    "                    \"didnt\": \"did not\",\n",
    "                    \"wasn\": \"was not\",\n",
    "                    \"arent\": \"are not\", \"aren\": \"are not\",\n",
    "                    \"aint\": \"is not\", \"isnt\": \"is not\", \"isn\": \"is not\",\n",
    "                    \"wouldnt\": \"would not\", \"wouldn\": \"would not\",\n",
    "                    \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "    expanded = ' '.join([contraction_mapping[t.lower()] if t.lower() in contraction_mapping else t for t in apostrophe_handled.split(\" \")])\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobj = hunspell.HunSpell('/Library/Spelling/en_US.dic', '/Library/Spelling/en_US.aff')\n",
    "\n",
    "\n",
    "known_words = ['wirelessly', 'hitman', 'Wal-Mart', 'noob', 'subwoofer', 'WTF', 'Waitrose', '<URL>', 'axe', 'TLDR', 'Coca~Cola', 'NPC', 'sci-fi', 'PS3', 'PSX', 'Clooney', 'Schumacher', 'PS2', 'XBOX']\n",
    "\n",
    "\n",
    "for w in known_words:\n",
    "    hobj.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = r'(?:http(s)?:\\/\\/)?[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&\\(\\)\\*\\+,;=.]+'\n",
    "\n",
    "def replace_urls_regex(sentence: str, url_token: str = '<URL>') -> str:\n",
    "    return re.sub(url_regex, url_token, sentence)\n",
    "\n",
    "def replace_urls(words, url_token: str = '<URL>'):\n",
    "    return [url_token if (w.lower().startswith('www') or w.lower().startswith('http')) else w for w in words]\n",
    "\n",
    "def spellcheck_sentence(row) -> str:\n",
    "    sent = row['reviewText']\n",
    "    #print(sent)\n",
    "    to_remove = [',', '(', ')', ':', '?', '&', '/', '*', '!']\n",
    "    for tr in to_remove:\n",
    "        sent = sent.replace(tr, ' ')\n",
    "        \n",
    "    sent = sent.replace('€™', \"'\")\n",
    "    sent = sent.replace('�', \"'\")\n",
    "    sent = en_contraction_removal(sent)\n",
    "    sent = sent.replace(\"'\", ' ')\n",
    "    sent = replace_urls_regex(sent)\n",
    "\n",
    "\n",
    "    tokens = sent.split(' ')\n",
    "    result = []\n",
    "    for t in tokens:\n",
    "        if t == ' ':\n",
    "            continue\n",
    "        if not hobj.spell(t):\n",
    "            suggestions = hobj.suggest(t)\n",
    "            if not suggestions:\n",
    "                result.append(t)\n",
    "            else:\n",
    "                if suggestions[0] == 'e':\n",
    "                    result.append(t)\n",
    "                    continue\n",
    "                result.append(suggestions[0])\n",
    "                #print(f'{t} -> {suggestions[0]}')\n",
    "        else:\n",
    "            result.append(t)\n",
    "    return ' '.join(result)\n",
    "        \n",
    "#spellcheck_sentence('This is a tset with a wong wod. Adn now anotheer one why does this notjn workd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0066550ad7114f5badcffe0f62d3b724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=859145), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = ['train', 'val', 'test']\n",
    "path = os.path.join(os.getcwd(), 'data', 'data', 'amazon')\n",
    "tqdm.pandas()\n",
    "\n",
    "for s in splits:\n",
    "    print('Split: ' + str(s))\n",
    "    fn = os.path.join(path, s + '.pkl')\n",
    "    df = pd.read_pickle(fn)\n",
    "    df['reviewText'] = df.progress_apply(spellcheck_sentence, axis=1)\n",
    "    \n",
    "    fn = os.path.join(path, s + '_sp.pkl')\n",
    "    df.to_pkl(fn)\n",
    "    df.to_csv(os.path.join(path, s + '_sp.csv'), sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
