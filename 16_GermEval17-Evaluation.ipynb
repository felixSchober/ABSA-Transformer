{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'n/a'),\n",
       " ('a', 'neg'),\n",
       " ('a', 'pos'),\n",
       " ('a', 'neu'),\n",
       " ('b', 'n/a'),\n",
       " ('b', 'neg'),\n",
       " ('b', 'pos'),\n",
       " ('b', 'neu')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_gold_combinations(classes, sentiments):\n",
    "    r = []\n",
    "    for c in classes:\n",
    "        for s in sentiments:\n",
    "            r.append((c, s))\n",
    "            \n",
    "    return r\n",
    "create_gold_combinations(['a', 'b'], ['n/a', 'neg', 'pos', 'neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'def create_eval_entries_from_gold_and_predictions(golds, predictions):\n",
    "#     eval_entries = []\n",
    "#     for gold_doc, pred_doc in zip(golds, predictions):\n",
    "#         # only works for the small example where only sentiment is misclassified\n",
    "#         for (g_cls, g_sent), (p_cls, p_sent) in zip(gold_doc, pred_doc):\n",
    "#             if g_cls\n",
    "#         eval_entries.extend(zip(gold_doc, pred_doc))\n",
    "#     return eval_entries\n",
    "\n",
    "# golds = [\n",
    "#     [ # Doc 1\n",
    "#         ('a', 'neg'),\n",
    "#     ], \n",
    "#     [ # Doc 2\n",
    "#         ('a', 'pos'),\n",
    "#         ('b', 'pos')\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# predictions = [\n",
    "#     [ # Doc 1\n",
    "#         ('a', 'neg'),\n",
    "#     ], \n",
    "#     [ # Doc 2\n",
    "#         ('a', 'pos'),\n",
    "#         ('b', 'negative')\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# eval_entries = create_eval_entries_from_gold_and_predictions(golds, predictions)\n",
    "\n",
    "# eval_entries'\n",
    "eval_entries = [\n",
    "    (('a', 'neu'),('a', 'neu')),\n",
    "    (('a', 'neu'), ('a', 'neu')),\n",
    "    (('b', 'neu'), ('b', 'n/a')),\n",
    "    (('b', 'n/a'), ('b', 'pos'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_metrics(classes, sentiments, eval_entries):\n",
    "    combinations = create_gold_combinations(classes, sentiments)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for cls, sent in combinations:\n",
    "        for (g_cls, g_sent), (p_cls, p_sent) in eval_entries:\n",
    "            if g_cls == cls and g_sent == sent:\n",
    "                if g_cls == p_cls and g_sent == p_sent:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            else:\n",
    "                if p_cls == cls and p_sent == sent:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "                    \n",
    "    return (tp, fp, fn, tn)\n",
    "\n",
    "get_metrics(['a', 'b'], ['n/a', 'neg', 'pos', 'neu'], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_micro_f1(classes, sentiments, eval_entries):\n",
    "    tp, fp, fn, _ = get_metrics(classes, sentiments, eval_entries)\n",
    "    micro_precission = tp / (tp + fp)\n",
    "    micro_recall = tp / (tp + fn)\n",
    "    micro_f1 = 2.0 * micro_precission * micro_recall / (micro_precission + micro_recall)\n",
    "    return micro_f1\n",
    "\n",
    "calculate_micro_f1(['a', 'b'], ['n/a', 'neg', 'pos', 'neu'], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adaption to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION:\n",
      "tensor([[0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.]])\n",
      "\n",
      "\n",
      "TARGET:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "\n",
    "target = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# per aspect\n",
    "target = torch.t(target)\n",
    "prediction = torch.t(prediction)\n",
    "print('PREDICTION:\\n' + str(prediction))\n",
    "print('\\n\\nTARGET:\\n' + str(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Samples\n",
      "Aspect 0 -\t tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Aspect 1 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 2 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 3 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 4 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 5 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 6 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 7 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 8 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 9 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 10 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 11 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 12 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 13 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 14 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 15 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 16 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.])\n",
      "Aspect 17 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 18 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Aspect 19 -\t tensor([0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t Samples')\n",
    "for i, aspect in enumerate(prediction):\n",
    "    print(f'Aspect {i} -\\t {aspect}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 Target:\ttensor([1., 1.])\n",
      "0 Prediction\ttensor([1., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((0, tensor(1.)), (0, tensor(1.))), ((0, tensor(1.)), (0, tensor(1.)))]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tensor_eval_entries(prediction, target):\n",
    "    eval_entries = []\n",
    "    # (('a', 'neu'),('a', 'neu')),\n",
    "    for aspect_index, (prediction_aspect, target_aspect) in enumerate(zip(prediction, target)):\n",
    "        print(f'\\n{aspect_index} Target:\\t{target_aspect}\\n{aspect_index} Prediction\\t{prediction_aspect}')\n",
    "\n",
    "        for y_hat, y in zip(prediction_aspect, target_aspect):\n",
    "                # y is applicable\n",
    "                if y != y_hat and y > 0:\n",
    "                    eval_entries.append(((aspect_index, y), (aspect_index, 0)))\n",
    "\n",
    "                    if y_hat > 0:\n",
    "                        eval_entries.append(((aspect_index, 0), (aspect_index, y_hat)))\n",
    "\n",
    "                elif y == y_hat and y > 0:\n",
    "                    eval_entries.append(((aspect_index, y), (aspect_index, y_hat)))\n",
    "    return eval_entries\n",
    "eval_entries = get_tensor_eval_entries(prediction, target)\n",
    "eval_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 0, 150)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(range(19), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_micro_f1(range(19), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check with example from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two samples, Two apsects\n",
    "\n",
    "#### GOLD\n",
    "```xml\n",
    "<Documents>\n",
    "    <Document id=\"1\">\n",
    "        <Opinions>\n",
    "            <Opinion category=\"Allgemein\" polarity=\"neutral\"/>\n",
    "        </Opinions>\n",
    "        <text>COMMENT</text>\n",
    "    </Document>\n",
    "    <Document id=\"2\">\n",
    "        <Opinions>\n",
    "            <Opinion category=\"Allgemein\" polarity=\"neutral\"/>\n",
    "\t\t\t<Opinion category=\"Ticketkauf\" polarity=\"neutral\"/>\n",
    "        </Opinions>\n",
    "        <text>COMMENT</text>\n",
    "    </Document>\n",
    "</Documents>\n",
    "```\n",
    "\n",
    "#### Prediction\n",
    "```xml\n",
    "<Documents>\n",
    "    <Document id=\"1\">\n",
    "        <Opinions>\n",
    "            <Opinion category=\"Allgemein\" polarity=\"neutral\"/>\n",
    "        </Opinions>\n",
    "        <text>COMMENT</text>\n",
    "    </Document>\n",
    "    <Document id=\"2\">\n",
    "        <Opinions>\n",
    "            <Opinion category=\"Allgemein\" polarity=\"neutral\"/>\n",
    "\t\t\t<Opinion category=\"Ticketkauf\" polarity=\"positive\"/>\n",
    "        </Opinions>\n",
    "        <text>COMMENT</text>\n",
    "    </Document>\n",
    "</Documents>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION:\n",
      "tensor([[1., 1.],\n",
      "        [0., 2.]])\n",
      "\n",
      "\n",
      "TARGET:\n",
      "tensor([[1., 1.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor(\n",
    "       [[1., 1.], # aspect a\n",
    "        [0., 1.]  # aspect b\n",
    "       ])\n",
    "\n",
    "prediction = torch.tensor(\n",
    "       [[1., 1.], # aspect a\n",
    "        [0., 2.]  # aspect b\n",
    "       ])\n",
    "\n",
    "\n",
    "# per aspect\n",
    "print('PREDICTION:\\n' + str(prediction))\n",
    "print('\\n\\nTARGET:\\n' + str(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 Target:\ttensor([1., 1.])\n",
      "0 Prediction\ttensor([1., 1.])\n",
      "\n",
      "1 Target:\ttensor([0., 1.])\n",
      "1 Prediction\ttensor([0., 2.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((0, tensor(1.)), (0, tensor(1.))),\n",
       " ((0, tensor(1.)), (0, tensor(1.))),\n",
       " ((1, tensor(1.)), (1, 0)),\n",
       " ((1, 0), (1, tensor(2.)))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_entries = get_tensor_eval_entries(prediction, target)\n",
    "eval_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 26)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(range(2), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_micro_f1(range(19), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only affecting one aspect at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 Target:\ttensor([1., 1.])\n",
      "0 Prediction\ttensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor(\n",
    "       [[1., 1.], # aspect a\n",
    "       ])\n",
    "\n",
    "prediction = torch.tensor(\n",
    "       [[1., 1.], # aspect a\n",
    "       ])\n",
    "eval_entries = get_tensor_eval_entries(prediction, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 0, 150)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(range(19), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 Target:\ttensor([0., 1.])\n",
      "0 Prediction\ttensor([0., 2.])\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor([[0., 1.]])\n",
    "\n",
    "prediction = torch.tensor([[0., 2.]])\n",
    "eval_entries = get_tensor_eval_entries(prediction, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 2, 148)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(range(19), [0, 1, 2, 3], eval_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
