{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\Anaconda3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from data.data_loader import Dataset\n",
    "from data.germeval2017 import germeval2017_dataset\n",
    "\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.visualizer import *\n",
    "from misc.run_configuration import get_default_params\n",
    "from misc import utils\n",
    "\n",
    "from optimizer import get_default_optimizer\n",
    "from criterion import NllLoss\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.softmax_output import SoftmaxOutputLayer, OutputLayer, SoftmaxOutputLayerWithCommentWiseClass\n",
    "from models.transformer_tagger import TransformerTagger\n",
    "from models.transformer.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'FastText'\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'a38d191'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_current_git_commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\FastText\n"
     ]
    }
   ],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/germeval2017',\n",
    "    data_train='train_v1.4.tsv',    \n",
    "    data_validation='dev_v1.4.tsv',\n",
    "    data_test='test_TIMESTAMP1.tsv',\n",
    "    early_stopping='highest_5_F1'\n",
    ")\n",
    "\n",
    "hyperparameters = get_default_params()\n",
    "hyperparameters.model_size = 300\n",
    "hyperparameters.batch_size = 12\n",
    "hyperparameters.num_encoder_blocks = 4\n",
    "hyperparameters.early_stopping = -1\n",
    "hyperparameters.use_cuda = use_cuda\n",
    "hyperparameters.language = 'de'\n",
    "hyperparameters.num_epochs = 25\n",
    "hyperparameters.log_every_xth_iteration = -1\n",
    "hyperparameters.embedding_type = 'fasttext'\n",
    "\n",
    "experiment_name = utils.create_loggers(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da02daa560154a92a4605ce61a2752cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loading finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d493a4b8a8af413f9ac599eb3561b63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c326ab194e44bfa9572029d95896046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------+\n",
      "|  GERM EVAL 2017 DATASET |\n",
      "+---------------+---------+\n",
      "|     Split     |   Size  |\n",
      "+---------------+---------+\n",
      "|     train     |  17043  |\n",
      "|   validation  |   2049  |\n",
      "|      test     |   2095  |\n",
      "+---------------+---------+\n",
      "+--------------------------------------+\n",
      "|           Vocabulary Stats           |\n",
      "+------------------------------+-------+\n",
      "|          Vocabulary          |  Size |\n",
      "+------------------------------+-------+\n",
      "|           comments           | 95112 |\n",
      "|      general_sentiments      |   3   |\n",
      "|           padding            | 33785 |\n",
      "|          Sicherheit          |   4   |\n",
      "|        Informationen         |   4   |\n",
      "|            Image             |   4   |\n",
      "|          Toiletten           |   4   |\n",
      "| Service_und_Kundenbetreuung  |   4   |\n",
      "|      DB_App_und_Website      |   4   |\n",
      "|   Gastronomisches_Angebot    |   4   |\n",
      "|            Gepäck            |   4   |\n",
      "|          Atmosphäre          |   4   |\n",
      "|           QR-Code            |   3   |\n",
      "|            Design            |   4   |\n",
      "|      Reisen_mit_Kindern      |   4   |\n",
      "| Auslastung_und_Platzangebot  |   4   |\n",
      "|          Allgemein           |   4   |\n",
      "|   Komfort_und_Ausstattung    |   4   |\n",
      "|           Zugfahrt           |   4   |\n",
      "|       Barrierefreiheit       |   4   |\n",
      "|          Ticketkauf          |   4   |\n",
      "| Sonstige_Unregelmässigkeiten |   4   |\n",
      "|         Connectivity         |   4   |\n",
      "+------------------------------+-------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------+\n",
      "|                      general_sentiments                      |\n",
      "+----------+---------+--------------------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |    Class Weight    |\n",
      "+----------+---------+--------------------+--------------------+\n",
      "| neutral  |  10599  | 62.18975532476677  | 0.3781024467523323 |\n",
      "| positive |   1216  | 7.1348940914158305 | 0.9286510590858417 |\n",
      "| negative |   5228  |  30.6753505838174  | 0.6932464941618259 |\n",
      "|   Sum    |  17043  |                    |        1.0         |\n",
      "+----------+---------+--------------------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                            Sicherheit                           |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight    |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|          |  20611  |   97.2813517723132   | 0.02718648227686793 |\n",
      "| negative |   542   |  2.558172464246944   |  0.9744182753575306 |\n",
      "| positive |    22   | 0.10383725869637041  |  0.9989616274130363 |\n",
      "| neutral  |    12   | 0.056638504743474774 |  0.9994336149525652 |\n",
      "|   Sum    |  21187  |                      |         1.0         |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                          Informationen                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  20765  |   98.0082125831878  | 0.019917874168121963 |\n",
      "| positive |    51   |  0.2407136451597678 |  0.9975928635484024  |\n",
      "| negative |   285   |  1.345164487657526  |  0.9865483551234248  |\n",
      "| neutral  |    86   | 0.40590928399490256 |  0.995940907160051   |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                              Image                              |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  21129  |   99.7262472270732  | 0.002737527729267941 |\n",
      "| negative |    34   | 0.16047576343984518 |  0.9983952423656015  |\n",
      "| positive |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "| neutral  |    14   |  0.0660782555340539 |  0.9993392174446595  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                           Toiletten                            |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |    Class Weight    |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|          |  21131  |  99.73568697786378   | 0.0026431302213622 |\n",
      "| negative |    41   | 0.19351489120687212  | 0.9980648510879313 |\n",
      "| neutral  |    13   | 0.06135838013876433  | 0.9993864161986123 |\n",
      "| positive |    2    | 0.009439750790579128 | 0.9999056024920943 |\n",
      "|   Sum    |  21187  |                      |        1.0         |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                  Service_und_Kundenbetreuung                  |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|          |  20589  | 97.17751451361684  | 0.02822485486383164 |\n",
      "| negative |   388   | 1.831311653372351  |  0.9816868834662765 |\n",
      "| positive |   146   | 0.6891018077122764 |  0.9931089819228772 |\n",
      "| neutral  |    64   | 0.3020720252985321 |  0.9969792797470147 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                        DB_App_und_Website                       |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  20951  |  98.88610940671167  | 0.011138905932883358 |\n",
      "| positive |    41   | 0.19351489120687212 |  0.9980648510879313  |\n",
      "| negative |   134   |  0.6324633029688016 |  0.993675366970312   |\n",
      "| neutral  |    61   |  0.2879123991126634 |  0.9971208760088733  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                     Gastronomisches_Angebot                      |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |      Class Weight     |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|          |  21136  |  99.75928635484024  | 0.0024071364515976246 |\n",
      "| negative |    32   | 0.15103601264926605 |   0.9984896398735074  |\n",
      "| neutral  |    10   | 0.04719875395289565 |   0.9995280124604711  |\n",
      "| positive |    9    | 0.04247887855760608 |   0.9995752112144239  |\n",
      "|   Sum    |  21187  |                     |          1.0          |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Gepäck                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|          |  21164  |  99.89144286590835   | 0.0010855713409165801 |\n",
      "| neutral  |    10   | 0.04719875395289565  |   0.9995280124604711  |\n",
      "| negative |    12   | 0.056638504743474774 |   0.9994336149525652  |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Atmosphäre                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|          |  19854  | 93.70840609807901  | 0.06291593901920989 |\n",
      "| negative |   1035  | 4.8850710341246995 |  0.951149289658753  |\n",
      "| positive |   133   | 0.6277434275735121 |  0.9937225657242649 |\n",
      "| neutral  |   165   | 0.7787794402227781 |  0.9922122055977722 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                              QR-Code                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|          |  21185  |  99.99056024920942   | 9.439750790574131e-05 |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "| neutral  |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Design                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|          |  21148  |   99.8159248595837   | 0.0018407514041629547 |\n",
      "| negative |    18   | 0.08495775711521215  |   0.9991504224288479  |\n",
      "| positive |    19   | 0.08967763251050172  |   0.999103223674895   |\n",
      "| neutral  |    2    | 0.009439750790579128 |   0.9999056024920943  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                        Reisen_mit_Kindern                        |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight     |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|          |  21132  |  99.74040685325907   | 0.002595931467409218 |\n",
      "| positive |    8    | 0.037759003162316514 |  0.9996224099683768  |\n",
      "| neutral  |    17   | 0.08023788171992259  |  0.9991976211828008  |\n",
      "| negative |    30   | 0.14159626185868693  |  0.9985840373814131  |\n",
      "|   Sum    |  21187  |                      |         1.0          |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                   Auslastung_und_Platzangebot                   |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  20868  |  98.49435974890262  | 0.015056402510973732 |\n",
      "| negative |   261   |  1.2318874781705764 |  0.9876811252182942  |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| neutral  |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------+\n",
      "|                          Allgemein                           |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy  |     Class Weight    |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "| neutral  |  12308  | 58.09222636522395 | 0.41907773634776047 |\n",
      "|          |   6176  | 29.14995044130835 |  0.7085004955869165 |\n",
      "| negative |   1922  | 9.071600509746542 |  0.9092839949025345 |\n",
      "| positive |   781   |  3.68622268372115 |  0.9631377731627885 |\n",
      "|   Sum    |  21187  |                   |         1.0         |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                     Komfort_und_Ausstattung                     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  20989  |  99.06546467173266  | 0.009345353282673385 |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| negative |   117   |  0.5522254212488791 |  0.9944777457875112  |\n",
      "| neutral  |    33   | 0.15575588804455562 |  0.9984424411195545  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                            Zugfahrt                           |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|          |  18958  | 89.47939774389955  | 0.10520602256100442 |\n",
      "| positive |   371   | 1.7510737716524283 |  0.9824892622834758 |\n",
      "| negative |   1706  | 8.052107424363996  |   0.91947892575636  |\n",
      "| neutral  |   152   | 0.7174210600840137 |  0.9928257893991599 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                         Barrierefreiheit                        |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  21097  |  99.57521121442394  | 0.004247887855760579 |\n",
      "| positive |    20   |  0.0943975079057913 |  0.999056024920942   |\n",
      "| neutral  |    16   | 0.07551800632463303 |  0.9992448199367536  |\n",
      "| negative |    54   |  0.2548732713456365 |  0.9974512672865437  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Ticketkauf                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|          |  20429  |  96.4223344503705  | 0.03577665549629494 |\n",
      "| negative |   505   | 2.3835370746212297 |  0.9761646292537877 |\n",
      "| neutral  |   137   | 0.6466229291546703 |  0.9935337707084533 |\n",
      "| positive |   116   | 0.5475055458535895 |  0.9945249445414641 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                  Sonstige_Unregelmässigkeiten                  |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|          |  19483  |  91.95733232642658  | 0.08042667673573423 |\n",
      "| negative |   1582  |  7.4668428753480915 |  0.9253315712465191 |\n",
      "| positive |    49   | 0.23127389436918866 |  0.9976872610563081 |\n",
      "| neutral  |    73   |  0.3445509038561382 |  0.9965544909614387 |\n",
      "|   Sum    |  21187  |                     |         1.0         |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                           Connectivity                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|          |  20871  |   98.5085193750885  | 0.014914806249115009 |\n",
      "| positive |    69   |  0.3256714022749799 |  0.9967432859772501  |\n",
      "| negative |   197   |  0.9298154528720441 |  0.9907018454712796  |\n",
      "| neutral  |    50   | 0.23599376976447822 |  0.9976400623023552  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    'germeval',\n",
    "    logging.getLogger('data_loaoder'),\n",
    "    hyperparameters,\n",
    "    source_index=0,\n",
    "    target_vocab_index=1,\n",
    "    data_path=PREFERENCES.data_root,\n",
    "    train_file=PREFERENCES.data_train,\n",
    "    valid_file=PREFERENCES.data_validation,\n",
    "    test_file=PREFERENCES.data_test,\n",
    "    file_format='.tsv',\n",
    "    init_token=None,\n",
    "    eos_token=None\n",
    ")\n",
    "dataset.load_data(germeval2017_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3781024467523323, 0.6932464941618259, 0.9286510590858417]\n",
      "['neutral', 'negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.class_weights)\n",
    "print(dataset.class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = NllLoss(dataset.target_size, dataset.class_weights)\n",
    "transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                 hyperparameters=hyperparameters)\n",
    "tagging_softmax = SoftmaxOutputLayerWithCommentWiseClass(hyperparameters.model_size, dataset.target_size)\n",
    "model = TransformerTagger(transformer, tagging_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - TransformerTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(95112, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((95112, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=31720096\n",
      "  (taggingLayer): SoftmaxOutputLayerWithCommentWiseClass(\n",
      "    (output_projection): Linear(in_features=300, out_features=3, bias=True)\n",
      "  ), weights=((3, 300), (3,)), parameters=903\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 31.720.999\n",
      "==================================\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1              [-1, 42, 300]      28,533,600\n",
      "           Dropout-2              [-1, 42, 300]               0\n",
      "PositionalEncoding2-3              [-1, 42, 300]               0\n",
      "            Linear-4              [-1, 42, 300]          90,000\n",
      "            Linear-5              [-1, 42, 300]          90,000\n",
      "            Linear-6              [-1, 42, 300]          90,000\n",
      "           Dropout-7               [-1, 42, 42]               0\n",
      "ScaledDotProductAttentionLayer-8              [-1, 42, 100]               0\n",
      "            Linear-9              [-1, 42, 300]          90,000\n",
      "          Dropout-10              [-1, 42, 300]               0\n",
      "        LayerNorm-11              [-1, 42, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-12              [-1, 42, 300]               0\n",
      "           Linear-13             [-1, 42, 2048]         616,448\n",
      "           Linear-14              [-1, 42, 300]         614,700\n",
      "          Dropout-15              [-1, 42, 300]               0\n",
      "        LayerNorm-16              [-1, 42, 300]               0\n",
      "     EncoderBlock-17              [-1, 42, 300]               0\n",
      "           Linear-18              [-1, 42, 300]          90,000\n",
      "           Linear-19              [-1, 42, 300]          90,000\n",
      "           Linear-20              [-1, 42, 300]          90,000\n",
      "          Dropout-21               [-1, 42, 42]               0\n",
      "ScaledDotProductAttentionLayer-22              [-1, 42, 100]               0\n",
      "           Linear-23              [-1, 42, 300]          90,000\n",
      "          Dropout-24              [-1, 42, 300]               0\n",
      "        LayerNorm-25              [-1, 42, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-26              [-1, 42, 300]               0\n",
      "           Linear-27             [-1, 42, 2048]         616,448\n",
      "           Linear-28              [-1, 42, 300]         614,700\n",
      "          Dropout-29              [-1, 42, 300]               0\n",
      "        LayerNorm-30              [-1, 42, 300]               0\n",
      "     EncoderBlock-31              [-1, 42, 300]               0\n",
      "TransformerEncoder-32              [-1, 42, 300]               0\n",
      "           Linear-33                [-1, 42, 3]             903\n",
      "SoftmaxOutputLayerWithCommentWiseClass-34                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 31,716,799\n",
      "Trainable params: 31,716,799\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.90\n",
      "Params size (MB): 120.99\n",
      "Estimated Total Size (MB): 124.89\n",
      "----------------------------------------------------------------\n",
      "pre_training - INFO - TransformerTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(95112, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((95112, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=31720096\n",
      "  (taggingLayer): SoftmaxOutputLayerWithCommentWiseClass(\n",
      "    (output_projection): Linear(in_features=300, out_features=3, bias=True)\n",
      "  ), weights=((3, 300), (3,)), parameters=903\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 31.720.999\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pre_training - INFO - Classes: ['neutral', 'negative', 'positive']\n",
      "pre_training - INFO - Tensorboard enabled. Run will be located at /runs/FastText/20190123/15/0/. Full path is C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\runs\\FastText\\20190123\\15EP\\0\n"
     ]
    }
   ],
   "source": [
    "hyperparameters.num_epochs = 15\n",
    "\n",
    "optimizer = get_default_optimizer(model, hyperparameters)\n",
    "trainer = Trainer(\n",
    "                    model,\n",
    "                    loss,\n",
    "                    optimizer,\n",
    "                    hyperparameters,\n",
    "                    dataset,\n",
    "                    experiment_name,\n",
    "                    enable_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - DEBUG - train with cuda support\n",
      "pre_training - INFO - 1421 Iterations per epoch with batch size of 12\n",
      "pre_training - INFO - START training.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c64d5582ca447286df7349163d1041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e484c6f4cb5430d87d7d2b4f244373a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time\n",
      "1\t1421\t97.483\t\t25.229\t\t0.301\t\t0.301\t\t4.19m - 4.2m / 0.0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e948efd378c9447383ff8971afaeefea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be954848750249848556967ebac2e5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t2842\t25.751\t\t1.971\t\t0.646\t\t0.646\t\t4.25m - 8.5m / 62.8m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cdc6f990214d7fb3b31326a4cec76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99b0cb2bb9749dab98422392ec333ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t4263\t9.144\t\t0.952\t\t0.597\t\t0.597\t\t4.16m - 12.8m / 63.9m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c083822b7e504d29a4663f0fdba37a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5b2f01fdbc48cbbdf5157cd2f96aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t5684\t5.608\t\t1.047\t\t0.612\t\t0.612\t\t4.38m - 17.5m / 63.0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa2e351a16944128f516f5219bcaa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c20fdad844643a2a315fc0b64dcfe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t7105\t2.324\t\t1.054\t\t0.590\t\t0.590\t\t4.08m - 21.7m / 65.8m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cdabd87dd14d41a74fe71cbcd8985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d37f407e3d4f1081dc7d45295413fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t8526\t1.122\t\t0.970\t\t0.644\t\t0.644\t\t4.06m - 26.0m / 62.7m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262a423d06bd4761bce40052e0b4b40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12c5fd1805741c595ccfc8f99f435a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t9947\t0.691\t\t0.984\t\t0.665\t\t0.665\t\t4.19m - 30.5m / 62.8m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15383111cac4d27a37c42890b042a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd9966578ce4361804d27c7b7a77e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t11368\t0.565\t\t0.957\t\t0.676\t\t0.676\t\t4.17m - 34.6m / 64.0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eceb281c1d43628e1b7679e706328d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918ac05336144c8c9cab57c5872b1958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t12789\t0.466\t\t0.959\t\t0.564\t\t0.564\t\t4.19m - 38.9m / 63.8m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9004e64c8bf94687b454d4126d37cfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca605821368140fcada172c214365a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\t14210\t0.382\t\t1.076\t\t0.530\t\t0.530\t\t4.32m - 43.4m / 64.2m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8635edf19744099cb814c61f8ca7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9708e403da4740e7a66a3d0a05250ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\t15631\t0.350\t\t1.039\t\t0.680\t\t0.680\t\t4.19m - 47.6m / 65.0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d811e36dddb4c4499fd4139477ebfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6dfa8176d44cd3bd3e428f9dc47b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\t17052\t0.309\t\t1.040\t\t0.667\t\t0.667\t\t4.26m - 51.9m / 64.5m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d2197be51d4bb1aa6dd1b5e12a4079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7738120f4241eba6857b373edfccfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\t18473\t0.278\t\t1.168\t\t0.656\t\t0.656\t\t4.14m - 56.1m / 64.8m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ba166983b34a35a68cd3c8366007f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f722ada4be24082909bb9e8c9ff6775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\t19894\t0.275\t\t1.109\t\t0.594\t\t0.594\t\t4.21m - 60.5m / 64.5m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc37716f9d0b47959bb772bbbaf41143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80e71f441d74142a5594f8d7dc26074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\t21315\t0.238\t\t1.114\t\t0.713\t\t0.713\t\t4.22m - 64.9m / 64.9m\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train(use_cuda=hyperparameters.use_cuda, perform_evaluation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = result['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_labels = trainer.classify_sentence('I was born in 1993 in Stuttgart')\n",
    "\n",
    "\n",
    "\n",
    "print(result_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = trainer.text_reverser[1]\n",
    "lr = trainer.label_reverser\n",
    "\n",
    "test_sentence = ['china', 'controlled', 'most', 'of', 'the', 'match']\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = tr.preprocess('Die Bahn ist nicht gut')\n",
    "\n",
    "#test_sentence = tr.preprocess('china controlled most of the match on 1993')\n",
    "test_sentence = [x.strip(' ') for x in test_sentence]\n",
    "test_sentence = [test_sentence]\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#test = tr.preprocess('china controlled most of the match')\n",
    "#print(test)\n",
    "\n",
    "#test_sentence = [['china', 'controlled', 'most', 'of', 'the', 'match']]\n",
    "x = tr.process(test_sentence)\n",
    "\n",
    "print(\"X TENSOR \",x)\n",
    "print('X Size', x.size())\n",
    "print(\"Reversed X\", tr.reverse(x))\n",
    "x = x.cuda()\n",
    "y_hat = model.predict(x)\n",
    "y_hat_label = lr.reverse(y_hat)\n",
    "print(y_hat_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.tb_writer = None\n",
    "trainer.enable_tensorboard = False\n",
    "evaluation_results = trainer.perform_final_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_matrix = evaluation_results[1][2]\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(c_matrix, class_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(c_matrix, dataset.class_labels, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict now to see model in final state\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df = predict_some_examples_to_df(model, conll2003['iters'][2], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = predict_some_examples_to_df(model, conll2003['iters'][1], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = predict_some_examples_to_df(model, conll2003['iters'][0], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([\n",
    "    np.array([[1, 1], [1, 1]]),\n",
    "    np.array([[2, 2], [-2, -3]])\n",
    "])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = predict_some_examples_to_df(model, test_sample_iter)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(tr_loss, tr_f1) = result['result_train']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
