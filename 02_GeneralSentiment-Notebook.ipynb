{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from data.data_loader import Dataset\n",
    "from data.germeval2017 import germeval2017_dataset\n",
    "\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.visualizer import *\n",
    "from misc.run_configuration import get_default_params\n",
    "from misc import utils\n",
    "\n",
    "from optimizer import get_default_optimizer\n",
    "from criterion import NllLoss\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.softmax_output import SoftmaxOutputLayer, OutputLayer, SoftmaxOutputLayerWithCommentWiseClass\n",
    "from models.transformer_tagger import TransformerTagger\n",
    "from models.transformer.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '04generalSentimentStdModel5Ep'\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  /Users/felix/Documents/Repositories/TUM/ABSA-Transformer/logs/04generalSentimentStdModel5Ep\n"
     ]
    }
   ],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/germeval2017',\n",
    "    data_train='train_v1.4.tsv',    \n",
    "    data_validation='dev_v1.4.tsv',\n",
    "    data_test='test_TIMESTAMP1.tsv',\n",
    "    early_stopping='highest_5_F1'\n",
    ")\n",
    "\n",
    "hyperparameters = get_default_params()\n",
    "hyperparameters.model_size = 300\n",
    "hyperparameters.batch_size = 80\n",
    "hyperparameters.early_stopping = -1\n",
    "hyperparameters.use_cuda = use_cuda\n",
    "hyperparameters.language = 'de'\n",
    "hyperparameters.num_epochs = 25\n",
    "hyperparameters.log_every_xth_iteration = -1\n",
    "\n",
    "experiment_name = utils.create_loggers(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - Getting glove with dimension 300\n",
      "pre_training - INFO - Word vectors successfully loaded.\n",
      "pre_training - DEBUG - Start loading dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545d524577754767a7ab68daa2d01327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Load train_v', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loading finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba0056f0d344c608960a0ab1cae9ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Load dev_v1.', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6bd64f0e2d42a8896ed539af0ceece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Load test_TI', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pre_training - INFO - +-------------------------------------------------------------------------------------+\n",
      "|                                     Data Loader                                     |\n",
      "+---------------------------------+---------------------------------------------------+\n",
      "|            Parameter            |                       Value                       |\n",
      "+---------------------------------+---------------------------------------------------+\n",
      "|            embedding            |           (Embedding(95161, 300), None)           |\n",
      "|            train_iter           | <torchtext.data.iterator.BucketIterator [...]f60> |\n",
      "|            valid_iter           | <torchtext.data.iterator.BucketIterator [...]cf8> |\n",
      "|            test_iter            | <torchtext.data.iterator.BucketIterator [...]588> |\n",
      "|            word_field           |                        None                       |\n",
      "|               name              |                      germeval                     |\n",
      "|             dataset             | {'task': 'germeval2017', 'split_length':[...]49}} |\n",
      "|              vocabs             | (<torchtext.vocab.Vocab object at 0x1a28[...]38>) |\n",
      "|               task              |                    germeval2017                   |\n",
      "|             examples            | [<torchtext.data.example.Example object [...]d0>] |\n",
      "|            batch_size           |                         80                        |\n",
      "|             language            |                         de                        |\n",
      "|            data_path            |                ./data/germeval2017                |\n",
      "|            train_file           |                   train_v1.4.tsv                  |\n",
      "|            valid_file           |                    dev_v1.4.tsv                   |\n",
      "|            test_file            |                test_TIMESTAMP1.tsv                |\n",
      "|           file_format           |                        .tsv                       |\n",
      "|            init_token           |                        None                       |\n",
      "|            eos_token            |                        None                       |\n",
      "|    pretrained_word_embeddings   |                       glove                       |\n",
      "|  pretrained_word_embeddings_dim |                        300                        |\n",
      "| pretrained_word_embeddings_name |                         6B                        |\n",
      "|             use_cuda            |                       False                       |\n",
      "|          use_stop_words         |                        True                       |\n",
      "|              logger             |           <Logger pre_training (DEBUG)>           |\n",
      "|           split_length          |                (17043, 2049, 2095)                |\n",
      "|          total_samples          |                         -1                        |\n",
      "|           source_index          |                         0                         |\n",
      "|        target_vocab_index       |                         1                         |\n",
      "|           target_size           |                         3                         |\n",
      "|         source_embedding        |               Embedding(95161, 300)               |\n",
      "|           class_labels          |        ['neutral', 'negative', 'positive']        |\n",
      "|        source_field_name        |                      comments                     |\n",
      "|        target_field_name        |                 general_sentiments                |\n",
      "|        padding_field_name       |                      padding                      |\n",
      "|         source_reverser         | <data.custom_fields.ReversibleField obje[...]320> |\n",
      "|         target_reverser         | ('general_sentiments', <data.custom_fiel[...]28>) |\n",
      "|            baselines            | {'germeval_baseline': 0.667, 'germeval_b[...]749} |\n",
      "|     majority_class_baseline     |                        0.0                        |\n",
      "|              fields             | {None: None, 'comments': <data.custom_fi[...]78>} |\n",
      "|              target             | [('general_sentiments', <data.custom_fie[...]8>)] |\n",
      "|           dummy_input           |         tensor([[0, 0, 0,  ..., 0, 0, 0],         |\n",
      "|                                 |                        [...]0]])                  |\n",
      "+---------------------------------+---------------------------------------------------+\n",
      "pre_training - INFO - +-------------------------+\n",
      "|  GERM EVAL 2017 DATASET |\n",
      "+---------------+---------+\n",
      "|     Split     |   Size  |\n",
      "+---------------+---------+\n",
      "|     train     |  17043  |\n",
      "|   validation  |   2049  |\n",
      "|      test     |   2095  |\n",
      "+---------------+---------+\n",
      "+-------------------------+\n",
      "|  GERM EVAL 2017 DATASET |\n",
      "+---------------+---------+\n",
      "|     Split     |   Size  |\n",
      "+---------------+---------+\n",
      "|     train     |  17043  |\n",
      "|   validation  |   2049  |\n",
      "|      test     |   2095  |\n",
      "+---------------+---------+\n",
      "pre_training - INFO - +--------------------------------------+\n",
      "|           Vocabulary Stats           |\n",
      "+------------------------------+-------+\n",
      "|          Vocabulary          |  Size |\n",
      "+------------------------------+-------+\n",
      "|           comments           | 95161 |\n",
      "|      general_sentiments      |   3   |\n",
      "|           padding            | 33834 |\n",
      "|           QR-Code            |   3   |\n",
      "| Auslastung_und_Platzangebot  |   4   |\n",
      "|      DB_App_und_Website      |   4   |\n",
      "| Sonstige_Unregelmässigkeiten |   4   |\n",
      "|          Ticketkauf          |   4   |\n",
      "|           Zugfahrt           |   4   |\n",
      "|          Atmosphäre          |   4   |\n",
      "|        Informationen         |   4   |\n",
      "|            Image             |   4   |\n",
      "|          Toiletten           |   4   |\n",
      "|            Gepäck            |   4   |\n",
      "|            Design            |   4   |\n",
      "|         Connectivity         |   4   |\n",
      "|       Barrierefreiheit       |   4   |\n",
      "|   Gastronomisches_Angebot    |   4   |\n",
      "| Service_und_Kundenbetreuung  |   4   |\n",
      "|          Sicherheit          |   4   |\n",
      "|      Reisen_mit_Kindern      |   4   |\n",
      "|          Allgemein           |   4   |\n",
      "|   Komfort_und_Ausstattung    |   4   |\n",
      "+------------------------------+-------+\n",
      "+--------------------------------------+\n",
      "|           Vocabulary Stats           |\n",
      "+------------------------------+-------+\n",
      "|          Vocabulary          |  Size |\n",
      "+------------------------------+-------+\n",
      "|           comments           | 95161 |\n",
      "|      general_sentiments      |   3   |\n",
      "|           padding            | 33834 |\n",
      "|           QR-Code            |   3   |\n",
      "| Auslastung_und_Platzangebot  |   4   |\n",
      "|      DB_App_und_Website      |   4   |\n",
      "| Sonstige_Unregelmässigkeiten |   4   |\n",
      "|          Ticketkauf          |   4   |\n",
      "|           Zugfahrt           |   4   |\n",
      "|          Atmosphäre          |   4   |\n",
      "|        Informationen         |   4   |\n",
      "|            Image             |   4   |\n",
      "|          Toiletten           |   4   |\n",
      "|            Gepäck            |   4   |\n",
      "|            Design            |   4   |\n",
      "|         Connectivity         |   4   |\n",
      "|       Barrierefreiheit       |   4   |\n",
      "|   Gastronomisches_Angebot    |   4   |\n",
      "| Service_und_Kundenbetreuung  |   4   |\n",
      "|          Sicherheit          |   4   |\n",
      "|      Reisen_mit_Kindern      |   4   |\n",
      "|          Allgemein           |   4   |\n",
      "|   Komfort_und_Ausstattung    |   4   |\n",
      "+------------------------------+-------+\n",
      "pre_training - INFO - \n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            general_sentiments           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  | 62.18975532476677  |\n",
      "| positive |   1216  | 7.1348940914158305 |\n",
      "| negative |   5228  |  30.6753505838174  |\n",
      "|   Sum    |  17043  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                 QR-Code                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Auslastung_und_Platzangebot       |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            DB_App_und_Website           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Sonstige_Unregelmässigkeiten      |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Ticketkauf               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                 Zugfahrt                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Atmosphäre               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|              Informationen              |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Image                  |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Toiletten                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Gepäck                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Design                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|               Connectivity              |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|             Barrierefreiheit            |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|         Gastronomisches_Angebot         |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Service_und_Kundenbetreuung       |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Sicherheit               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            Reisen_mit_Kindern           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Allgemein                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|         Komfort_und_Ausstattung         |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            general_sentiments           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  | 62.18975532476677  |\n",
      "| positive |   1216  | 7.1348940914158305 |\n",
      "| negative |   5228  |  30.6753505838174  |\n",
      "|   Sum    |  17043  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                 QR-Code                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Auslastung_und_Platzangebot       |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            DB_App_und_Website           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Sonstige_Unregelmässigkeiten      |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Ticketkauf               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                 Zugfahrt                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Atmosphäre               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|              Informationen              |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Image                  |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Toiletten                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Gepäck                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                  Design                 |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|               Connectivity              |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|             Barrierefreiheit            |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|         Gastronomisches_Angebot         |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|       Service_und_Kundenbetreuung       |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Sicherheit               |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|            Reisen_mit_Kindern           |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|                Allgemein                |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------+\n",
      "|         Komfort_und_Ausstattung         |\n",
      "+----------+---------+--------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |\n",
      "+----------+---------+--------------------+\n",
      "| neutral  |  10599  |  50.0259593146741  |\n",
      "| positive |   1216  |  5.73936848067211  |\n",
      "| negative |   5228  | 24.675508566573843 |\n",
      "|   Sum    |  21187  |                    |\n",
      "+----------+---------+--------------------+\n",
      "\n",
      "\n",
      "pre_training - INFO - Dataset loaded. Ready for training\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    'germeval',\n",
    "    logging.getLogger('data_loaoder'),\n",
    "    hyperparameters,\n",
    "    source_index=0,\n",
    "    target_vocab_index=1,\n",
    "    data_path=PREFERENCES.data_root,\n",
    "    train_file=PREFERENCES.data_train,\n",
    "    valid_file=PREFERENCES.data_validation,\n",
    "    test_file=PREFERENCES.data_test,\n",
    "    file_format='.tsv',\n",
    "    init_token=None,\n",
    "    eos_token=None\n",
    ")\n",
    "dataset.load_data(germeval2017_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NllLoss(dataset.target_size)\n",
    "transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                 hyperparameters=hyperparameters)\n",
    "tagging_softmax = SoftmaxOutputLayerWithCommentWiseClass(hyperparameters.model_size, dataset.target_size)\n",
    "model = TransformerTagger(transformer, tagging_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - TransformerTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(95161, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((95161, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=31734796\n",
      "  (taggingLayer): SoftmaxOutputLayerWithCommentWiseClass(\n",
      "    (output_projection): Linear(in_features=300, out_features=3, bias=True)\n",
      "  ), weights=((3, 300), (3,)), parameters=903\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 31735699\n",
      "==================================\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1              [-1, 42, 300]      28,548,300\n",
      "           Dropout-2              [-1, 42, 300]               0\n",
      "PositionalEncoding2-3              [-1, 42, 300]               0\n",
      "            Linear-4              [-1, 42, 300]          90,000\n",
      "            Linear-5              [-1, 42, 300]          90,000\n",
      "            Linear-6              [-1, 42, 300]          90,000\n",
      "           Dropout-7               [-1, 42, 42]               0\n",
      "ScaledDotProductAttentionLayer-8              [-1, 42, 100]               0\n",
      "            Linear-9              [-1, 42, 300]          90,000\n",
      "          Dropout-10              [-1, 42, 300]               0\n",
      "        LayerNorm-11              [-1, 42, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-12              [-1, 42, 300]               0\n",
      "           Linear-13             [-1, 42, 2048]         616,448\n",
      "           Linear-14              [-1, 42, 300]         614,700\n",
      "          Dropout-15              [-1, 42, 300]               0\n",
      "        LayerNorm-16              [-1, 42, 300]               0\n",
      "     EncoderBlock-17              [-1, 42, 300]               0\n",
      "           Linear-18              [-1, 42, 300]          90,000\n",
      "           Linear-19              [-1, 42, 300]          90,000\n",
      "           Linear-20              [-1, 42, 300]          90,000\n",
      "          Dropout-21               [-1, 42, 42]               0\n",
      "ScaledDotProductAttentionLayer-22              [-1, 42, 100]               0\n",
      "           Linear-23              [-1, 42, 300]          90,000\n",
      "          Dropout-24              [-1, 42, 300]               0\n",
      "        LayerNorm-25              [-1, 42, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-26              [-1, 42, 300]               0\n",
      "           Linear-27             [-1, 42, 2048]         616,448\n",
      "           Linear-28              [-1, 42, 300]         614,700\n",
      "          Dropout-29              [-1, 42, 300]               0\n",
      "        LayerNorm-30              [-1, 42, 300]               0\n",
      "     EncoderBlock-31              [-1, 42, 300]               0\n",
      "TransformerEncoder-32              [-1, 42, 300]               0\n",
      "           Linear-33                [-1, 42, 3]             903\n",
      "SoftmaxOutputLayerWithCommentWiseClass-34                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 31,731,499\n",
      "Trainable params: 31,731,499\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.90\n",
      "Params size (MB): 121.05\n",
      "Estimated Total Size (MB): 124.95\n",
      "----------------------------------------------------------------\n",
      "pre_training - INFO - TransformerTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(95161, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((95161, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=31734796\n",
      "  (taggingLayer): SoftmaxOutputLayerWithCommentWiseClass(\n",
      "    (output_projection): Linear(in_features=300, out_features=3, bias=True)\n",
      "  ), weights=((3, 300), (3,)), parameters=903\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 31735699\n",
      "==================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - Classes: ['neutral', 'negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "optimizer = get_default_optimizer(model, hyperparameters)\n",
    "trainer = Trainer(\n",
    "                    model,\n",
    "                    loss,\n",
    "                    optimizer,\n",
    "                    hyperparameters,\n",
    "                    dataset,\n",
    "                    experiment_name,\n",
    "                    enable_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - DEBUG - train without cuda support\n",
      "pre_training - INFO - 214 Iterations per epoch with batch size of 80\n",
      "pre_training - INFO - START training.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c7117c26784530880b1c876c41557b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EP 1', max=214, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bb932d761385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperform_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, use_cuda, perform_evaluation)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0msource_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_padding_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/train.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, input, target, source_mask)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# Compute loss and gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# preform training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/train.py\u001b[0m in \u001b[0;36m_get_loss\u001b[0;34m(self, input, source_mask, target)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer_tagger.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaggingLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Example CollNl2003: The output will be of size [batch_size, number_of_labels, prob_of_each_class_for_the_label]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# apply the forward pass for each encoding sub layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_sub_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_sub_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# residual = attentionResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfcResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentionResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;31m# fcResult = self.layer_norm.forward(fcResult + residual)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/TUM/ABSA-Transformer/models/transformer/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = trainer.train(hyperparameters.num_epochs, use_cuda=hyperparameters.use_cuda, perform_evaluation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = result['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels = trainer.classify_sentence('I was born in 1993 in Stuttgart')\n",
    "\n",
    "\n",
    "\n",
    "print(result_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = trainer.text_reverser[1]\n",
    "lr = trainer.label_reverser\n",
    "\n",
    "test_sentence = ['china', 'controlled', 'most', 'of', 'the', 'match']\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = tr.preprocess('Die Bahn ist nicht gut')\n",
    "\n",
    "#test_sentence = tr.preprocess('china controlled most of the match on 1993')\n",
    "test_sentence = [x.strip(' ') for x in test_sentence]\n",
    "test_sentence = [test_sentence]\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test = tr.preprocess('china controlled most of the match')\n",
    "#print(test)\n",
    "\n",
    "#test_sentence = [['china', 'controlled', 'most', 'of', 'the', 'match']]\n",
    "x = tr.process(test_sentence)\n",
    "\n",
    "print(\"X TENSOR \",x)\n",
    "print('X Size', x.size())\n",
    "print(\"Reversed X\", tr.reverse(x))\n",
    "x = x.cuda()\n",
    "y_hat = model.predict(x)\n",
    "y_hat_label = lr.reverse(y_hat)\n",
    "print(y_hat_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.tb_writer = None\n",
    "trainer.enable_tensorboard = False\n",
    "evaluation_results = trainer.perform_final_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_matrix = evaluation_results[1][2]\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(c_matrix, class_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(c_matrix, class_labels, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict now to see model in final state\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df = predict_some_examples_to_df(model, conll2003['iters'][2], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = predict_some_examples_to_df(model, conll2003['iters'][1], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = predict_some_examples_to_df(model, conll2003['iters'][0], num_samples=800)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([\n",
    "    np.array([[1, 1], [1, 1]]),\n",
    "    np.array([[2, 2], [-2, -3]])\n",
    "])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = predict_some_examples_to_df(model, test_sample_iter)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(tr_loss, tr_f1) = result['result_train']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
