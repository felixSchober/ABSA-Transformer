+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 84.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         84                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.001712347749725593               |
|  noam_learning_rate_warmup   |                        3590                       |
|  noam_learning_rate_factor   |                 1.182114679115839                 |
|          adam_beta1          |                 0.9101244092839652                |
|          adam_beta2          |                 0.8337181619921996                |
|           adam_eps           |               7.862261509789165e-09               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                 0.6824148259631818                |
|     pointwise_layer_size     |                        198                        |
|      last_layer_dropout      |                0.42116258222239245                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        143                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]
Epoch 5
100% 203/203 [11:13<00:00, 1.66it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time
1	203	20.01		16.74		0.244		0.959		2.36m - 2.4m / 0.0m
2	406	16.23		17.21		0.234		0.917		2.20m - 4.6m / 82.5m
3	609	16.26		16.88		0.244		0.959		2.21m - 6.8m / 77.3m
4	812	16.29		18.18		0.232		0.910		2.22m - 9.0m / 77.6m
5	1015	16.41		19.05		0.244		0.959		2.23m - 11.2m / 77.9m
Best f1 0.2441399350742839                           
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 13.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         13                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.00884659211817554                |
|  noam_learning_rate_warmup   |                        4476                       |
|  noam_learning_rate_factor   |                 1.6706614552799313                |
|          adam_beta1          |                 0.8083422716691562                |
|          adam_beta2          |                 0.8037414746805143                |
|           adam_eps           |               3.410937266662712e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         3                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                0.06547683385072496                |
|     pointwise_layer_size     |                        396                        |
|      last_layer_dropout      |                0.38725402210909937                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        219                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  1%|          | 1/100 [17:00<28:03:23, 1020.23s/it, best loss: 19.0487140083313]
Epoch 5
100% 1311/1311 [14:52<00:00, 7.98it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                       
1	1311	11.41		10.46		0.244		0.959		2.98m - 3.0m / 0.0m             
2	2622	11.05		9.96		0.244		0.959		2.96m - 5.9m / 104.5m            
3	3933	10.69		10.15		0.244		0.959		2.99m - 8.9m / 103.7m           
4	5244	10.36		9.90		0.244		0.959		2.97m - 11.9m / 104.5m           
5	6555	10.11		9.62		0.244		0.959		2.97m - 14.9m / 104.0m           
Best f1 0.2441399350742839                                                       
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 92.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         92                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.0007289573236568684               |
|  noam_learning_rate_warmup   |                        6404                       |
|  noam_learning_rate_factor   |                 0.4851611936572505                |
|          adam_beta1          |                 0.8027528718985583                |
|          adam_beta2          |                 0.7909343022686817                |
|           adam_eps           |               3.8812386570653145e-09              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                 0.6802219858175053                |
|     pointwise_layer_size     |                        358                        |
|      last_layer_dropout      |                 0.6407853185066901                |
|   output_conv_num_filters    |                        316                        |
|   output_conv_kernel_size    |                         4                         |
|      output_conv_stride      |                         9                         |
|     output_conv_padding      |                         5                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        143                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  2%|▏         | 2/100 [34:03<27:47:46, 1021.09s/it, best loss: 9.621138359926924]
Epoch 5
100% 186/186 [16:16<00:00, 1.03it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                        
1	186	19.41		19.07		0.188		0.731		3.26m - 3.3m / 0.0m               
2	372	16.65		25.90		0.054		0.194		3.25m - 6.5m / 114.3m             
3	558	16.58		27.45		0.054		0.194		3.27m - 9.8m / 113.7m             
4	744	16.46		25.00		0.054		0.195		3.24m - 13.0m / 114.3m            
5	930	16.64		21.84		0.115		0.439		3.26m - 16.3m / 113.4m            
Best f1 0.1877568511007078                                                        
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 28.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         28                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.0026182588608539494               |
|  noam_learning_rate_warmup   |                        8274                       |
|  noam_learning_rate_factor   |                 1.2341010293701744                |
|          adam_beta1          |                 0.9297347323662211                |
|          adam_beta2          |                 0.8523996500251234                |
|           adam_eps           |               0.00030096293114247703              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                 0.730342933011631                 |
|     pointwise_layer_size     |                         62                        |
|      last_layer_dropout      |                0.09556832335285446                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        173                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  3%|▎         | 3/100 [52:07<28:01:20, 1040.01s/it, best loss: 9.621138359926924]
Epoch 5
100% 609/609 [13:52<00:00, 3.94it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                        
1	609	15.61		13.92		0.244		0.959		2.78m - 2.8m / 0.0m               
2	1218	12.47		15.13		0.234		0.916		2.77m - 5.6m / 97.5m             
3	1827	12.55		13.90		0.234		0.916		2.77m - 8.3m / 97.1m             
4	2436	12.53		14.39		0.234		0.916		2.77m - 11.1m / 96.9m              
5	3045	12.56		19.66		0.244		0.959		2.77m - 13.9m / 96.9m              
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 25.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         25                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.01529429952235348                |
|  noam_learning_rate_warmup   |                        6859                       |
|  noam_learning_rate_factor   |                0.07631236486408167                |
|          adam_beta1          |                 0.9252009865236691                |
|          adam_beta2          |                 0.9965427834360303                |
|           adam_eps           |               4.520435442393136e-05               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                 0.5209146223940523                |
|     pointwise_layer_size     |                        462                        |
|      last_layer_dropout      |                 0.6945987032510481                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        178                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  4%|▍         | 4/100 [1:07:33<26:49:25, 1005.89s/it, best loss: 9.621138359926924]
Epoch 6
100% 682/682 [29:25<00:00, 2.44it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	682	18.45		11.72		0.234		0.916		4.95m - 5.0m / 0.0m                 
2	1364	12.32		11.31		0.244		0.959		4.90m - 9.9m / 173.3m              
3	2046	12.08		11.47		0.244		0.959		4.90m - 14.8m / 171.5m             
4	2728	12.11		11.66		0.244		0.959		4.89m - 19.6m / 171.5m             
5	3410	12.09		11.39		0.244		0.959		4.89m - 24.5m / 171.3m             
6	4092	12.05		11.57		0.244		0.959		4.89m - 29.4m / 171.3m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 33.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         33                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.00045659584061036535              |
|  noam_learning_rate_warmup   |                        7136                       |
|  noam_learning_rate_factor   |                 1.699958898990478                 |
|          adam_beta1          |                 0.8546094106817431                |
|          adam_beta2          |                 0.9746617593731157                |
|           adam_eps           |                 0.3041700164494531                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                0.33553029000696477                |
|     pointwise_layer_size     |                        213                        |
|      last_layer_dropout      |                0.22053386519258675                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        219                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  5%|▌         | 5/100 [1:39:43<33:51:34, 1283.10s/it, best loss: 9.621138359926924]
Epoch 5
100% 517/517 [14:12<00:00, 3.29it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	517	17.12		11.89		0.244		0.959		2.84m - 2.8m / 0.0m                 
2	1034	13.03		12.40		0.232		0.912		2.84m - 5.7m / 99.4m               
3	1551	13.03		12.27		0.234		0.916		2.84m - 8.5m / 99.5m               
4	2068	13.05		11.73		0.244		0.959		2.84m - 11.4m / 99.6m              
5	2585	13.05		12.00		0.244		0.959		2.84m - 14.2m / 99.5m              
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 40.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         40                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.004093157264743146               |
|  noam_learning_rate_warmup   |                        4121                       |
|  noam_learning_rate_factor   |                 1.337506882889756                 |
|          adam_beta1          |                 0.9071844231677957                |
|          adam_beta2          |                 0.8397906712855818                |
|           adam_eps           |                 0.4213271914304345                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         1                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                 0.5091071928896698                |
|     pointwise_layer_size     |                        294                        |
|      last_layer_dropout      |                 0.3542666323263373                |
|   output_conv_num_filters    |                        258                        |
|   output_conv_kernel_size    |                         5                         |
|      output_conv_stride      |                         2                         |
|     output_conv_padding      |                         5                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         17                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  6%|▌         | 6/100 [1:55:33<30:53:45, 1183.25s/it, best loss: 9.621138359926924]
Epoch 1
0% 0/427 [00:00<?, ?it/s]
Exception while training: size mismatch, m1: [10320 x 3], m2: [258 x 4] at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/THC/generic/THCTensorMathBlas.cu:266
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 32.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         32                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.017894287413033467               |
|  noam_learning_rate_warmup   |                        5439                       |
|  noam_learning_rate_factor   |                 1.662879382351526                 |
|          adam_beta1          |                 0.8554016887590582                |
|          adam_beta2          |                 0.8891969683750303                |
|           adam_eps           |                0.001114780884969481               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         2                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                 0.2638245725824908                |
|     pointwise_layer_size     |                        231                        |
|      last_layer_dropout      |                 0.7340346304989824                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        184                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  7%|▋         | 7/100 [1:55:47<21:30:00, 832.26s/it, best loss: 9.621138359926924]
Epoch 8
100% 533/533 [09:55<00:00, 7.75it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	533	15.67		12.46		0.234		0.917		1.24m - 1.2m / 0.0m                
2	1066	13.45		12.36		0.233		0.915		1.24m - 2.5m / 43.3m              
3	1599	13.46		12.67		0.234		0.916		1.24m - 3.7m / 43.2m              
4	2132	13.57		12.58		0.244		0.959		1.24m - 5.0m / 43.3m              
5	2665	13.62		12.32		0.234		0.916		1.24m - 6.2m / 43.5m              
6	3198	13.56		13.55		0.223		0.872		1.25m - 7.4m / 43.4m              
7	3731	13.54		12.44		0.232		0.910		1.24m - 8.7m / 43.6m              
8	4264	13.58		12.57		0.244		0.959		1.24m - 9.9m / 43.4m              
Best f1 0.2441399350742839                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 21.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         21                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.002430556705992445               |
|  noam_learning_rate_warmup   |                        1493                       |
|  noam_learning_rate_factor   |                 1.0900200919042877                |
|          adam_beta1          |                 0.7526472035524232                |
|          adam_beta2          |                 0.7678608362033541                |
|           adam_eps           |               1.4845114530838494e-08              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                 0.5546731004374941                |
|     pointwise_layer_size     |                         76                        |
|      last_layer_dropout      |                 0.5494240529775934                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        129                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  8%|▊         | 8/100 [2:06:29<19:48:40, 775.22s/it, best loss: 9.621138359926924]
Epoch 5
100% 812/812 [13:23<00:00, 5.31it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	812	13.12		13.77		0.244		0.959		2.68m - 2.7m / 0.0m                
2	1624	12.50		26.60		0.244		0.959		2.69m - 5.4m / 93.8m              
3	2436	11.96		33.94		0.244		0.959		2.68m - 8.0m / 94.1m              
4	3248	11.81		28.14		0.244		0.959		2.67m - 10.7m / 93.7m             
5	4060	11.69		37.96		0.244		0.959		2.67m - 13.4m / 93.6m             
Best f1 0.2441399350742839                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 97.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         97                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.06346093369353513                |
|  noam_learning_rate_warmup   |                        5406                       |
|  noam_learning_rate_factor   |                 1.2601163026340225                |
|          adam_beta1          |                 0.8267667852333515                |
|          adam_beta2          |                 0.832740233818315                 |
|           adam_eps           |               1.4303337573859504e-09              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                 0.6209931462213147                |
|     pointwise_layer_size     |                        176                        |
|      last_layer_dropout      |                 0.4054175690377398                |
|   output_conv_num_filters    |                        334                        |
|   output_conv_kernel_size    |                         2                         |
|      output_conv_stride      |                         8                         |
|     output_conv_padding      |                         3                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         64                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
  9%|▉         | 9/100 [2:21:28<20:32:07, 812.39s/it, best loss: 9.621138359926924]
Epoch 5
100% 176/176 [04:29<00:00, 3.48it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	176	19.07		16.28		0.223		0.874		0.90m - 0.9m / 0.0m                
2	352	16.59		21.62		0.187		0.728		0.90m - 1.8m / 31.6m               
3	528	16.48		19.92		0.187		0.726		0.90m - 2.7m / 31.4m               
4	704	16.64		20.57		0.183		0.713		0.90m - 3.6m / 31.4m               
5	880	16.80		18.51		0.198		0.773		0.90m - 4.5m / 31.4m               
Best f1 0.2233611821931029                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 32.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         32                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.07399242805192587                |
|  noam_learning_rate_warmup   |                        5187                       |
|  noam_learning_rate_factor   |                 1.5288020470174086                |
|          adam_beta1          |                 0.7524852041192064                |
|          adam_beta2          |                 0.9220879794149636                |
|           adam_eps           |               4.5490789237838556e-08              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                 0.7412459894667143                |
|     pointwise_layer_size     |                        426                        |
|      last_layer_dropout      |                 0.3772112225821409                |
|   output_conv_num_filters    |                        288                        |
|   output_conv_kernel_size    |                         5                         |
|      output_conv_stride      |                         3                         |
|     output_conv_padding      |                         1                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        128                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 10%|█         | 10/100 [2:26:38<16:32:29, 661.66s/it, best loss: 9.621138359926924]
Epoch 1
100% 533/533 [03:02<00:00, 2.99it/s]
Exception while training: local variable 'mean_valid_loss' referenced before assignment
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 79.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         79                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.0023159036649508633               |
|  noam_learning_rate_warmup   |                        4032                       |
|  noam_learning_rate_factor   |                 1.8553501693009633                |
|          adam_beta1          |                 0.9242645604286099                |
|          adam_beta2          |                 0.9818207395304669                |
|           adam_eps           |               5.882304164633772e-05               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.5731910302252268                |
|     pointwise_layer_size     |                        155                        |
|      last_layer_dropout      |                 0.4229602143627769                |
|   output_conv_num_filters    |                        323                        |
|   output_conv_kernel_size    |                         3                         |
|      output_conv_stride      |                         5                         |
|     output_conv_padding      |                         1                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         20                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 11%|█         | 11/100 [2:29:55<12:54:37, 522.22s/it, best loss: 9.621138359926924]
Epoch 5
100% 216/216 [03:35<00:00, 5.45it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	216	17.30		15.68		0.210		0.820		0.72m - 0.7m / 0.0m                 
2	432	16.07		15.53		0.198		0.773		0.72m - 1.4m / 25.3m                
3	648	16.32		17.54		0.198		0.772		0.71m - 2.2m / 25.2m                
4	864	16.52		17.04		0.209		0.819		0.72m - 2.9m / 25.0m                
5	1080	16.63		16.63		0.188		0.732		0.71m - 3.6m / 25.0m               
Best f1 0.20971938953512054                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 14.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         14                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.01888723872554137                |
|  noam_learning_rate_warmup   |                        6702                       |
|  noam_learning_rate_factor   |                 1.4569035470305118                |
|          adam_beta1          |                 0.9696060219336016                |
|          adam_beta2          |                 0.9685509860405285                |
|           adam_eps           |               5.527474412560233e-09               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                0.20958069852401442                |
|     pointwise_layer_size     |                        207                        |
|      last_layer_dropout      |                 0.7628026101970407                |
|   output_conv_num_filters    |                        399                        |
|   output_conv_kernel_size    |                         3                         |
|      output_conv_stride      |                         8                         |
|     output_conv_padding      |                         2                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        229                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 12%|█▏        | 12/100 [2:33:54<10:41:17, 437.25s/it, best loss: 9.621138359926924]
Epoch 5
100% 1218/1218 [34:16<00:00, 3.11it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	1218	11.36		16.80		0.244		0.959		6.84m - 6.8m / 0.0m                
2	2436	10.88		15.68		0.244		0.959		6.86m - 13.7m / 239.5m             
3	3654	11.12		18.86		0.234		0.916		6.86m - 20.6m / 240.2m             
4	4872	11.33		18.63		0.232		0.909		6.85m - 27.4m / 240.1m             
5	6090	11.41		18.75		0.244		0.959		6.85m - 34.3m / 239.9m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 85.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         85                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.00019171684140152054              |
|  noam_learning_rate_warmup   |                        3872                       |
|  noam_learning_rate_factor   |                 1.6230145911290175                |
|          adam_beta1          |                 0.9292868014273244                |
|          adam_beta2          |                 0.9853945080730877                |
|           adam_eps           |               1.4579825191991573e-09              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         1                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                 0.5171744422263704                |
|     pointwise_layer_size     |                        351                        |
|      last_layer_dropout      |                 0.7599135685698282                |
|   output_conv_num_filters    |                        149                        |
|   output_conv_kernel_size    |                         6                         |
|      output_conv_stride      |                         8                         |
|     output_conv_padding      |                         3                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         15                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 13%|█▎        | 13/100 [3:11:49<23:53:20, 988.51s/it, best loss: 9.621138359926924]
Epoch 29
100% 201/201 [10:49<00:00, 6.86s/it]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	201	18.22		15.23		0.224		0.872		0.37m - 0.4m / 0.0m                 
2	402	16.78		16.28		0.234		0.916		0.37m - 0.7m / 13.1m                
3	603	16.27		16.22		0.242		0.870		0.37m - 1.1m / 13.0m                
4	804	14.91		16.86		0.246		0.867		0.37m - 1.5m / 12.9m                
5	1005	13.53		17.28		0.245		0.825		0.37m - 1.9m / 12.9m               
6	1206	12.22		17.24		0.281		0.912		0.37m - 2.2m / 13.0m               
7	1407	11.08		16.72		0.279		0.867		0.37m - 2.6m / 13.0m               
8	1608	10.31		17.35		0.284		0.858		0.37m - 3.0m / 13.0m               
9	1809	9.52		21.06		0.285		0.877		0.37m - 3.4m / 13.0m                
10	2010	9.39		20.86		0.284		0.880		0.37m - 3.7m / 13.0m               
11	2211	8.55		26.42		0.293		0.910		0.37m - 4.1m / 13.0m               
12	2412	8.88		25.07		0.272		0.813		0.37m - 4.5m / 13.0m               
13	2613	8.18		28.34		0.299		0.899		0.37m - 4.8m / 13.0m               
14	2814	8.21		24.98		0.273		0.821		0.37m - 5.2m / 13.0m               
15	3015	8.28		31.03		0.289		0.874		0.37m - 5.6m / 13.0m               
16	3216	8.53		36.12		0.297		0.900		0.37m - 6.0m / 13.0m               
17	3417	7.92		39.75		0.299		0.894		0.37m - 6.3m / 13.0m               
18	3618	8.34		39.54		0.302		0.906		0.37m - 6.7m / 13.1m               
19	3819	9.86		51.85		0.288		0.870		0.37m - 7.1m / 13.1m               
20	4020	9.06		47.60		0.299		0.910		0.37m - 7.5m / 13.0m               
21	4221	9.08		54.64		0.305		0.912		0.37m - 7.8m / 13.0m               
22	4422	8.84		38.24		0.302		0.899		0.37m - 8.2m / 13.0m               
23	4623	8.01		67.51		0.307		0.916		0.37m - 8.6m / 13.1m               
24	4824	7.91		57.23		0.317		0.929		0.37m - 9.0m / 13.0m               
25	5025	7.40		65.27		0.319		0.924		0.37m - 9.3m / 13.1m               
26	5226	8.10		52.36		0.318		0.926		0.38m - 9.7m / 13.0m               
27	5427	7.30		51.41		0.307		0.910		0.37m - 10.1m / 13.1m              
28	5628	7.32		64.12		0.312		0.924		0.37m - 10.4m / 13.0m              
29	5829	6.63		60.61		0.317		0.925		0.37m - 10.8m / 13.0m              
Best f1 0.31877136095446695                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 55.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         55                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.001310573448803399               |
|  noam_learning_rate_warmup   |                        4395                       |
|  noam_learning_rate_factor   |                 1.1645182232495666                |
|          adam_beta1          |                 0.9562622598572617                |
|          adam_beta2          |                 0.8107062025214329                |
|           adam_eps           |               1.3707296454433637e-09              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.16162869325856333                |
|     pointwise_layer_size     |                        440                        |
|      last_layer_dropout      |                0.36850612151384543                |
|   output_conv_num_filters    |                        296                        |
|   output_conv_kernel_size    |                         9                         |
|      output_conv_stride      |                         4                         |
|     output_conv_padding      |                         0                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        205                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 14%|█▍        | 14/100 [3:23:05<21:22:42, 894.91s/it, best loss: 9.621138359926924]
Epoch 5
100% 310/310 [20:30<00:00, 1.37it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	310	17.16		17.59		0.244		0.959		4.13m - 4.1m / 0.0m                 
2	620	16.70		20.27		0.222		0.868		4.11m - 8.2m / 144.5m               
3	930	29.75		19.01		0.232		0.909		4.10m - 12.3m / 144.0m              
4	1240	73.23		18.49		0.234		0.916		4.09m - 16.4m / 143.6m             
5	1550	1632.25		18.43		0.223		0.874		4.08m - 20.5m / 143.1m           
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 11.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         11                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               0.0005223901748658011               |
|  noam_learning_rate_warmup   |                        7049                       |
|  noam_learning_rate_factor   |                 1.336516017945928                 |
|          adam_beta1          |                 0.8441792230730512                |
|          adam_beta2          |                 0.9983148967247115                |
|           adam_eps           |               0.0002983815165837193               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                 0.3171627890206189                |
|     pointwise_layer_size     |                        368                        |
|      last_layer_dropout      |                0.08136217551958796                |
|   output_conv_num_filters    |                         13                        |
|   output_conv_kernel_size    |                         8                         |
|      output_conv_stride      |                         5                         |
|     output_conv_padding      |                         2                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         91                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 15%|█▌        | 15/100 [3:46:26<24:43:00, 1046.83s/it, best loss: 9.621138359926924]
Epoch 5
100% 1550/1550 [17:44<00:00, 7.73it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1550	10.26		9.39		0.244		0.959		3.55m - 3.6m / 0.0m                  
2	3100	9.38		9.26		0.234		0.917		3.56m - 7.1m / 124.4m                 
3	4650	9.31		9.03		0.244		0.959		3.54m - 10.7m / 124.6m                
4	6200	9.34		9.12		0.234		0.917		3.54m - 14.2m / 124.0m                
5	7750	9.31		9.14		0.244		0.959		3.54m - 17.7m / 124.0m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 64.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         64                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.013517433679587035               |
|  noam_learning_rate_warmup   |                        3672                       |
|  noam_learning_rate_factor   |                 1.7567918062675139                |
|          adam_beta1          |                 0.9454106632501511                |
|          adam_beta2          |                 0.9927822551420427                |
|           adam_eps           |                0.008192784945859243               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         2                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.7689293301249862                |
|     pointwise_layer_size     |                         37                        |
|      last_layer_dropout      |                 0.3353736331886185                |
|   output_conv_num_filters    |                        303                        |
|   output_conv_kernel_size    |                         7                         |
|      output_conv_stride      |                         7                         |
|     output_conv_padding      |                         4                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        154                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 16%|█▌        | 16/100 [4:06:38<25:34:33, 1096.12s/it, best loss: 9.136692348011037]
Epoch 1
100% 267/267 [02:16<00:00, 1.96it/s]
Exception while training: local variable 'mean_valid_loss' referenced before assignment
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 54.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         54                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.019816031796488987               |
|  noam_learning_rate_warmup   |                        3433                       |
|  noam_learning_rate_factor   |                 1.0336945083396007                |
|          adam_beta1          |                 0.7747925100001554                |
|          adam_beta2          |                 0.7080836475658773                |
|           adam_eps           |                0.12674077433553982                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                 0.514398467530367                 |
|     pointwise_layer_size     |                        505                        |
|      last_layer_dropout      |                0.08643091147279316                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         51                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 17%|█▋        | 17/100 [4:09:15<18:46:56, 814.66s/it, best loss: 9.136692348011037]
Epoch 9
100% 316/316 [09:48<00:00, 5.23it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	316	18.04		14.27		0.223		0.874		1.09m - 1.1m / 0.0m                 
2	632	14.76		14.22		0.234		0.917		1.09m - 2.2m / 38.0m                
3	948	14.85		14.54		0.232		0.898		1.09m - 3.3m / 38.0m                
4	1264	14.74		15.08		0.236		0.896		1.09m - 4.4m / 38.0m               
5	1580	14.60		14.00		0.243		0.925		1.09m - 5.4m / 38.1m               
6	1896	14.68		14.43		0.241		0.892		1.09m - 6.5m / 38.0m               
7	2212	14.62		14.04		0.240		0.913		1.09m - 7.6m / 38.2m               
8	2528	14.68		15.13		0.231		0.872		1.09m - 8.7m / 38.1m               
9	2844	14.79		13.87		0.240		0.907		1.09m - 9.8m / 38.1m               
Best f1 0.2426934060848756                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 91.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         91                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               0.0005727798153711289               |
|  noam_learning_rate_warmup   |                        8263                       |
|  noam_learning_rate_factor   |                 1.0277080287853018                |
|          adam_beta1          |                 0.7269043529472751                |
|          adam_beta2          |                 0.7285593147396356                |
|           adam_eps           |                9.48090691797533e-07               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         2                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                0.10731195239094093                |
|     pointwise_layer_size     |                        353                        |
|      last_layer_dropout      |                 0.4363778786046135                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        148                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 18%|█▊        | 18/100 [4:19:56<17:21:46, 762.28s/it, best loss: 9.136692348011037]
Epoch 16
100% 188/188 [20:33<00:00, 2.49it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	188	24.32		15.04		0.227		0.879		1.28m - 1.3m / 0.0m                 
2	376	16.14		14.77		0.234		0.908		1.28m - 2.6m / 44.7m                
3	564	15.95		14.79		0.251		0.934		1.28m - 3.8m / 44.7m                
4	752	15.55		14.28		0.256		0.924		1.28m - 5.1m / 44.9m                
5	940	14.47		13.09		0.262		0.897		1.28m - 6.4m / 44.9m                
6	1128	12.67		12.68		0.292		0.876		1.28m - 7.7m / 44.8m               
7	1316	11.06		12.78		0.294		0.886		1.28m - 9.0m / 44.8m               
8	1504	9.71		12.34		0.309		0.866		1.29m - 10.3m / 44.8m               
9	1692	8.36		12.56		0.314		0.902		1.28m - 11.6m / 45.0m               
10	1880	7.03		13.03		0.322		0.907		1.28m - 12.8m / 44.8m              
11	2068	5.85		13.62		0.351		0.932		1.29m - 14.1m / 44.9m              
12	2256	4.88		15.45		0.363		0.938		1.28m - 15.4m / 45.0m              
13	2444	4.11		15.46		0.338		0.903		1.28m - 16.7m / 44.8m              
14	2632	3.34		16.96		0.359		0.943		1.28m - 18.0m / 45.0m              
15	2820	2.74		18.31		0.342		0.933		1.28m - 19.3m / 44.9m              
16	3008	2.47		19.60		0.351		0.946		1.28m - 20.6m / 44.9m              
Best f1 0.3625379140820278                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 26.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         26                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.007473673351831418               |
|  noam_learning_rate_warmup   |                        6452                       |
|  noam_learning_rate_factor   |                 1.6166761898200066                |
|          adam_beta1          |                 0.7377078208332674                |
|          adam_beta2          |                 0.9830046157575762                |
|           adam_eps           |               1.7349424050662537e-09              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         3                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                 0.7436470603944978                |
|     pointwise_layer_size     |                        340                        |
|      last_layer_dropout      |                0.20807255058094976                |
|   output_conv_num_filters    |                        272                        |
|   output_conv_kernel_size    |                         3                         |
|      output_conv_stride      |                         4                         |
|     output_conv_padding      |                         1                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        217                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 19%|█▉        | 19/100 [4:41:26<20:43:05, 920.80s/it, best loss: 9.136692348011037]
Epoch 5
100% 656/656 [19:01<00:00, 3.02it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	656	13.61		15.09		0.221		0.868		3.80m - 3.8m / 0.0m                 
2	1312	12.43		44.35		0.025		0.085		3.81m - 7.6m / 133.1m              
3	1968	12.84		114.28		0.003		0.007		3.81m - 11.4m / 133.4m            
4	2624	13.24		121.01		0.015		0.056		3.80m - 15.2m / 133.3m            
5	3280	13.48		99.68		0.023		0.082		3.80m - 19.0m / 133.1m             
Best f1 0.22149865497670834                                                         
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 10.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         10                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               3.332925490247688e-07               |
|  noam_learning_rate_warmup   |                        1509                       |
|  noam_learning_rate_factor   |                 0.7941281179384557                |
|          adam_beta1          |                 0.8809360438530516                |
|          adam_beta2          |                 0.7505823018395948                |
|           adam_eps           |               7.235499349440234e-07               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |               0.00046406818708191744              |
|     pointwise_layer_size     |                        404                        |
|      last_layer_dropout      |                0.027421390630210818               |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         97                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 20%|██        | 20/100 [5:02:30<22:44:52, 1023.65s/it, best loss: 9.136692348011037]
Epoch 5
100% 1705/1705 [20:04<00:00, 7.82it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1705	11.53		10.21		0.244		0.959		3.98m - 4.0m / 0.0m                 
2	3410	10.33		9.09		0.244		0.959		4.01m - 8.0m / 139.4m                
3	5115	9.34		8.60		0.244		0.959		4.02m - 12.0m / 140.4m                
4	6820	9.18		8.64		0.244		0.959		4.00m - 16.0m / 140.6m                
5	8525	9.08		8.45		0.244		0.959		4.05m - 20.1m / 139.9m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 11.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         11                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               5.2248740630608753e-08              |
|  noam_learning_rate_warmup   |                        1834                       |
|  noam_learning_rate_factor   |                 0.7475660381866688                |
|          adam_beta1          |                 0.8805224360002579                |
|          adam_beta2          |                 0.7491546374346164                |
|           adam_eps           |               4.541068686896134e-07               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.40395576755825957                |
|     pointwise_layer_size     |                        509                        |
|      last_layer_dropout      |                0.013519544137845077               |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         97                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 21%|██        | 21/100 [5:24:38<24:28:04, 1115.00s/it, best loss: 8.45468438776528]
Epoch 5
100% 1550/1550 [19:54<00:00, 6.83it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	1550	11.21		10.95		0.244		0.959		3.98m - 4.0m / 0.0m                
2	3100	11.07		10.41		0.234		0.917		4.01m - 8.0m / 139.2m              
3	4650	9.80		9.14		0.244		0.959		3.98m - 12.0m / 140.3m               
4	6200	9.55		11.70		0.232		0.910		3.97m - 15.9m / 139.3m              
5	7750	9.32		11.55		0.232		0.911		3.98m - 19.9m / 138.9m              
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 42.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         42                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.018144841719896e-06               |
|  noam_learning_rate_warmup   |                        2833                       |
|  noam_learning_rate_factor   |                 0.7639680743195622                |
|          adam_beta1          |                 0.8804140826330821                |
|          adam_beta2          |                 0.9330355604518326                |
|           adam_eps           |                0.007198431357907604               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |               0.0015396865769323198               |
|     pointwise_layer_size     |                        297                        |
|      last_layer_dropout      |                0.03297121366633135                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        103                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 22%|██▏       | 22/100 [5:46:36<25:28:33, 1175.82s/it, best loss: 8.45468438776528]
Epoch 6
100% 406/406 [12:05<00:00, 3.74it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	406	16.18		12.77		0.244		0.959		2.02m - 2.0m / 0.0m                 
2	812	14.22		12.92		0.246		0.946		2.01m - 4.0m / 70.8m                
3	1218	14.10		13.45		0.244		0.959		2.01m - 6.1m / 70.5m               
4	1624	14.17		12.62		0.237		0.913		2.01m - 8.1m / 70.5m               
5	2030	14.08		13.10		0.245		0.945		2.01m - 10.1m / 70.4m              
6	2436	14.09		13.00		0.240		0.925		2.01m - 12.1m / 70.4m              
Best f1 0.24552905110717008                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 19.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         19                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                2.97866941938433e-07               |
|  noam_learning_rate_warmup   |                        7818                       |
|  noam_learning_rate_factor   |                 0.7524126363675968                |
|          adam_beta1          |                 0.8876471970209832                |
|          adam_beta2          |                 0.8698796859752219                |
|           adam_eps           |               1.6576475196172804e-07              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                0.00913314716104303                |
|     pointwise_layer_size     |                        403                        |
|      last_layer_dropout      |                 0.1830854220816142                |
|   output_conv_num_filters    |                         46                        |
|   output_conv_kernel_size    |                         10                        |
|      output_conv_stride      |                         6                         |
|     output_conv_padding      |                         2                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         75                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 23%|██▎       | 23/100 [6:00:05<22:47:56, 1065.92s/it, best loss: 8.45468438776528]
Epoch 9
100% 897/897 [22:16<00:00, 6.47it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	897	12.56		11.78		0.244		0.959		2.47m - 2.5m / 0.0m                 
2	1794	11.59		10.67		0.244		0.959		2.47m - 5.0m / 86.6m               
3	2691	11.28		10.14		0.244		0.959		2.47m - 7.4m / 86.5m               
4	3588	11.00		10.68		0.245		0.950		2.48m - 9.9m / 86.3m               
5	4485	10.96		11.48		0.248		0.955		2.48m - 12.4m / 86.7m              
6	5382	11.22		10.52		0.244		0.959		2.47m - 14.9m / 86.8m              
7	6279	11.83		10.82		0.244		0.959		2.47m - 17.3m / 86.5m              
8	7176	11.75		11.47		0.244		0.959		2.48m - 19.8m / 86.5m              
9	8073	11.97		10.95		0.244		0.959		2.47m - 22.3m / 86.6m              
Best f1 0.24791091839938456                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 45.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         45                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                 1.511378605987318                 |
|  noam_learning_rate_warmup   |                        1028                       |
|  noam_learning_rate_factor   |                 0.2512689550001509                |
|          adam_beta1          |                 0.8264619819658015                |
|          adam_beta2          |                 0.7127701200168268                |
|           adam_eps           |               1.727458488048544e-10               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                 0.4131810310307698                |
|     pointwise_layer_size     |                        480                        |
|      last_layer_dropout      |                0.09783771493718536                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         44                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 24%|██▍       | 24/100 [6:24:16<24:56:30, 1181.46s/it, best loss: 8.45468438776528]
Epoch 5
100% 379/379 [05:47<00:00, 5.82it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	379	15.84		14.00		0.244		0.959		1.15m - 1.2m / 0.0m                 
2	758	14.89		14.43		0.244		0.959		1.17m - 2.3m / 40.3m                
3	1137	15.13		15.89		0.210		0.819		1.15m - 3.5m / 40.8m               
4	1516	14.91		13.69		0.211		0.823		1.15m - 4.6m / 40.4m               
5	1895	14.61		14.30		0.223		0.874		1.15m - 5.8m / 40.4m               
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 69.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         69                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               0.00013598463020920203              |
|  noam_learning_rate_warmup   |                        2599                       |
|  noam_learning_rate_factor   |                 0.5335858590374303                |
|          adam_beta1          |                 0.9897465007376673                |
|          adam_beta2          |                 0.9031983020838125                |
|           adam_eps           |               1.2310605093922251e-05              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.31222821617355356                |
|     pointwise_layer_size     |                        269                        |
|      last_layer_dropout      |                 0.2528395167555004                |
|   output_conv_num_filters    |                         21                        |
|   output_conv_kernel_size    |                         8                         |
|      output_conv_stride      |                         1                         |
|     output_conv_padding      |                         4                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        106                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 25%|██▌       | 25/100 [6:30:57<19:43:54, 947.12s/it, best loss: 8.45468438776528]
Epoch 1
0% 0/247 [00:00<?, ?it/s]
Exception while training: size mismatch, m1: [1449 x 9], m2: [21 x 4] at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/THC/generic/THCTensorMathBlas.cu:266
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 16.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         16                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.2769486521159358e-06              |
|  noam_learning_rate_warmup   |                        7413                       |
|  noam_learning_rate_factor   |                 0.9022125142199087                |
|          adam_beta1          |                 0.7823297519941321                |
|          adam_beta2          |                 0.9422659959677516                |
|           adam_eps           |               0.0008638249534450643               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                0.21646130763300536                |
|     pointwise_layer_size     |                        394                        |
|      last_layer_dropout      |                0.13548347574215466                |
|   output_conv_num_filters    |                         95                        |
|   output_conv_kernel_size    |                         9                         |
|      output_conv_stride      |                         10                        |
|     output_conv_padding      |                         4                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         85                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 26%|██▌       | 26/100 [6:31:12<13:43:11, 667.45s/it, best loss: 8.45468438776528]
Epoch 1
100% 1066/1066 [03:03<00:00, 5.82it/s]
Exception while training: local variable 'mean_valid_loss' referenced before assignment
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 10.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         10                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.604302299181554e-09               |
|  noam_learning_rate_warmup   |                        8852                       |
|  noam_learning_rate_factor   |                 0.5135593434676333                |
|          adam_beta1          |                 0.7074494117485062                |
|          adam_beta2          |                 0.7735962575542332                |
|           adam_eps           |               4.578122003693052e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.08523564298418013                |
|     pointwise_layer_size     |                        315                        |
|      last_layer_dropout      |                 0.2782967853202529                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         41                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 27%|██▋       | 27/100 [6:34:41<10:44:58, 530.12s/it, best loss: 8.45468438776528]
Epoch 19
100% 1705/1705 [44:55<00:00, 42.90s/it]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	1705	10.92		8.42		0.244		0.959		2.38m - 2.4m / 0.0m                
2	3410	8.99		8.66		0.253		0.960		2.38m - 4.8m / 83.2m                
3	5115	8.74		8.34		0.253		0.941		2.38m - 7.1m / 83.2m                
4	6820	8.73		8.09		0.264		0.952		2.38m - 9.5m / 83.4m                
5	8525	8.74		8.59		0.255		0.931		2.38m - 11.9m / 83.3m               
6	10230	8.50		7.64		0.271		0.941		2.38m - 14.3m / 83.3m              
7	11935	7.84		8.07		0.270		0.948		2.42m - 16.7m / 83.3m              
8	13640	7.45		7.73		0.274		0.938		2.39m - 19.1m / 84.6m              
9	15345	7.09		9.08		0.267		0.889		2.41m - 21.5m / 83.7m              
10	17050	6.90		8.13		0.280		0.930		2.36m - 23.9m / 84.2m             
11	18755	6.68		9.11		0.276		0.902		2.37m - 26.3m / 82.8m             
12	20460	6.50		8.15		0.278		0.934		2.36m - 28.6m / 83.2m             
13	22165	6.26		8.04		0.283		0.948		2.32m - 30.9m / 82.8m             
14	23870	6.13		8.32		0.277		0.915		2.32m - 33.3m / 82.0m             
15	25575	5.98		9.37		0.285		0.928		2.33m - 35.6m / 82.0m             
16	27280	5.87		8.93		0.274		0.901		2.35m - 37.9m / 82.2m             
17	28985	5.74		10.13		0.277		0.913		2.32m - 40.3m / 82.6m            
18	30690	5.57		9.35		0.280		0.913		2.32m - 42.6m / 82.1m             
19	32395	5.48		8.77		0.280		0.925		2.33m - 44.9m / 82.1m             
Best f1 0.2846998032657083                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 49.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         49                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.5575750418662222e-11              |
|  noam_learning_rate_warmup   |                        8945                       |
|  noam_learning_rate_factor   |                 0.4370248966409628                |
|          adam_beta1          |                 0.7061097141551297                |
|          adam_beta2          |                 0.7575731163585873                |
|           adam_eps           |               3.590464351061493e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.07599769358910914                |
|     pointwise_layer_size     |                        318                        |
|      last_layer_dropout      |                0.29511644400526355                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         42                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 28%|██▊       | 28/100 [7:20:57<24:04:39, 1203.88s/it, best loss: 8.45468438776528]
Epoch 28
100% 348/348 [19:46<00:00, 8.70it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	348	21.65		13.17		0.244		0.959		0.72m - 0.7m / 0.0m                 
2	696	14.45		13.73		0.239		0.909		0.71m - 1.4m / 25.0m                
3	1044	14.29		13.09		0.241		0.909		0.71m - 2.1m / 24.9m               
4	1392	13.58		12.32		0.266		0.925		0.71m - 2.9m / 24.8m               
5	1740	12.31		11.60		0.275		0.924		0.71m - 3.6m / 24.9m               
6	2088	11.53		12.02		0.275		0.867		0.71m - 4.3m / 24.9m               
7	2436	10.84		11.25		0.298		0.928		0.70m - 5.0m / 24.8m               
8	2784	10.22		11.44		0.291		0.882		0.70m - 5.7m / 24.6m               
9	3132	9.44		11.29		0.303		0.910		0.71m - 6.4m / 24.7m                
10	3480	8.79		11.74		0.318		0.931		0.70m - 7.1m / 24.7m               
11	3828	7.99		11.97		0.322		0.934		0.70m - 7.8m / 24.6m               
12	4176	7.44		11.07		0.323		0.924		0.70m - 8.5m / 24.6m               
13	4524	6.85		13.08		0.318		0.920		0.70m - 9.2m / 24.7m               
14	4872	6.10		13.39		0.330		0.938		0.70m - 9.9m / 24.7m               
15	5220	5.59		13.56		0.326		0.939		0.70m - 10.6m / 24.7m              
16	5568	5.12		14.26		0.332		0.931		0.71m - 11.3m / 24.7m              
17	5916	4.80		14.76		0.324		0.926		0.70m - 12.0m / 24.8m              
18	6264	4.48		15.11		0.331		0.933		0.70m - 12.7m / 24.7m              
19	6612	4.14		15.68		0.301		0.893		0.70m - 13.4m / 24.6m              
20	6960	4.00		16.54		0.337		0.948		0.70m - 14.1m / 24.7m              
21	7308	3.71		16.21		0.315		0.917		0.70m - 14.9m / 24.7m              
22	7656	3.72		14.69		0.331		0.926		0.70m - 15.6m / 24.7m              
23	8004	3.34		16.51		0.324		0.912		0.70m - 16.3m / 24.7m              
24	8352	3.26		16.92		0.340		0.947		0.70m - 17.0m / 24.7m              
25	8700	3.10		17.48		0.311		0.913		0.70m - 17.7m / 24.7m              
26	9048	3.07		16.69		0.326		0.905		0.70m - 18.4m / 24.7m              
27	9396	2.78		17.65		0.309		0.909		0.70m - 19.1m / 24.7m              
28	9744	2.58		20.02		0.337		0.941		0.70m - 19.8m / 24.7m              
Best f1 0.34022292162075163                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 21.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         21                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.6307921657859561e-09              |
|  noam_learning_rate_warmup   |                        6016                       |
|  noam_learning_rate_factor   |                 0.0259835313464174                |
|          adam_beta1          |                 0.8908042173883072                |
|          adam_beta2          |                 0.7333713267001604                |
|           adam_eps           |               1.7636835452589353e-07              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                 0.1547001067087861                |
|     pointwise_layer_size     |                        261                        |
|      last_layer_dropout      |                 0.5040681013963577                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        113                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 29%|██▉       | 29/100 [7:41:24<23:52:51, 1210.87s/it, best loss: 8.45468438776528]
Epoch 15
100% 812/812 [46:13<00:00, 4.73it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	812	21.06		10.55		0.244		0.959		3.05m - 3.1m / 0.0m                 
2	1624	11.52		10.43		0.244		0.959		3.06m - 6.1m / 106.9m              
3	2436	11.25		10.27		0.254		0.956		3.07m - 9.2m / 107.2m              
4	3248	10.44		9.07		0.273		0.933		3.08m - 12.3m / 107.5m              
5	4060	8.43		8.42		0.307		0.926		3.07m - 15.4m / 107.9m               
6	4872	6.64		9.23		0.319		0.931		3.08m - 18.4m / 107.5m               
7	5684	5.08		10.49		0.316		0.867		3.09m - 21.5m / 107.9m              
8	6496	3.83		10.38		0.338		0.941		3.08m - 24.6m / 108.0m              
9	7308	2.76		11.45		0.339		0.924		3.08m - 27.7m / 107.8m              
10	8120	2.05		11.46		0.331		0.935		3.08m - 30.8m / 107.8m             
11	8932	1.58		12.59		0.364		0.952		3.09m - 33.9m / 107.9m             
12	9744	1.29		12.57		0.341		0.934		3.08m - 37.0m / 107.9m             
13	10556	1.05		13.42		0.342		0.943		3.08m - 40.1m / 107.9m            
14	11368	0.86		13.99		0.345		0.943		3.09m - 43.1m / 107.9m            
15	12180	0.77		15.44		0.354		0.952		3.08m - 46.2m / 107.9m            
Best f1 0.36382897548073984                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 35.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         35                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.2453511248134036e-09              |
|  noam_learning_rate_warmup   |                        8854                       |
|  noam_learning_rate_factor   |                0.24432452278708183                |
|          adam_beta1          |                 0.7136978779046744                |
|          adam_beta2          |                 0.7837547522898349                |
|           adam_eps           |               1.7946775451364302e-05              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.03128225325962404                |
|     pointwise_layer_size     |                        129                        |
|      last_layer_dropout      |                 0.283846678871258                 |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         30                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 30%|███       | 30/100 [8:29:32<33:19:38, 1713.98s/it, best loss: 8.45468438776528]
Epoch 18
100% 487/487 [14:57<00:00, 10.36it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	487	22.92		12.28		0.234		0.917		0.83m - 0.8m / 0.0m                 
2	974	13.25		12.22		0.227		0.864		0.83m - 1.7m / 29.1m                
3	1461	13.09		12.05		0.250		0.925		0.83m - 2.5m / 29.1m               
4	1948	12.32		10.89		0.269		0.921		0.83m - 3.3m / 29.0m               
5	2435	11.36		12.28		0.271		0.906		0.83m - 4.2m / 29.0m               
6	2922	10.54		10.98		0.273		0.870		0.83m - 5.0m / 29.0m               
7	3409	9.96		10.04		0.297		0.926		0.83m - 5.8m / 29.1m                
8	3896	9.43		11.06		0.293		0.900		0.83m - 6.7m / 29.2m                
9	4383	8.73		10.16		0.308		0.917		0.83m - 7.5m / 29.0m                
10	4870	8.17		10.36		0.312		0.935		0.83m - 8.3m / 29.0m               
11	5357	7.66		10.52		0.323		0.943		0.83m - 9.2m / 29.0m               
12	5844	7.18		10.63		0.327		0.939		0.83m - 10.0m / 29.1m              
13	6331	6.71		10.82		0.316		0.931		0.83m - 10.8m / 29.1m              
14	6818	6.19		11.87		0.330		0.945		0.83m - 11.6m / 29.0m              
15	7305	5.76		12.45		0.326		0.950		0.83m - 12.5m / 29.0m              
16	7792	5.61		12.10		0.306		0.911		0.83m - 13.3m / 29.1m              
17	8279	5.14		13.05		0.318		0.939		0.83m - 14.1m / 29.0m              
18	8766	4.72		12.37		0.312		0.906		0.83m - 15.0m / 29.0m              
Best f1 0.3298961085692401                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 66.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         66                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               7.513083566081126e-09               |
|  noam_learning_rate_warmup   |                        2562                       |
|  noam_learning_rate_factor   |                 0.608729489883024                 |
|          adam_beta1          |                 0.9958189330297343                |
|          adam_beta2          |                 0.8203393674408936                |
|           adam_eps           |               1.2871995076193585e-06              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.12013770169394739                |
|     pointwise_layer_size     |                        245                        |
|      last_layer_dropout      |                 0.4915441066636819                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         62                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 31%|███       | 31/100 [8:45:13<28:24:19, 1482.02s/it, best loss: 8.45468438776528]
Epoch 6
100% 259/259 [06:04<00:00, 4.31it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	259	18.96		171.02		0.232		0.910		1.04m - 1.0m / 0.0m                
2	518	48.41		450.01		0.234		0.917		1.03m - 2.1m / 36.5m               
3	777	136.75		460.94		0.223		0.872		1.00m - 3.1m / 36.2m              
4	1036	104.56		486.24		0.233		0.912		1.00m - 4.1m / 35.2m             
5	1295	40.40		537.03		0.232		0.911		1.00m - 5.1m / 35.0m              
6	1554	106.91		517.76		0.223		0.872		1.00m - 6.1m / 35.0m             
Best f1 0.2338251662416125                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 12.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         12                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               5.156534731887596e-08               |
|  noam_learning_rate_warmup   |                        4757                       |
|  noam_learning_rate_factor   |                0.31468992695744097                |
|          adam_beta1          |                 0.8016391446405224                |
|          adam_beta2          |                 0.7875599982308569                |
|           adam_eps           |               4.023485228513645e-08               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.04805460624200935                |
|     pointwise_layer_size     |                        386                        |
|      last_layer_dropout      |                0.15379776927931135                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         74                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 32%|███▏      | 32/100 [8:52:08<21:56:51, 1161.94s/it, best loss: 8.45468438776528]
Epoch 14
100% 1421/1421 [43:05<00:00, 8.01it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	1421	10.73		9.02		0.244		0.959		3.08m - 3.1m / 0.0m                 
2	2842	9.45		8.21		0.266		0.954		3.08m - 6.2m / 107.9m                
3	4263	9.26		8.54		0.258		0.943		3.08m - 9.3m / 107.8m                
4	5684	9.15		8.89		0.256		0.919		3.09m - 12.3m / 107.7m               
5	7105	8.38		8.44		0.268		0.918		3.09m - 15.4m / 108.3m               
6	8526	7.50		8.75		0.276		0.939		3.09m - 18.5m / 108.0m               
7	9947	6.98		8.57		0.275		0.939		3.08m - 21.6m / 108.1m               
8	11368	6.61		8.53		0.270		0.909		3.08m - 24.7m / 107.8m              
9	12789	6.24		9.00		0.281		0.919		3.08m - 27.8m / 107.8m              
10	14210	6.04		8.22		0.283		0.924		3.08m - 30.8m / 107.8m             
11	15631	5.83		9.22		0.268		0.893		3.08m - 33.9m / 107.8m             
12	17052	5.63		9.66		0.267		0.870		3.08m - 37.0m / 107.8m             
13	18473	5.56		9.36		0.276		0.904		3.07m - 40.1m / 107.9m             
14	19894	5.36		9.39		0.274		0.890		3.00m - 43.1m / 107.7m             
Best f1 0.28256845213557685                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 37.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         37                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.594902609041939e-10               |
|  noam_learning_rate_warmup   |                        5788                       |
|  noam_learning_rate_factor   |                 0.6289419373604423                |
|          adam_beta1          |                 0.904058021572045                 |
|          adam_beta2          |                 0.7432462987867515                |
|           adam_eps           |               2.727407252474686e-10               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                0.20650576869631873                |
|     pointwise_layer_size     |                        324                        |
|      last_layer_dropout      |                 0.5518842111112724                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        118                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 33%|███▎      | 33/100 [9:36:53<30:07:47, 1618.92s/it, best loss: 8.45468438776528]
Epoch 10
100% 461/461 [18:25<00:00, 4.46it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	461	16.16		11.83		0.251		0.917		1.84m - 1.8m / 0.0m                 
2	922	8.35		11.55		0.310		0.916		1.83m - 3.7m / 64.3m                 
3	1383	3.98		12.85		0.323		0.921		1.84m - 5.5m / 64.0m                
4	1844	2.73		16.95		0.339		0.945		1.85m - 7.4m / 64.2m                
5	2305	2.26		18.01		0.336		0.932		1.84m - 9.2m / 64.6m                
6	2766	2.28		20.79		0.340		0.949		1.84m - 11.0m / 64.5m               
7	3227	2.26		19.11		0.322		0.941		1.84m - 12.9m / 64.4m               
8	3688	2.54		22.17		0.330		0.951		1.84m - 14.7m / 64.5m               
9	4149	2.46		20.11		0.312		0.930		1.84m - 16.6m / 64.4m               
10	4610	2.62		17.73		0.319		0.907		1.84m - 18.4m / 64.5m              
Best f1 0.3401540153221524                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 26.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         26                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               4.464299843523621e-08               |
|  noam_learning_rate_warmup   |                        3098                       |
|  noam_learning_rate_factor   |                 0.8929308225284796                |
|          adam_beta1          |                 0.865236170851431                 |
|          adam_beta2          |                 0.7002244242588889                |
|           adam_eps           |               3.2091919337334153e-06              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                0.08283519381958263                |
|     pointwise_layer_size     |                        464                        |
|      last_layer_dropout      |                 0.650664858245781                 |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        165                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 34%|███▍      | 34/100 [9:56:32<27:15:41, 1486.99s/it, best loss: 8.45468438776528]
Epoch 5
100% 656/656 [19:38<00:00, 2.95it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	656	14.07		11.53		0.243		0.899		3.93m - 3.9m / 0.0m                  
2	1312	12.90		12.39		0.241		0.917		3.93m - 7.9m / 137.5m               
3	1968	14.19		13.92		0.223		0.874		3.93m - 11.8m / 137.6m              
4	2624	14.20		12.50		0.234		0.916		3.93m - 15.7m / 137.4m              
5	3280	13.96		13.50		0.223		0.874		3.93m - 19.6m / 137.4m              
Best f1 0.24296469444415436                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 73.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         73                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.5048326098934745e-07              |
|  noam_learning_rate_warmup   |                        2127                       |
|  noam_learning_rate_factor   |                 0.3383350896685914                |
|          adam_beta1          |                 0.8276586353055162                |
|          adam_beta2          |                 0.7693994025773293                |
|           adam_eps           |               4.344096960885726e-05               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.44551466334967915                |
|     pointwise_layer_size     |                        426                        |
|      last_layer_dropout      |                0.009686456737690221               |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         29                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 35%|███▌      | 35/100 [10:18:29<25:55:34, 1435.92s/it, best loss: 8.45468438776528]
Epoch 6
100% 234/234 [04:05<00:00, 6.54it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	234	19.54		14.70		0.234		0.916		0.69m - 0.7m / 0.0m                  
2	468	15.90		14.35		0.244		0.959		0.68m - 1.4m / 24.0m                 
3	702	15.84		15.17		0.241		0.915		0.68m - 2.1m / 23.7m                 
4	936	15.72		14.89		0.241		0.885		0.68m - 2.7m / 23.9m                 
5	1170	15.15		15.47		0.243		0.906		0.68m - 3.4m / 23.9m                
6	1404	14.74		16.46		0.226		0.771		0.68m - 4.1m / 23.9m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 59.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         59                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                9.12731079299625e-09               |
|  noam_learning_rate_warmup   |                        1059                       |
|  noam_learning_rate_factor   |                 0.8754267390566313                |
|          adam_beta1          |                 0.7841418888094442                |
|          adam_beta2          |                 0.8584614839238234                |
|           adam_eps           |                0.012304539699691142               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                 0.2618228427925323                |
|     pointwise_layer_size     |                        295                        |
|      last_layer_dropout      |                0.31498537203529664                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         78                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 36%|███▌      | 36/100 [10:23:15<19:23:31, 1090.81s/it, best loss: 8.45468438776528]
Epoch 13
100% 289/289 [17:32<00:00, 3.83it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	289	17.16		13.95		0.223		0.874		1.35m - 1.3m / 0.0m                  
2	578	15.72		14.77		0.194		0.737		1.35m - 2.7m / 47.2m                 
3	867	15.65		14.73		0.223		0.872		1.35m - 4.0m / 47.1m                 
4	1156	15.68		15.23		0.223		0.857		1.35m - 5.4m / 47.2m                
5	1445	15.46		14.71		0.234		0.910		1.35m - 6.7m / 47.2m                
6	1734	15.39		14.68		0.244		0.959		1.35m - 8.1m / 47.1m                
7	2023	15.18		13.63		0.246		0.944		1.35m - 9.5m / 47.3m                
8	2312	14.96		13.99		0.245		0.948		1.35m - 10.8m / 47.2m               
9	2601	14.88		13.87		0.246		0.938		1.35m - 12.2m / 47.2m               
10	2890	14.94		13.91		0.244		0.951		1.35m - 13.5m / 47.2m              
11	3179	14.91		13.61		0.244		0.916		1.35m - 14.9m / 47.2m              
12	3468	14.55		13.39		0.244		0.930		1.35m - 16.2m / 47.2m              
13	3757	14.21		13.05		0.244		0.930		1.35m - 17.5m / 47.2m              
Best f1 0.2456028006436549                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 29.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         29                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               2.8226130889180267e-10              |
|  noam_learning_rate_warmup   |                        8518                       |
|  noam_learning_rate_factor   |                 0.1845863764390605                |
|          adam_beta1          |                 0.8117443392911325                |
|          adam_beta2          |                 0.8022386251181077                |
|           adam_eps           |               0.0002581788282344568               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         3                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.005606829768272495               |
|     pointwise_layer_size     |                        324                        |
|      last_layer_dropout      |                0.25086003644817534                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         53                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 37%|███▋      | 37/100 [10:41:49<19:12:41, 1097.80s/it, best loss: 8.45468438776528]
Epoch 15
100% 588/588 [12:13<00:00, 12.64it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	588	21.29		11.39		0.244		0.959		0.82m - 0.8m / 0.0m                  
2	1176	12.45		11.48		0.235		0.895		0.81m - 1.6m / 28.6m                
3	1764	12.15		10.88		0.252		0.937		0.81m - 2.4m / 28.5m                
4	2352	11.23		9.84		0.283		0.940		0.81m - 3.3m / 28.4m                 
5	2940	9.87		10.00		0.283		0.906		0.81m - 4.1m / 28.5m                 
6	3528	8.94		9.39		0.304		0.935		0.81m - 4.9m / 28.5m                  
7	4116	8.02		9.73		0.315		0.930		0.81m - 5.7m / 28.4m                  
8	4704	6.95		9.72		0.335		0.934		0.81m - 6.5m / 28.5m                  
9	5292	5.93		9.80		0.322		0.914		0.81m - 7.3m / 28.5m                  
10	5880	5.03		10.42		0.332		0.945		0.81m - 8.2m / 28.4m                
11	6468	4.19		11.38		0.350		0.951		0.81m - 9.0m / 28.5m                
12	7056	3.52		10.37		0.349		0.940		0.81m - 9.8m / 28.4m                
13	7644	2.91		12.32		0.346		0.927		0.81m - 10.6m / 28.5m               
14	8232	2.60		13.60		0.333		0.936		0.81m - 11.4m / 28.5m               
15	8820	2.20		12.60		0.339		0.941		0.81m - 12.2m / 28.5m               
Best f1 0.34965148791938216                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 19.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         19                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.011479381795191e-06               |
|  noam_learning_rate_warmup   |                        7566                       |
|  noam_learning_rate_factor   |                 0.1010263172983154                |
|          adam_beta1          |                 0.8672346438931117                |
|          adam_beta2          |                 0.7247592806011792                |
|           adam_eps           |               1.434586616519111e-07               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                0.15586268680772725                |
|     pointwise_layer_size     |                        373                        |
|      last_layer_dropout      |                0.06540750558679709                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        140                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 38%|███▊      | 38/100 [10:54:43<17:14:03, 1000.70s/it, best loss: 8.45468438776528]
Epoch 19
100% 897/897 [49:05<00:00, 5.88it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	897	17.01		10.02		0.245		0.954		2.57m - 2.6m / 0.0m                  
2	1794	11.05		10.18		0.245		0.959		2.58m - 5.2m / 90.1m                
3	2691	10.39		8.67		0.292		0.935		2.58m - 7.7m / 90.2m                 
4	3588	8.58		8.98		0.298		0.912		2.58m - 10.3m / 90.3m                 
5	4485	6.93		8.18		0.324		0.938		2.58m - 12.9m / 90.3m                 
6	5382	5.51		9.19		0.323		0.931		2.59m - 15.5m / 90.4m                 
7	6279	4.20		10.54		0.338		0.941		2.58m - 18.1m / 90.7m                
8	7176	3.30		10.61		0.338		0.947		2.61m - 20.7m / 90.4m                
9	8073	2.58		11.20		0.347		0.951		2.59m - 23.3m / 91.1m                
10	8970	2.04		14.09		0.354		0.961		2.60m - 25.9m / 90.7m               
11	9867	1.56		12.62		0.342		0.940		2.58m - 28.5m / 90.9m               
12	10764	1.22		12.99		0.345		0.955		2.58m - 31.1m / 90.3m              
13	11661	1.04		16.44		0.356		0.962		2.57m - 33.6m / 90.3m              
14	12558	0.85		15.46		0.361		0.955		2.58m - 36.2m / 90.2m              
15	13455	0.72		16.38		0.366		0.962		2.57m - 38.8m / 90.4m              
16	14352	0.67		16.59		0.338		0.953		2.57m - 41.4m / 90.2m              
17	15249	0.59		16.68		0.346		0.955		2.58m - 43.9m / 90.3m              
18	16146	0.53		18.24		0.351		0.961		2.57m - 46.5m / 90.3m              
19	17043	0.52		18.85		0.350		0.958		2.57m - 49.1m / 90.3m              
Best f1 0.3660576174177372                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 47.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         47                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               3.887664082719425e-07               |
|  noam_learning_rate_warmup   |                        1494                       |
|  noam_learning_rate_factor   |                 0.4200129067482043                |
|          adam_beta1          |                 0.9667419386050078                |
|          adam_beta2          |                 0.7687481026318659                |
|           adam_eps           |               2.1895152662577703e-08              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                 0.6651294510544854                |
|     pointwise_layer_size     |                         99                        |
|      last_layer_dropout      |                0.14886906955088103                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         31                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 39%|███▉      | 39/100 [11:45:25<27:19:51, 1612.98s/it, best loss: 8.45468438776528]
Epoch 10
100% 363/363 [06:50<00:00, 9.31it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	363	17.20		405.36		0.221		0.865		0.69m - 0.7m / 0.0m                 
2	726	132.47		1121.26		0.195		0.762		0.68m - 1.4m / 24.1m              
3	1089	1206.81		545.29		0.232		0.909		0.68m - 2.1m / 23.9m             
4	1452	841.17		1077.50		0.221		0.866		0.68m - 2.7m / 24.0m             
5	1815	479.25		747.50		0.232		0.909		0.68m - 3.4m / 23.9m              
6	2178	621.04		817.65		0.244		0.959		0.68m - 4.1m / 23.9m              
7	2541	464.97		622.65		0.244		0.959		0.68m - 4.8m / 23.9m              
8	2904	306.26		590.65		0.244		0.959		0.68m - 5.5m / 24.0m              
9	3267	188.00		530.21		0.244		0.959		0.68m - 6.2m / 24.0m              
10	3630	131.40		765.04		0.232		0.909		0.68m - 6.8m / 24.0m             
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 39.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         39                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |                0.03691578299340281                |
|  noam_learning_rate_warmup   |                        4733                       |
|  noam_learning_rate_factor   |                 1.9805512377495094                |
|          adam_beta1          |                 0.8428286255932426                |
|          adam_beta2          |                 0.8342830428676127                |
|           adam_eps           |               6.731583234075398e-05               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.35045048731078576                |
|     pointwise_layer_size     |                        229                        |
|      last_layer_dropout      |                 0.5825246540624475                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        196                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 40%|████      | 40/100 [11:52:45<21:01:07, 1261.13s/it, best loss: 8.45468438776528]
Epoch 9
100% 437/437 [18:57<00:00, 3.62it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	437	15.98		13.20		0.232		0.910		2.10m - 2.1m / 0.0m                  
2	874	14.16		12.84		0.239		0.897		2.10m - 4.2m / 73.6m                 
3	1311	13.53		13.07		0.256		0.924		2.11m - 6.3m / 73.6m                
4	1748	12.67		12.86		0.270		0.932		2.11m - 8.4m / 73.8m                
5	2185	12.31		13.38		0.271		0.915		2.11m - 10.6m / 73.8m               
6	2622	11.99		13.30		0.263		0.895		2.11m - 12.7m / 73.7m               
7	3059	12.16		12.38		0.271		0.939		2.10m - 14.8m / 73.8m               
8	3496	12.25		15.60		0.234		0.916		2.10m - 16.9m / 73.6m               
9	3933	14.20		14.90		0.223		0.874		2.10m - 19.0m / 73.5m               
Best f1 0.2712109338237173                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         17                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               5.027326686303944e-06               |
|  noam_learning_rate_warmup   |                        5946                       |
|  noam_learning_rate_factor   |                 0.6337767596354231                |
|          adam_beta1          |                 0.7648471914503553                |
|          adam_beta2          |                 0.7995946988064209                |
|           adam_eps           |               5.345305430796593e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         5                         |
|             d_k              |                         60                        |
|             d_v              |                         60                        |
|         dropout_rate         |                0.26254728496652735                |
|     pointwise_layer_size     |                        186                        |
|      last_layer_dropout      |                0.47649371270479135                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         67                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 41%|████      | 41/100 [12:13:06<20:28:11, 1249.01s/it, best loss: 8.45468438776528]
Epoch 5
100% 1003/1003 [10:26<00:00, 8.53it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1003	12.93		10.37		0.244		0.959		2.09m - 2.1m / 0.0m                 
2	2006	11.22		10.54		0.244		0.959		2.09m - 4.2m / 73.2m                
3	3009	11.28		10.69		0.244		0.959		2.08m - 6.3m / 73.0m                
4	4012	11.43		11.02		0.244		0.959		2.09m - 8.3m / 72.8m                
5	5015	11.46		10.64		0.244		0.959		2.09m - 10.4m / 73.1m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 23.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         23                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                 0.3217803950728811                |
|  noam_learning_rate_warmup   |                        2185                       |
|  noam_learning_rate_factor   |                 0.5444180164646952                |
|          adam_beta1          |                 0.9167071149658085                |
|          adam_beta2          |                 0.8762818144557527                |
|           adam_eps           |               7.334261693128304e-07               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                 0.444543224394738                 |
|     pointwise_layer_size     |                        482                        |
|      last_layer_dropout      |                0.24688764763489954                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        127                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 42%|████▏     | 42/100 [12:24:37<17:25:46, 1081.84s/it, best loss: 8.45468438776528]
Epoch 5
100% 741/741 [16:22<00:00, 4.07it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	741	13.07		11.96		0.244		0.959		3.26m - 3.3m / 0.0m                  
2	1482	12.52		11.91		0.244		0.959		3.28m - 6.5m / 114.2m               
3	2223	12.59		11.65		0.244		0.959		3.28m - 9.8m / 114.8m               
4	2964	12.48		11.75		0.244		0.959		3.28m - 13.1m / 114.9m              
5	3705	12.20		12.29		0.244		0.959		3.27m - 16.4m / 114.8m              
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 30.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         30                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.0029475078270815e-08              |
|  noam_learning_rate_warmup   |                        3232                       |
|  noam_learning_rate_factor   |                 1.1985140027128343                |
|          adam_beta1          |                 0.7995570946983036                |
|          adam_beta2          |                 0.8193114243401188                |
|           adam_eps           |                0.03513570378027051                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                0.12021499101523414                |
|     pointwise_layer_size     |                        428                        |
|      last_layer_dropout      |                 0.0397793639402636                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         11                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 43%|████▎     | 43/100 [12:42:55<17:12:24, 1086.74s/it, best loss: 8.45468438776528]
Epoch 5
100% 569/569 [02:54<00:00, 17.36it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	569	14.40		11.89		0.244		0.959		0.59m - 0.6m / 0.0m                  
2	1138	13.19		11.99		0.233		0.912		0.58m - 1.2m / 20.7m                
3	1707	13.37		12.14		0.232		0.911		0.58m - 1.8m / 20.4m                
4	2276	13.51		12.12		0.234		0.916		0.57m - 2.3m / 20.3m                
5	2845	13.42		11.76		0.233		0.915		0.58m - 2.9m / 20.1m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 51.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         51                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               2.0125351511979244e-08              |
|  noam_learning_rate_warmup   |                        8125                       |
|  noam_learning_rate_factor   |                 0.9529756675158223                |
|          adam_beta1          |                 0.9434965357630472                |
|          adam_beta2          |                 0.7768769168127256                |
|           adam_eps           |                0.003032971584344387               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                0.35548416235541885                |
|     pointwise_layer_size     |                        450                        |
|      last_layer_dropout      |                 0.1848992731042625                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        168                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 44%|████▍     | 44/100 [12:46:16<12:46:12, 820.93s/it, best loss: 8.45468438776528]
Epoch 5
100% 335/335 [15:21<00:00, 1.91it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	335	18.61		13.63		0.244		0.959		3.06m - 3.1m / 0.0m                 
2	670	14.62		13.49		0.244		0.959		3.06m - 6.1m / 107.2m               
3	1005	14.55		14.11		0.244		0.959		3.07m - 9.2m / 107.1m              
4	1340	14.58		13.37		0.240		0.895		3.08m - 12.3m / 107.4m             
5	1675	14.51		13.89		0.233		0.915		3.08m - 15.4m / 107.7m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 98.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         98                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.4672633681170661e-09              |
|  noam_learning_rate_warmup   |                        4351                       |
|  noam_learning_rate_factor   |                 0.8117084469480199                |
|          adam_beta1          |                 0.9029222633329912                |
|          adam_beta2          |                 0.8446297382795956                |
|           adam_eps           |                 0.9586106663986372                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                0.18733456582448352                |
|     pointwise_layer_size     |                        159                        |
|      last_layer_dropout      |                 0.4445430170776985                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        249                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                       False                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 45%|████▌     | 45/100 [13:03:33<13:31:53, 885.70s/it, best loss: 8.45468438776528]
Epoch 6
100% 174/174 [36:50<00:00, 2.00s/it]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	174	28.73		17.46		0.221		0.868		6.14m - 6.1m / 0.0m                 
2	348	17.36		15.42		0.244		0.959		6.14m - 12.3m / 214.9m              
3	522	16.49		15.11		0.244		0.959		6.14m - 18.4m / 214.9m              
4	696	16.46		15.15		0.244		0.959		6.14m - 24.6m / 214.8m              
5	870	16.43		15.07		0.244		0.959		6.14m - 30.7m / 214.9m              
6	1044	16.42		15.22		0.233		0.912		6.14m - 36.8m / 214.8m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 14.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         14                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               3.2246060385983857e-09              |
|  noam_learning_rate_warmup   |                        5159                       |
|  noam_learning_rate_factor   |                 1.4202437921822315                |
|          adam_beta1          |                 0.981753563891292                 |
|          adam_beta2          |                 0.7589893152989484                |
|           adam_eps           |               9.158645651875734e-09               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         3                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.04133895723930334                |
|     pointwise_layer_size     |                        280                        |
|      last_layer_dropout      |                 0.1180363066712761                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         92                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 46%|████▌     | 46/100 [13:43:51<20:10:52, 1345.41s/it, best loss: 8.45468438776528]
Epoch 5
100% 1218/1218 [07:35<00:00, 27.45s/it]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1218	68641.24		208379.83		0.219		0.859		1.52m - 1.5m / 0.0m          
2	2436	nan		nan		0.240		0.944		1.52m - 3.0m / 53.3m                    
3	3654	nan		nan		0.240		0.944		1.52m - 4.6m / 53.1m                    
4	4872	nan		nan		0.240		0.944		1.52m - 6.1m / 53.1m                    
5	6090	nan		nan		0.240		0.944		1.51m - 7.6m / 53.1m                    
Best f1 0.2191887409085896                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 10.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         10                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               1.251864622190076e-05               |
|  noam_learning_rate_warmup   |                        5465                       |
|  noam_learning_rate_factor   |                 1.127679243476648                 |
|          adam_beta1          |                 0.8645106029519317                |
|          adam_beta2          |                 0.7555692205473139                |
|           adam_eps           |               0.00017415834697836807              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.04343623797974872                |
|     pointwise_layer_size     |                        285                        |
|      last_layer_dropout      |                 0.1228192934378746                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         87                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 47%|████▋     | 47/100 [13:52:23<16:07:27, 1095.23s/it, best loss: 8.45468438776528]
Epoch 5
100% 1705/1705 [15:19<00:00, 10.22it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1705	10.39		8.91		0.244		0.959		3.07m - 3.1m / 0.0m                  
2	3410	9.99		9.42		0.244		0.959		3.07m - 6.1m / 107.3m                 
3	5115	9.94		9.07		0.234		0.916		3.06m - 9.2m / 107.3m                 
4	6820	9.54		9.00		0.244		0.959		3.06m - 12.3m / 107.2m                
5	8525	9.24		8.46		0.244		0.959		3.07m - 15.3m / 107.3m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 78.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         78                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               2.9446846117006814e-05              |
|  noam_learning_rate_warmup   |                        5639                       |
|  noam_learning_rate_factor   |                 1.4327366184454524                |
|          adam_beta1          |                 0.8582237132264553                |
|          adam_beta2          |                 0.7546184879765397                |
|           adam_eps           |               0.0001272240807314336               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.05192463103185194                |
|     pointwise_layer_size     |                        282                        |
|      last_layer_dropout      |                0.13299760337491418                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        138                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 48%|████▊     | 48/100 [14:09:15<15:27:40, 1070.39s/it, best loss: 8.45468438776528]
Epoch 9
100% 219/219 [12:20<00:00, 2.71it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	219	19.90		14.59		0.233		0.909		1.37m - 1.4m / 0.0m                  
2	438	15.96		14.18		0.249		0.944		1.37m - 2.7m / 47.9m                 
3	657	14.64		12.55		0.282		0.914		1.37m - 4.1m / 47.9m                 
4	876	11.43		12.11		0.305		0.930		1.37m - 5.5m / 48.0m                 
5	1095	9.12		13.44		0.323		0.927		1.37m - 6.9m / 47.9m                 
6	1314	7.25		14.91		0.306		0.839		1.37m - 8.2m / 47.9m                 
7	1533	5.75		16.11		0.320		0.921		1.37m - 9.6m / 47.8m                 
8	1752	5.02		16.03		0.317		0.904		1.37m - 11.0m / 47.8m                
9	1971	4.29		18.44		0.309		0.895		1.37m - 12.3m / 48.0m                
Best f1 0.3231203236575541                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 43.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         43                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                1.63166711558715e-05               |
|  noam_learning_rate_warmup   |                        5040                       |
|  noam_learning_rate_factor   |                 1.2983694184878791                |
|          adam_beta1          |                 0.8355422395446901                |
|          adam_beta2          |                 0.7103920904593402                |
|           adam_eps           |               0.0012302141914448336               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.2421236334177102                |
|     pointwise_layer_size     |                        224                        |
|      last_layer_dropout      |                0.11814321574794971                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        181                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 49%|████▉     | 49/100 [14:22:38<14:01:31, 990.02s/it, best loss: 8.45468438776528]
Epoch 5
100% 397/397 [12:17<00:00, 2.80it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	397	16.29		13.28		0.244		0.959		2.46m - 2.5m / 0.0m                 
2	794	14.37		13.62		0.233		0.912		2.45m - 4.9m / 86.1m                
3	1191	14.40		14.23		0.244		0.959		2.46m - 7.4m / 85.9m               
4	1588	14.52		13.54		0.234		0.917		2.46m - 9.8m / 86.0m               
5	1985	14.61		13.56		0.234		0.917		2.46m - 12.3m / 86.0m              
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 15.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         15                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               7.133227317692451e-06               |
|  noam_learning_rate_warmup   |                        6765                       |
|  noam_learning_rate_factor   |                 1.1010017814020774                |
|          adam_beta1          |                 0.939681416830642                 |
|          adam_beta2          |                 0.7405707337346189                |
|           adam_eps           |                0.06779636068232742                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.6091316684625818                |
|     pointwise_layer_size     |                        343                        |
|      last_layer_dropout      |                0.05171744124239516                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         87                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 50%|█████     | 50/100 [14:36:24<13:04:03, 940.87s/it, best loss: 8.45468438776528]
Epoch 7
100% 1137/1137 [17:13<00:00, 8.06it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	1137	12.60		10.13		0.244		0.959		2.46m - 2.5m / 0.0m                
2	2274	10.34		10.31		0.234		0.916		2.46m - 4.9m / 86.0m               
3	3411	10.33		10.36		0.245		0.948		2.46m - 7.4m / 86.0m               
4	4548	10.39		10.75		0.244		0.953		2.46m - 9.8m / 86.1m               
5	5685	10.35		10.00		0.243		0.946		2.46m - 12.3m / 86.2m              
6	6822	10.37		10.62		0.238		0.906		2.46m - 14.8m / 86.1m              
7	7959	10.34		10.91		0.244		0.959		2.46m - 17.2m / 86.1m              
Best f1 0.24500200446159348                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 86.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         86                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               7.200868973821766e-05               |
|  noam_learning_rate_warmup   |                        6263                       |
|  noam_learning_rate_factor   |                 1.4186667548276133                |
|          adam_beta1          |                 0.8130724900257169                |
|          adam_beta2          |                 0.7173490905841432                |
|           adam_eps           |                0.00081407858467921                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         2                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.3024247604198044                |
|     pointwise_layer_size     |                        405                        |
|      last_layer_dropout      |                 0.7960208976624636                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        113                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 51%|█████     | 51/100 [14:55:04<13:32:15, 994.61s/it, best loss: 8.45468438776528]
Epoch 19
100% 199/199 [13:17<00:00, 5.11it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	199	21.51		14.66		0.244		0.959		0.70m - 0.7m / 0.0m                 
2	398	16.27		15.27		0.244		0.950		0.70m - 1.4m / 24.5m                
3	597	16.22		15.12		0.246		0.932		0.70m - 2.1m / 24.5m                
4	796	15.96		14.62		0.247		0.932		0.69m - 2.8m / 24.4m                
5	995	15.41		13.65		0.254		0.910		0.70m - 3.5m / 24.3m                
6	1194	13.47		12.97		0.287		0.884		0.70m - 4.2m / 24.5m               
7	1393	11.64		14.80		0.301		0.901		0.70m - 4.9m / 24.5m               
8	1592	10.05		15.07		0.302		0.892		0.70m - 5.6m / 24.4m               
9	1791	8.39		18.03		0.330		0.929		0.70m - 6.3m / 24.4m                
10	1990	7.03		19.06		0.328		0.935		0.70m - 7.0m / 24.5m               
11	2189	5.61		19.18		0.332		0.918		0.69m - 7.7m / 24.4m               
12	2388	4.58		23.50		0.370		0.951		0.70m - 8.4m / 24.4m               
13	2587	4.04		24.60		0.360		0.949		0.69m - 9.1m / 24.5m               
14	2786	3.56		23.91		0.359		0.952		0.70m - 9.8m / 24.4m               
15	2985	2.98		29.86		0.375		0.959		0.69m - 10.5m / 24.5m              
16	3184	2.90		27.45		0.362		0.958		0.70m - 11.2m / 24.4m              
17	3383	2.53		35.40		0.363		0.964		0.69m - 11.9m / 24.4m              
18	3582	2.43		32.08		0.365		0.961		0.69m - 12.6m / 24.3m              
19	3781	2.30		30.69		0.353		0.955		0.70m - 13.3m / 24.4m              
Best f1 0.3746614206692979                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 33.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         33                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.004025435455434316               |
|  noam_learning_rate_warmup   |                        5390                       |
|  noam_learning_rate_factor   |                 1.5507678725242722                |
|          adam_beta1          |                 0.8725506405606333                |
|          adam_beta2          |                 0.7018425518507563                |
|           adam_eps           |               2.354125329014908e-05               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.4635211722732885                |
|     pointwise_layer_size     |                        198                        |
|      last_layer_dropout      |                0.20182197786121986                |
|   output_conv_num_filters    |                        192                        |
|   output_conv_kernel_size    |                         1                         |
|      output_conv_stride      |                         1                         |
|     output_conv_padding      |                         0                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        157                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 52%|█████▏    | 52/100 [15:09:00<12:37:46, 947.23s/it, best loss: 8.45468438776528]
Epoch 8
100% 517/517 [30:28<00:00, 2.45it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	517	15.05		19.04		0.198		0.771		3.81m - 3.8m / 0.0m                 
2	1034	15.01		21.42		0.137		0.532		3.81m - 7.6m / 133.3m              
3	1551	15.88		18.08		0.211		0.825		3.81m - 11.4m / 133.3m             
4	2068	15.18		13.16		0.244		0.959		3.81m - 15.2m / 133.3m             
5	2585	14.82		14.24		0.244		0.959		3.81m - 19.1m / 133.3m             
6	3102	15.33		14.10		0.244		0.959		3.81m - 22.9m / 133.2m             
7	3619	14.54		13.25		0.244		0.959		3.80m - 26.7m / 133.3m             
8	4136	14.19		13.53		0.244		0.959		3.80m - 30.5m / 133.2m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 60.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         60                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.0009455232576389437               |
|  noam_learning_rate_warmup   |                        3953                       |
|  noam_learning_rate_factor   |                 1.0849401722538008                |
|          adam_beta1          |                 0.9793327491409841                |
|          adam_beta2          |                 0.820920518976496                 |
|           adam_eps           |               3.5987470092261466e-07              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         3                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                 0.3724467087640712                |
|     pointwise_layer_size     |                        241                        |
|      last_layer_dropout      |                0.17017771330055648                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         96                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 53%|█████▎    | 53/100 [15:41:57<16:23:54, 1256.05s/it, best loss: 8.45468438776528]
Epoch 8
100% 285/285 [07:58<00:00, 4.97it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	285	19.44		164.13		0.222		0.869		1.02m - 1.0m / 0.0m                 
2	570	15.38		257.75		0.233		0.912		1.01m - 2.0m / 35.5m                
3	855	38.20		151.58		0.211		0.826		1.02m - 3.0m / 35.4m                
4	1140	26.53		137.37		0.244		0.959		1.01m - 4.0m / 35.5m               
5	1425	35.22		218.25		0.221		0.867		1.00m - 5.0m / 35.2m               
6	1710	28.64		180.68		0.234		0.916		0.98m - 6.0m / 35.0m               
7	1995	41.94		158.32		0.244		0.959		0.98m - 7.0m / 34.4m               
8	2280	45.78		179.64		0.244		0.959		0.97m - 8.0m / 34.4m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 24.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         24                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               6.9242522734665855e-06              |
|  noam_learning_rate_warmup   |                        4724                       |
|  noam_learning_rate_factor   |                 1.7735982052690908                |
|          adam_beta1          |                 0.8939765479744509                |
|          adam_beta2          |                 0.9027636217439918                |
|           adam_eps           |               7.431787695704793e-09               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         1                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                0.023422819410458443               |
|     pointwise_layer_size     |                        376                        |
|      last_layer_dropout      |                0.002533793396410036               |
|   output_conv_num_filters    |                        393                        |
|   output_conv_kernel_size    |                         1                         |
|      output_conv_stride      |                         2                         |
|     output_conv_padding      |                         3                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        120                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 54%|█████▍    | 54/100 [15:50:34<13:13:04, 1034.44s/it, best loss: 8.45468438776528]
Epoch 1
0% 0/711 [00:00<?, ?it/s]
Exception while training: size mismatch, m1: [9432 x 2], m2: [393 x 4] at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/THC/generic/THCTensorMathBlas.cu:266
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 13.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         13                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               3.394048577136343e-05               |
|  noam_learning_rate_warmup   |                        3524                       |
|  noam_learning_rate_factor   |                 0.7012919122735363                |
|          adam_beta1          |                 0.914601848340792                 |
|          adam_beta2          |                 0.8553741949022029                |
|           adam_eps           |               0.00013823438209932865              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.14028761334410506                |
|     pointwise_layer_size     |                        489                        |
|      last_layer_dropout      |                0.35666089656415456                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        195                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 55%|█████▌    | 55/100 [15:50:48<9:06:07, 728.17s/it, best loss: 8.45468438776528]
Epoch 5
100% 1311/1311 [18:18<00:00, 6.17it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	1311	11.25		10.13		0.244		0.959		3.65m - 3.7m / 0.0m               
2	2622	10.76		10.14		0.244		0.959		3.67m - 7.3m / 127.8m             
3	3933	10.56		9.79		0.244		0.959		3.66m - 11.0m / 128.4m             
4	5244	10.26		10.07		0.244		0.959		3.67m - 14.7m / 128.2m            
5	6555	10.16		9.55		0.244		0.959		3.66m - 18.3m / 128.3m             
Best f1 0.2441399350742839                                                         
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 93.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         93                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               3.0961347301891012e-06              |
|  noam_learning_rate_warmup   |                        6517                       |
|  noam_learning_rate_factor   |                 1.253807281866454                 |
|          adam_beta1          |                 0.8541367171308426                |
|          adam_beta2          |                 0.756679150249404                 |
|           adam_eps           |               3.9785665284663716e-10              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                0.18611787591170248                |
|     pointwise_layer_size     |                        413                        |
|      last_layer_dropout      |                0.10483410858287578                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         57                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 56%|█████▌    | 56/100 [16:11:07<10:41:59, 875.44s/it, best loss: 8.45468438776528]
Epoch 13
100% 184/184 [14:17<00:00, 2.94it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	184	20.83		14.98		0.223		0.873		1.10m - 1.1m / 0.0m                 
2	368	16.71		14.80		0.222		0.870		1.10m - 2.2m / 38.6m                
3	552	16.61		15.09		0.222		0.868		1.10m - 3.3m / 38.4m                
4	736	16.42		15.16		0.220		0.863		1.10m - 4.4m / 38.5m                
5	920	16.56		15.37		0.234		0.916		1.10m - 5.5m / 38.5m                
6	1104	16.61		15.18		0.222		0.870		1.10m - 6.6m / 38.4m               
7	1288	16.63		15.27		0.234		0.916		1.10m - 7.7m / 38.5m               
8	1472	16.63		15.82		0.234		0.917		1.10m - 8.8m / 38.4m               
9	1656	16.57		15.50		0.244		0.959		1.10m - 9.9m / 38.4m               
10	1840	16.69		14.84		0.232		0.910		1.10m - 11.0m / 38.4m             
11	2024	16.63		15.47		0.223		0.873		1.10m - 12.1m / 38.5m             
12	2208	16.83		15.70		0.234		0.916		1.09m - 13.2m / 38.4m             
13	2392	16.78		15.27		0.244		0.959		1.10m - 14.3m / 38.4m             
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 28.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         28                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               5.186166215382137e-07               |
|  noam_learning_rate_warmup   |                        7194                       |
|  noam_learning_rate_factor   |                 1.3715377229580625                |
|          adam_beta1          |                 0.9330299221133984                |
|          adam_beta2          |                 0.8110368409812794                |
|           adam_eps           |               2.105545973990397e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                0.29319127935335065                |
|     pointwise_layer_size     |                        257                        |
|      last_layer_dropout      |                0.22614398862668741                |
|   output_conv_num_filters    |                        101                        |
|   output_conv_kernel_size    |                         6                         |
|      output_conv_stride      |                         10                        |
|     output_conv_padding      |                         5                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         82                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 57%|█████▋    | 57/100 [16:26:09<10:33:04, 883.37s/it, best loss: 8.45468438776528]
Epoch 5
100% 609/609 [11:12<00:00, 4.82it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	609	14.24		12.28		0.244		0.959		2.24m - 2.2m / 0.0m                 
2	1218	13.73		12.60		0.234		0.916		2.23m - 4.5m / 78.4m               
3	1827	13.30		13.75		0.244		0.959		2.24m - 6.7m / 78.2m               
4	2436	13.34		13.44		0.234		0.916		2.24m - 9.0m / 78.5m               
5	3045	13.61		13.69		0.244		0.959		2.25m - 11.2m / 78.4m              
Best f1 0.2441399350742839                                                          
+----------------------------------------------------------------------------------+
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 39.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         39                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               0.00031317973182371834              |
|  noam_learning_rate_warmup   |                        5300                       |
|  noam_learning_rate_factor   |                 1.9431074032392437                |
|          adam_beta1          |                 0.954856415184443                 |
|          adam_beta2          |                 0.7346195605464494                |
|           adam_eps           |                0.28228387190980275                |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                 0.7025240432507688                |
|     pointwise_layer_size     |                         53                        |
|      last_layer_dropout      |                0.32835690688496083                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        135                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 58%|█████▊    | 58/100 [16:38:49<9:52:30, 846.44s/it, best loss: 8.45468438776528]
Epoch 9
100% 437/437 [24:52<00:00, 2.78it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                         
1	437	18.33		13.69		0.244		0.958		2.76m - 2.8m / 0.0m                
2	874	13.61		13.98		0.244		0.949		2.76m - 5.5m / 96.6m               
3	1311	13.54		14.18		0.244		0.955		2.76m - 8.3m / 96.6m              
4	1748	13.58		14.15		0.244		0.939		2.76m - 11.0m / 96.6m             
5	2185	13.48		14.22		0.244		0.910		2.77m - 13.8m / 96.6m             
6	2622	13.45		13.58		0.231		0.881		2.77m - 16.6m / 96.9m             
7	3059	13.46		14.31		0.244		0.916		2.76m - 19.3m / 96.8m             
8	3496	13.47		15.09		0.243		0.910		2.76m - 22.1m / 96.7m             
9	3933	13.40		14.66		0.229		0.838		2.76m - 24.9m / 96.8m             
Best f1 0.24435870798744705                                                        
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 10.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         10                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               2.0912882296752392e-07              |
|  noam_learning_rate_warmup   |                        4203                       |
|  noam_learning_rate_factor   |                 1.5117409610618269                |
|          adam_beta1          |                 0.8764674161084126                |
|          adam_beta2          |                 0.7901979714669914                |
|           adam_eps           |               8.280407960096286e-08               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.10138493174996052                |
|     pointwise_layer_size     |                        360                        |
|      last_layer_dropout      |                 0.6893620962879203                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        105                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 59%|█████▉    | 59/100 [17:05:30<12:13:01, 1072.71s/it, best loss: 8.45468438776528]
Epoch 6
100% 1705/1705 [20:34<00:00, 9.16it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1705	10.59		9.44		0.234		0.917		3.43m - 3.4m / 0.0m                  
2	3410	10.51		9.28		0.244		0.959		3.42m - 6.9m / 119.9m                
3	5115	10.07		8.79		0.244		0.959		3.43m - 10.3m / 119.9m               
4	6820	9.42		8.86		0.244		0.959		3.43m - 13.7m / 120.0m                
5	8525	9.18		8.51		0.244		0.959		3.43m - 17.1m / 119.9m                
6	10230	9.14		8.51		0.244		0.959		3.43m - 20.6m / 120.0m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 20.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         20                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               1.5474670450619347e-05              |
|  noam_learning_rate_warmup   |                        1676                       |
|  noam_learning_rate_factor   |                 1.0090843510061063                |
|          adam_beta1          |                 0.7509849594563678                |
|          adam_beta2          |                 0.948960681645239                 |
|           adam_eps           |               7.771546054224573e-06               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         4                         |
|           n_heads            |                         4                         |
|             d_k              |                         75                        |
|             d_v              |                         75                        |
|         dropout_rate         |                 0.557668590708495                 |
|     pointwise_layer_size     |                        124                        |
|      last_layer_dropout      |                0.39645484570586154                |
|   output_conv_num_filters    |                        194                        |
|   output_conv_kernel_size    |                         10                        |
|      output_conv_stride      |                         6                         |
|     output_conv_padding      |                         0                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        151                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 60%|██████    | 60/100 [17:27:46<12:47:50, 1151.75s/it, best loss: 8.45468438776528]
Epoch 10
100% 853/853 [34:38<00:00, 4.27it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	853	14.27		111.22		0.024		0.083		3.48m - 3.5m / 0.0m                 
2	1706	18.62		37.17		0.074		0.285		3.48m - 7.0m / 121.7m               
3	2559	17.41		34.27		0.058		0.216		3.48m - 10.5m / 121.9m              
4	3412	13.57		18.77		0.172		0.668		3.46m - 13.9m / 121.9m              
5	4265	12.09		15.91		0.234		0.916		3.46m - 17.4m / 121.1m              
6	5118	11.66		13.12		0.244		0.959		3.46m - 20.8m / 121.2m              
7	5971	11.58		20.10		0.234		0.916		3.46m - 24.3m / 121.2m              
8	6824	11.54		14.61		0.244		0.959		3.45m - 27.8m / 121.1m              
9	7677	11.53		10.83		0.244		0.959		3.44m - 31.2m / 120.8m              
10	8530	11.57		12.38		0.244		0.959		3.44m - 34.6m / 120.7m             
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 35.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         35                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.17152447717270863                |
|  noam_learning_rate_warmup   |                        6258                       |
|  noam_learning_rate_factor   |                 0.8339594596239759                |
|          adam_beta1          |                 0.8203221960427474                |
|          adam_beta2          |                 0.7217556331552882                |
|           adam_eps           |               3.097914976624119e-09               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         2                         |
|             d_k              |                        150                        |
|             d_v              |                        150                        |
|         dropout_rate         |                0.05908199663484881                |
|     pointwise_layer_size     |                        282                        |
|      last_layer_dropout      |                0.07783720459401389                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         71                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                        True                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 61%|██████    | 61/100 [18:04:27<15:53:14, 1466.52s/it, best loss: 8.45468438776528]
Epoch 9
100% 487/487 [11:28<00:00, 6.92it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	487	16.14		12.56		0.222		0.870		1.28m - 1.3m / 0.0m                  
2	974	13.59		12.27		0.234		0.917		1.27m - 2.6m / 44.6m                 
3	1461	13.69		12.89		0.233		0.912		1.28m - 3.8m / 44.6m                
4	1948	13.78		12.82		0.234		0.916		1.28m - 5.1m / 44.7m                
5	2435	13.81		12.66		0.244		0.959		1.27m - 6.4m / 44.8m                
6	2922	13.88		13.30		0.223		0.874		1.28m - 7.7m / 44.5m                
7	3409	14.02		13.06		0.232		0.910		1.27m - 8.9m / 44.6m                
8	3896	14.18		13.27		0.244		0.959		1.27m - 10.2m / 44.6m               
9	4383	13.96		13.34		0.244		0.959		1.28m - 11.5m / 44.5m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 58.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         58                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |                0.005932435231150469               |
|  noam_learning_rate_warmup   |                        1208                       |
|  noam_learning_rate_factor   |                 1.1487380262304514                |
|          adam_beta1          |                 0.7933858021763889                |
|          adam_beta2          |                 0.7973231299295828                |
|           adam_eps           |                0.002377745598560743               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         10                        |
|             d_k              |                         30                        |
|             d_v              |                         30                        |
|         dropout_rate         |                0.23033799923829387                |
|     pointwise_layer_size     |                        303                        |
|      last_layer_dropout      |                0.03104678220007021                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         96                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 62%|██████▏   | 62/100 [18:16:46<13:10:31, 1248.19s/it, best loss: 8.45468438776528]
Epoch 5
100% 294/294 [10:56<00:00, 2.37it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	294	16.58		14.10		0.244		0.959		2.19m - 2.2m / 0.0m                  
2	588	15.91		14.26		0.244		0.959		2.19m - 4.4m / 76.5m                 
3	882	15.99		14.61		0.234		0.916		2.19m - 6.6m / 76.6m                 
4	1176	15.98		15.14		0.232		0.910		2.19m - 8.8m / 76.6m                
5	1470	15.72		14.52		0.212		0.827		2.19m - 10.9m / 76.6m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 54.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         54                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |            OutputLayerType.Convolutions           |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               9.580123316568382e-08               |
|  noam_learning_rate_warmup   |                        3769                       |
|  noam_learning_rate_factor   |                 0.6957531402853518                |
|          adam_beta1          |                 0.8435011034779316                |
|          adam_beta2          |                 0.8844944416548892                |
|           adam_eps           |               0.0004029851793933405               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.4852360635497968                |
|     pointwise_layer_size     |                        336                        |
|      last_layer_dropout      |               0.0024737279456362865               |
|   output_conv_num_filters    |                        369                        |
|   output_conv_kernel_size    |                         7                         |
|      output_conv_stride      |                         3                         |
|     output_conv_padding      |                         4                         |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        159                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 63%|██████▎   | 63/100 [18:29:09<11:16:20, 1096.78s/it, best loss: 8.45468438776528]
Epoch 6
100% 316/316 [41:05<00:00, 1.21s/it]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	316	15.86		18.57		0.197		0.768		6.84m - 6.8m / 0.0m                  
2	632	14.91		19.29		0.197		0.769		6.84m - 13.7m / 239.3m               
3	948	15.06		23.00		0.104		0.393		6.85m - 20.5m / 239.5m               
4	1264	15.08		21.20		0.177		0.685		6.85m - 27.4m / 239.6m              
5	1580	15.00		21.75		0.128		0.491		6.85m - 34.2m / 239.8m              
6	1896	15.12		22.44		0.103		0.391		6.84m - 41.1m / 239.9m              
Best f1 0.19694117314322762                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 75.0, 'clip_comments_to':[...]rue} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         75                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               7.467672449540808e-07               |
|  noam_learning_rate_warmup   |                        5046                       |
|  noam_learning_rate_factor   |                 0.929339073924059                 |
|          adam_beta1          |                 0.9015206662983022                |
|          adam_beta2          |                 0.7614963428092574                |
|           adam_eps           |               1.8853321154448785e-08              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                        True                       |
|         n_enc_blocks         |                         5                         |
|           n_heads            |                         6                         |
|             d_k              |                         50                        |
|             d_v              |                         50                        |
|         dropout_rate         |                0.034323944881234865               |
|     pointwise_layer_size     |                        454                        |
|      last_layer_dropout      |                 0.2233017992083675                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         47                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 64%|██████▍   | 64/100 [19:14:47<15:53:30, 1589.19s/it, best loss: 8.45468438776528]
Epoch 9
100% 228/228 [06:47<00:00, 5.49it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	228	20.36			14.48		0.227		0.861		0.76m - 0.8m / 0.0m                  
2	456	13.62			15.14		0.249		0.754		0.75m - 1.5m / 26.4m                 
3	684	6.57		15.25		0.312		0.881		0.75m - 2.3m / 26.2m                  
4	912	3.95		16.03		0.326		0.900		0.75m - 3.0m / 26.2m                  
5	1140	2.96		18.90		0.327		0.927		0.75m - 3.8m / 26.4m                 
6	1368	2.84		19.63		0.314		0.908		0.75m - 4.5m / 26.3m                 
7	1596	2.45		20.99		0.325		0.928		0.75m - 5.3m / 26.3m                 
8	1824	2.35		23.03		0.315		0.913		0.75m - 6.0m / 26.3m                 
9	2052	2.48		25.03		0.324		0.940		0.75m - 6.8m / 26.4m                 
Best f1 0.32737353310286676                                                          
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 17.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         17                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                      fasttext                     |
|        learning_rate         |               1.6232386802291788e-06              |
|  noam_learning_rate_warmup   |                        2978                       |
|  noam_learning_rate_factor   |                 0.9909689637667933                |
|          adam_beta1          |                 0.9188635920924239                |
|          adam_beta2          |                 0.7797903744863303                |
|           adam_eps           |                6.57193304638054e-10               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         3                         |
|             d_k              |                        100                        |
|             d_v              |                        100                        |
|         dropout_rate         |                0.18284720671157273                |
|     pointwise_layer_size     |                        208                        |
|      last_layer_dropout      |                 0.591620136734875                 |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        146                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 65%|██████▌   | 65/100 [19:22:17<12:07:32, 1247.21s/it, best loss: 8.45468438776528]
Epoch 6
100% 1003/1003 [22:15<00:00, 4.98it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1003	16.16		19.54		0.232		0.912		3.79m - 3.8m / 0.0m                 
2	2006	28.31		45.82		0.244		0.959		3.75m - 7.5m / 132.6m               
3	3009	63.59		63.55		0.244		0.959		3.69m - 11.2m / 131.4m              
4	4012	43.58		29.23		0.244		0.959		3.67m - 14.9m / 129.4m              
5	5015	17.44		18.54		0.244		0.959		3.67m - 18.6m / 128.8m              
6	6018	12.65		16.06		0.244		0.959		3.67m - 22.3m / 128.8m              
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 12.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         12                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               1.9954961091963452e-07              |
|  noam_learning_rate_warmup   |                        4220                       |
|  noam_learning_rate_factor   |                 1.5179179138551513                |
|          adam_beta1          |                 0.882339859244645                 |
|          adam_beta2          |                 0.7465822695666373                |
|           adam_eps           |               7.500050108075827e-08               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.11049631628873292                |
|     pointwise_layer_size     |                        361                        |
|      last_layer_dropout      |                 0.6822085884595857                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        107                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 66%|██████▌   | 66/100 [19:46:48<12:24:50, 1314.42s/it, best loss: 8.45468438776528]
Epoch 5
100% 1421/1421 [15:54<00:00, 7.80it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1421	11.42		10.80		0.244		0.959		3.18m - 3.2m / 0.0m                 
2	2842	11.92		9.97		0.244		0.959		3.18m - 6.4m / 111.3m                
3	4263	11.04		11.04		0.234		0.917		3.18m - 9.5m / 111.3m               
4	5684	10.42		9.60		0.244		0.959		3.18m - 12.7m / 111.4m               
5	7105	9.89		9.20		0.244		0.959		3.18m - 15.9m / 111.3m                
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 10.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         10                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               2.1287332619009528e-07              |
|  noam_learning_rate_warmup   |                        2539                       |
|  noam_learning_rate_factor   |                 1.743656438070507                 |
|          adam_beta1          |                 0.8705584272888164                |
|          adam_beta2          |                 0.793079110122327                 |
|           adam_eps           |               3.7168526518637175e-07              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.0957583494507285                |
|     pointwise_layer_size     |                        387                        |
|      last_layer_dropout      |                 0.7427445015243175                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        125                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 67%|██████▋   | 67/100 [20:04:26<11:20:35, 1237.44s/it, best loss: 8.45468438776528]
Epoch 6
100% 1705/1705 [22:48<00:00, 8.12it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	1705	11.02		9.86		0.234		0.917		3.81m - 3.8m / 0.0m                  
2	3410	10.21		8.97		0.244		0.959		3.80m - 7.6m / 133.4m                
3	5115	9.24		8.62		0.244		0.959		3.81m - 11.4m / 133.2m                
4	6820	9.18		8.59		0.244		0.959		3.77m - 15.2m / 133.2m                
5	8525	9.24		8.77		0.244		0.959		3.79m - 19.0m / 132.1m                
6	10230	9.69		9.50		0.244		0.959		3.82m - 22.8m / 132.7m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 22.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         22                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               1.5256300740683142e-07              |
|  noam_learning_rate_warmup   |                        2192                       |
|  noam_learning_rate_factor   |                 1.672107208193024                 |
|          adam_beta1          |                 0.8334882119841114                |
|          adam_beta2          |                 0.8135061645572769                |
|           adam_eps           |               1.5301850196326698e-06              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         8                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.13149759544244907                |
|     pointwise_layer_size     |                        308                        |
|      last_layer_dropout      |                 0.6438752846398463                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                        103                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 68%|██████▊   | 68/100 [20:29:07<11:38:54, 1310.47s/it, best loss: 8.45468438776528]
Epoch 6
100% 775/775 [14:47<00:00, 5.50it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	775	13.67		13.07		0.211		0.825		2.46m - 2.5m / 0.0m                  
2	1550	13.34		11.94		0.244		0.959		2.46m - 4.9m / 86.3m                
3	2325	12.64		11.48		0.244		0.959		2.47m - 7.4m / 86.0m                
4	3100	11.86		11.00		0.244		0.959		2.47m - 9.9m / 86.3m                
5	3875	11.74		10.78		0.244		0.959		2.46m - 12.3m / 86.3m               
6	4650	11.69		12.17		0.244		0.959		2.47m - 14.8m / 86.2m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 26.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         26                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               2.6454962867072436e-07              |
|  noam_learning_rate_warmup   |                        3326                       |
|  noam_learning_rate_factor   |                 1.8924015121998556                |
|          adam_beta1          |                 0.8957926446297169                |
|          adam_beta2          |                 0.8268707626174803                |
|           adam_eps           |               8.839307417933475e-08               |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         7                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                0.000366745694447522               |
|     pointwise_layer_size     |                        418                        |
|      last_layer_dropout      |                 0.6955912421039157                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         60                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 69%|██████▉   | 69/100 [20:45:23<10:25:22, 1210.41s/it, best loss: 8.45468438776528]
Epoch 9
100% 656/656 [13:01<00:00, 7.97it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                           
1	656	14.10		12.22		0.235		0.920		1.45m - 1.4m / 0.0m                  
2	1312	13.88		12.52		0.232		0.910		1.44m - 2.9m / 50.7m                
3	1968	13.99		12.92		0.213		0.830		1.45m - 4.3m / 50.6m                
4	2624	13.63		12.06		0.234		0.916		1.45m - 5.8m / 50.6m                
5	3280	13.12		12.11		0.244		0.959		1.44m - 7.2m / 50.7m                
6	3936	12.93		11.88		0.244		0.959		1.45m - 8.7m / 50.6m                
7	4592	12.61		11.34		0.244		0.959		1.45m - 10.1m / 50.6m               
8	5248	12.41		11.37		0.244		0.959		1.45m - 11.6m / 50.6m               
9	5904	12.30		11.39		0.244		0.959		1.44m - 13.0m / 50.6m               
Best f1 0.2441399350742839                                                           
+----------------------------------------------------------------------------------+ 
|                                 Hyperparameters                                  |
+------------------------------+---------------------------------------------------+
|          Parameter           |                       Value                       |
+------------------------------+---------------------------------------------------+
|            kwargs            | {'batch_size': 15.0, 'clip_comments_to':[...]lse} |
|          model_size          |                        300                        |
|        early_stopping        |                         4                         |
|           use_cuda           |                        True                       |
|          batch_size          |                         15                        |
| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |
|      output_layer_type       |             OutputLayerType.LinearSum             |
|        optimizer_type        |                 OptimizerType.Adam                |
|        embedding_type        |                       glove                       |
|        learning_rate         |               3.498186394550192e-07               |
|  noam_learning_rate_warmup   |                        5602                       |
|  noam_learning_rate_factor   |                 1.5760101446071442                |
|          adam_beta1          |                 0.9258642710060644                |
|          adam_beta2          |                 0.7378515109497739                |
|           adam_eps           |               1.0180252601390082e-10              |
|      adam_weight_decay       |                         0                         |
|         adam_amsgrad         |                       False                       |
|           use_bias           |                       False                       |
|         n_enc_blocks         |                         6                         |
|           n_heads            |                         1                         |
|             d_k              |                        300                        |
|             d_v              |                        300                        |
|         dropout_rate         |                 0.0726273551851656                |
|     pointwise_layer_size     |                        442                        |
|      last_layer_dropout      |                 0.5871024195866014                |
|   log_every_xth_iteration    |                         -1                        |
|          num_epochs          |                         35                        |
|        embedding_name        |                         6B                        |
|        embedding_dim         |                        300                        |
|       clip_comments_to       |                         91                        |
|           language           |                         de                        |
|        use_stop_words        |                       False                       |
|         use_stemming         |                       False                       |
|        harmonize_bahn        |                        True                       |
|      use_spell_checkers      |                       False                       |
|      replace_url_tokens      |                       False                       |
|             seed             |                         42                        |
+------------------------------+---------------------------------------------------+
 70%|███████   | 70/100 [20:59:24<9:09:41, 1099.38s/it, best loss: 8.45468438776528]
Epoch 4
51% 578/1137 [08:03<01:04, 8.63it/s]
# EP	# IT	tr loss		val loss	f1		acc		duration / total time                          
1	1137	43.48		75.38		0.196		0.765		2.31m - 2.3m / 0.0m                
2	2274	1903.56		1816.00		0.220		0.862		2.31m - 4.6m / 80.7m           
3	3411	1407.46		962.98		0.244		0.959		2.31m - 6.9m / 80.8m            
 70%|███████   | 70/100 [21:06:33<9:09:41, 1099.38s/it, best loss: 8.45468438776528]