{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from hyperopt.plotting import *\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, STATUS_FAIL, Trials, base, rand\n",
    "from data.data_loader import Dataset\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.run_configuration import from_hyperopt, OutputLayerType, LearningSchedulerType, OptimizerType, default_params\n",
    "from misc import utils\n",
    "from misc.hyperopt_space import *\n",
    "\n",
    "from optimizer import get_optimizer\n",
    "from criterion import NllLoss, LossCombiner\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.jointAspectTagger import JointAspectTagger\n",
    "from trainer.train import Trainer\n",
    "import pprint\n",
    "import argparse\n",
    "import pickle\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSSIBLE_DATASET_VALUES = ['germeval', 'organic', 'coNLL-2003', 'amazon']\n",
    "\n",
    "\n",
    "def load_model(dataset, rc, experiment_name):\n",
    "    transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                        hyperparameters=rc)\n",
    "\n",
    "    # NER or ABSA-task?\n",
    "    if rc.task == 'ner':\n",
    "        from models.transformer_tagger import TransformerTagger\n",
    "        from models.output_layers import SoftmaxOutputLayer\n",
    "        loss = NllLoss(dataset.target_size, dataset.class_weights[0])\n",
    "        softmax = SoftmaxOutputLayer(rc.model_size, dataset.target_size)\n",
    "        model = TransformerTagger(transformer, softmax)\n",
    "\n",
    "    else:\n",
    "        from models.jointAspectTagger import JointAspectTagger\n",
    "        loss = LossCombiner(4, dataset.class_weights, NllLoss)\n",
    "        model = JointAspectTagger(transformer, rc, 4, 20, dataset.target_names)\n",
    "\n",
    "\n",
    "    optimizer = get_optimizer(model, rc)\n",
    "    trainer = Trainer(\n",
    "                        model,\n",
    "                        loss,\n",
    "                        optimizer,\n",
    "                        rc,\n",
    "                        dataset,\n",
    "                        experiment_name,\n",
    "                        enable_tensorboard=False,\n",
    "                        verbose=False)\n",
    "    return trainer\n",
    "\n",
    "def load_dataset(rc, logger, task):\n",
    "    dataset = Dataset(\n",
    "            task,\n",
    "            logger,\n",
    "            rc,\n",
    "            source_index=PREFERENCES.source_index,\n",
    "            target_vocab_index=PREFERENCES.target_vocab_index,\n",
    "            data_path=PREFERENCES.data_root,\n",
    "            train_file=PREFERENCES.data_train,\n",
    "            valid_file=PREFERENCES.data_validation,\n",
    "            test_file=PREFERENCES.data_test,\n",
    "            file_format=PREFERENCES.file_format,\n",
    "            init_token=None,\n",
    "            eos_token=None\n",
    "        )\n",
    "    dataset.load_data(dsl, verbose=False)\n",
    "    return dataset\n",
    "\n",
    "def objective(parameters):\n",
    "    run_time = time.time()\n",
    "\n",
    "    utils.reset_loggers()\n",
    "    experiment_name = utils.create_loggers(experiment_name=main_experiment_name)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    dataset_logger = logging.getLogger('data_loader')\n",
    "\n",
    "    # generate hp's from parameters\n",
    "    try:\n",
    "        rc = from_hyperopt(parameters, use_cuda, model_size=300, early_stopping=5, num_epochs=35, log_every_xth_iteration=-1, language=PREFERENCES.language)\n",
    "    except Exception as err:\n",
    "        print('Could not convert params: ' + str(err))\n",
    "        logger.exception(\"Could not load parameters from hyperopt configuration: \" + parameters)\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "    logger.info('New Params:')\n",
    "    logger.info(rc)\n",
    "    print('\\n\\n#########################################################################')\n",
    "    print(rc)\n",
    "\n",
    "    logger.debug('Load dataset')\n",
    "    try:\n",
    "        dataset = load_dataset(rc, dataset_logger, rc.task)\n",
    "    except Exception as err:\n",
    "        print('Could not load dataset: ' + str(err))\n",
    "        logger.exception(\"Could not load dataset\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "    logger.debug('dataset loaded')\n",
    "    logger.debug('Load model')\n",
    "\n",
    "    try:\n",
    "        trainer = load_model(dataset, rc, experiment_name)\n",
    "    except Exception as err:\n",
    "        print('Could not load model: ' + str(err))\n",
    "        logger.exception(\"Could not load model\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time\n",
    "        }\n",
    "\n",
    "    logger.debug('model loaded')\n",
    "\n",
    "    logger.debug('Begin training')\n",
    "    model = None\n",
    "    try:\n",
    "        result = trainer.train(use_cuda=rc.use_cuda, perform_evaluation=False)\n",
    "        model = result['model']\n",
    "    except Exception as err:\n",
    "        print('Exception while training: ' + str(err))\n",
    "        logger.exception(\"Could not complete iteration\")\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "\n",
    "    if math.isnan(trainer.get_best_loss()):\n",
    "        print('Loss is nan')\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "\n",
    "    # perform evaluation and log results\n",
    "    result = None\n",
    "    try:\n",
    "        result = trainer.perform_final_evaluation(use_test_set=True, verbose=False)\n",
    "    except Exception as err:\n",
    "        logger.exception(\"Could not complete iteration evaluation.\")\n",
    "        print('Could not complete iteration evaluation: ' + str(err))\n",
    "        return {\n",
    "            'status': STATUS_FAIL,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1()\n",
    "        }\n",
    "    print(f'VAL f1\\t{trainer.get_best_f1()} - ({result[1][1]})')\n",
    "    print(f'VAL loss\\t{trainer.get_best_loss()}')\n",
    "\n",
    "    print(f\"       .---.\\n \\\n",
    "         /     \\\\\\n\\\n",
    "          \\\\.@-@./\\n\\\n",
    "          /`\\\\_/`\\\\\\n\\\n",
    "         //  _  \\\\\\\\\\tLoss: {trainer.get_best_loss()}\\n\\\n",
    "        | \\\\     )|_\\tf1: {trainer.get_best_f1()}\\n\\\n",
    "       /`\\\\_`>  <_/ \\\\\\n\\\n",
    "       \\\\__/'---'\\\\__/\\n\")\n",
    "\n",
    "    return {\n",
    "            'loss': result[1][0],\n",
    "            'status': STATUS_OK,\n",
    "            'eval_time': time.time() - run_time,\n",
    "            'best_loss': trainer.get_best_loss(),\n",
    "            'best_f1': trainer.get_best_f1(),\n",
    "            'sample_iterations': trainer.get_num_samples_seen(),\n",
    "            'iterations': trainer.get_num_iterations(),\n",
    "            'rc': rc,\n",
    "            'results': {\n",
    "                'train': {\n",
    "                    'loss': result[0][0],\n",
    "                    'f1': result[0][1]\n",
    "                },\n",
    "                'validation': {\n",
    "                    'loss': result[1][0],\n",
    "                    'f1': result[1][1]\n",
    "                },\n",
    "                'test': {\n",
    "                    'loss': result[2][0],\n",
    "                    'f1': result[2][1]\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_choice = 'coNLL-2003'\n",
    "runs = 150\n",
    "main_experiment_name = 'CoNLL-2003HyperoptTPE'\n",
    "use_cuda = True\n",
    "description = 'CoNLL-2003 NER TPE Hyperopt run'\n",
    "\n",
    "if dataset_choice not in POSSIBLE_DATASET_VALUES:\n",
    "    raise Error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataset_choice == POSSIBLE_DATASET_VALUES[0]:\n",
    "    PREFERENCES.defaults(\n",
    "        data_root='./data/data/germeval2017',\n",
    "        data_train='train_v1.4.tsv',    \n",
    "        data_validation='dev_v1.4.tsv',\n",
    "        data_test='test_TIMESTAMP1.tsv',\n",
    "        source_index=0,\n",
    "        target_vocab_index=2,\n",
    "        file_format='csv',\n",
    "        language='de'\n",
    "    )\n",
    "    from data.germeval2017 import germeval2017_dataset as dsl\n",
    "\n",
    "    search_space = {\n",
    "        'batch_size': hp.quniform('batch_size', 10, 100, 1),\n",
    "        'num_encoder_blocks': hp.quniform('num_encoder_blocks', 1, 8, 1),\n",
    "        'pointwise_layer_size': hp.quniform('pointwise_layer_size', 32, 256, 1),\n",
    "        'clip_comments_to': hp.quniform('clip_comments_to', 10, 250, 1),\n",
    "        'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.8),\n",
    "        'output_dropout_rate': hp.uniform('last_layer_dropout', 0.0, 0.8),\n",
    "        'num_heads': hp.choice('num_heads', [1, 2, 3, 4, 5]),\n",
    "        'transformer_use_bias': hp_bool('transformer_use_bias'),\n",
    "        'output_layer': hp.choice('output_layer', [\n",
    "            {\n",
    "                'type': OutputLayerType.Convolutions,\n",
    "                'output_conv_num_filters': hp.quniform('output_conv_num_filters', 1, 400, 1),\n",
    "                'output_conv_kernel_size': hp.quniform('output_conv_kernel_size', 1, 10, 1),\n",
    "                'output_conv_stride': hp.quniform('output_conv_stride', 1, 10, 1),\n",
    "                'output_conv_padding': hp.quniform('output_conv_padding', 0, 5, 1),\n",
    "            },\n",
    "            {\n",
    "                'type': OutputLayerType.LinearSum\n",
    "            }\n",
    "        ]),\n",
    "        'learning_rate_scheduler': hp.choice('learning_rate_scheduler', [\n",
    "            {\n",
    "                'type': LearningSchedulerType.Noam,\n",
    "                'noam_learning_rate_warmup': hp.quniform('noam_learning_rate_warmup', 1000, 9000, 1),\n",
    "                'noam_learning_rate_factor': hp.uniform('noam_learning_rate_factor', 0.01, 4)\n",
    "            }\n",
    "        ]),\n",
    "        'optimizer': hp.choice('optimizer', [\n",
    "            {\n",
    "                'type': OptimizerType.Adam,\n",
    "                'adam_beta1': hp.uniform('adam_beta1', 0.7, 0.999),\n",
    "                'adam_beta2': hp.uniform('adam_beta2', 0.7, 0.999),\n",
    "                'adam_eps': hp.loguniform('adam_eps', np.log(1e-10), np.log(1)),\n",
    "                'learning_rate': hp.lognormal('adam_learning_rate', np.log(0.01), np.log(10)),\n",
    "                'adam_weight_decay': 1*10**hp.quniform('adam_weight_decay', -8, -3, 1)\n",
    "            },\n",
    "            #{\n",
    "            #    'type': OptimizerType.SGD,\n",
    "            #    'sgd_momentum': hp.uniform('sgd_momentum', 0.4, 1),\n",
    "            #    'sgd_weight_decay': hp.loguniform('sgd_weight_decay', np.log(1e-4), np.log(1)),\n",
    "            #    'sgd_nesterov': hp_bool('sgd_nesterov'),\n",
    "            #    'learning_rate': hp.lognormal('sgd_learning_rate', np.log(0.01), np.log(10))\n",
    "        ]),\n",
    "        'replace_url_tokens': hp_bool('replace_url_tokens'),\n",
    "        'harmonize_bahn': hp_bool('harmonize_bahn'),\n",
    "        'embedding_type': hp.choice('embedding_type', ['fasttext', 'glove']),\n",
    "        'embedding_name': hp.choice('embedding_name', ['6B']),\n",
    "        'embedding_dim': hp.choice('embedding_dim', [300]),\n",
    "        'use_stop_words': hp_bool('use_stop_words'),\n",
    "        'use_spell_checker': hp_bool('use_spell_checker'),\n",
    "        'embedding_type': hp.choice('embedding_type', ['fasttext', 'glove']),\n",
    "        'task': 'germeval'\n",
    "    }\n",
    "\n",
    "elif dataset_choice == POSSIBLE_DATASET_VALUES[1]:\n",
    "     from data.organic2019 import organic_dataset as dsl\n",
    "     from data.organic2019 import ORGANIC_TASK_ALL, ORGANIC_TASK_ENTITIES, ORGANIC_TASK_ATTRIBUTES, ORGANIC_TASK_ENTITIES_COMBINE, ORGANIC_TASK_COARSE\n",
    "     PREFERENCES.defaults(\n",
    "        data_root='./data/data/organic2019',\n",
    "        data_train='train.csv',    \n",
    "        data_validation='validation.csv',\n",
    "        data_test='test.csv',\n",
    "        source_index=0,\n",
    "        target_vocab_index=1,\n",
    "        file_format='csv',\n",
    "        language='en'\n",
    "     )\n",
    "\n",
    "     search_space = {\n",
    "        'batch_size': hp.quniform('batch_size', 10, 64, 1),\n",
    "        'num_encoder_blocks': hp.quniform('num_encoder_blocks', 1, 4, 1),\n",
    "        'pointwise_layer_size': hp.quniform('pointwise_layer_size', 32, 350, 1),\n",
    "        'clip_comments_to': hp.quniform('clip_comments_to', 45, 180, 1),\n",
    "        'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.8),\n",
    "        'output_dropout_rate': hp.uniform('last_layer_dropout', 0.0, 0.8),\n",
    "        'num_heads': hp.choice('num_heads', [1, 2, 3, 4, 5]),\n",
    "        'transformer_use_bias': hp_bool('transformer_use_bias'),\n",
    "        'output_layer': hp.choice('output_layer', [\n",
    "            {\n",
    "                'type': OutputLayerType.Convolutions,\n",
    "                'output_conv_num_filters': hp.quniform('output_conv_num_filters', 10, 400, 1),\n",
    "                'output_conv_kernel_size': hp.quniform('output_conv_kernel_size', 1, 10, 1),\n",
    "                'output_conv_stride': hp.quniform('output_conv_stride', 1, 10, 1),\n",
    "                'output_conv_padding': hp.quniform('output_conv_padding', 0, 5, 1),\n",
    "            },\n",
    "            {\n",
    "                'type': OutputLayerType.LinearSum\n",
    "            }\n",
    "        ]),\n",
    "        'learning_rate_scheduler': hp.choice('learning_rate_scheduler', [\n",
    "            {\n",
    "                'type': LearningSchedulerType.Noam,\n",
    "                'noam_learning_rate_warmup': hp.quniform('noam_learning_rate_warmup', 1000, 9000, 1),\n",
    "                'noam_learning_rate_factor': hp.uniform('noam_learning_rate_factor', 0.01, 4)\n",
    "            }\n",
    "        ]),\n",
    "        'optimizer': hp.choice('optimizer', [\n",
    "            {\n",
    "                'type': OptimizerType.Adam,\n",
    "                'adam_beta1': hp.uniform('adam_beta1', 0.7, 0.999),\n",
    "                'adam_beta2': hp.uniform('adam_beta2', 0.7, 0.999),\n",
    "                'adam_eps': hp.loguniform('adam_eps', np.log(1e-10), np.log(1)),\n",
    "                'learning_rate': hp.lognormal('adam_learning_rate', np.log(0.01), np.log(10)),\n",
    "                'adam_weight_decay': 1*10**hp.quniform('adam_weight_decay', -8, -3, 1)\n",
    "            },\n",
    "            #{\n",
    "            #    'type': OptimizerType.SGD,\n",
    "            #    'sgd_momentum': hp.uniform('sgd_momentum', 0.4, 1),\n",
    "            #    'sgd_weight_decay': hp.loguniform('sgd_weight_decay', np.log(1e-4), np.log(1)),\n",
    "            #    'sgd_nesterov': hp_bool('sgd_nesterov'),\n",
    "            #    'learning_rate': hp.lognormal('sgd_learning_rate', np.log(0.01), np.log(10))\n",
    "        ]),\n",
    "        'task': hp.choice('task', [\n",
    "            ORGANIC_TASK_ENTITIES,\n",
    "            ORGANIC_TASK_ENTITIES_COMBINE\n",
    "        ]),\n",
    "        'use_stop_words': hp_bool('use_stop_words'),\n",
    "        'use_spell_checker': hp_bool('use_spell_checker'),\n",
    "        'embedding_type': hp.choice('embedding_type', ['fasttext', 'glove'])\n",
    "    }\n",
    "elif dataset_choice == POSSIBLE_DATASET_VALUES[2]:\n",
    "    PREFERENCES.defaults(\n",
    "        data_root='./data/data/conll2003',\n",
    "        data_train='eng.train.txt',\n",
    "        data_validation='eng.testa.txt',\n",
    "        data_test='eng.testb.txt',\n",
    "        source_index=0,\n",
    "        target_vocab_index=1,\n",
    "        file_format='txt',\n",
    "        language='en'\n",
    "    )\n",
    "    from data.conll import conll2003_dataset as dsl\n",
    "\n",
    "    search_space = {\n",
    "        'batch_size': hp.quniform('batch_size', 10, 64, 1),\n",
    "        'num_encoder_blocks': hp.quniform('num_encoder_blocks', 1, 4, 1),\n",
    "        'pointwise_layer_size': hp.quniform('pointwise_layer_size', 32, 350, 1),\n",
    "        'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.8),\n",
    "        'output_dropout_rate': hp.uniform('last_layer_dropout', 0.0, 0.8),\n",
    "        'num_heads': hp.choice('num_heads', [1, 2, 3]),\n",
    "        'transformer_use_bias': True,\n",
    "        'learning_rate_scheduler': {\n",
    "                'type': LearningSchedulerType.Noam,\n",
    "                'noam_learning_rate_warmup': hp.quniform('noam_learning_rate_warmup', 1000, 9000, 1),\n",
    "                'noam_learning_rate_factor': hp.uniform('noam_learning_rate_factor', 0.01, 4)\n",
    "            },\n",
    "        'optimizer':\n",
    "            {\n",
    "                'type': OptimizerType.Adam,\n",
    "                'adam_beta1': 0.9,\n",
    "                'adam_beta2': 0.98,\n",
    "                'adam_eps': 10e-9,\n",
    "                'learning_rate': hp.lognormal('adam_learning_rate', np.log(0.01), np.log(10)),\n",
    "                'adam_weight_decay': 1*10**hp.quniform('adam_weight_decay', -8, -3, 1)\n",
    "            },\n",
    "        'output_layer': {'type': None},\n",
    "        'task': 'ner',\n",
    "        'clip_comments_to': 200,\n",
    "        'embedding_type': hp.choice('embedding_type', ['fasttext', 'glove'])\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    PREFERENCES.defaults(\n",
    "        data_root='./data/data/amazon/splits',\n",
    "        data_train='train.pkl',    \n",
    "        data_validation='val.pkl',\n",
    "        data_test='test.pkl',\n",
    "        source_index=0,\n",
    "        target_vocab_index=1,\n",
    "        file_format='pkl',\n",
    "        language='en'\n",
    "    )\n",
    "    from data.amazon import amazon_dataset as dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\3\n"
     ]
    }
   ],
   "source": [
    "experiment_name = utils.create_loggers(experiment_name=main_experiment_name)\n",
    "logger = logging.getLogger(__name__)\n",
    "dataset_logger = logging.getLogger('data_loader')\n",
    "logger.info('Run hyper parameter random grid search for experiment with name ' + main_experiment_name)\n",
    "logger.info('num_optim_iterations: ' + str(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current commit: b'8b18e1e'\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\4  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0016145923757410754               |\n",
      "|  noam_learning_rate_warmup   |                        5000                       |\n",
      "|  noam_learning_rate_factor   |                 3.355271232609175                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5798707999165865                |\n",
      "|     pointwise_layer_size     |                        297                        |\n",
      "|      last_layer_dropout      |                0.046886713888812985               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  0%|                                                                            | 0/150 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb6ad2fa4243cf897277eba7231a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.122\t\t0.800\t\t0.60m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.146\t\t0.831\t\t0.61m - 1.3m / 21.1m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.126\t\t0.803\t\t0.60m - 1.9m / 21.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.118\t\t0.797\t\t0.61m - 2.5m / 21.1m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.136\t\t0.824\t\t0.60m - 3.1m / 21.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.179\t\t0.864\t\t0.59m - 3.7m / 21.1m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.180\t\t0.864\t\t0.61m - 4.3m / 20.9m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.176\t\t0.858\t\t0.59m - 4.9m / 21.5m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.204\t\t0.880\t\t0.59m - 5.6m / 20.8m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.201\t\t0.878\t\t0.59m - 6.2m / 20.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.206\t\t0.881\t\t0.59m - 6.8m / 21.0m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.187\t\t0.868\t\t0.60m - 7.4m / 20.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.197\t\t0.876\t\t0.60m - 8.0m / 21.1m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.176\t\t0.857\t\t0.61m - 8.6m / 21.2m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.160\t\t0.840\t\t0.60m - 9.2m / 21.4m                                                                 \n",
      "16\t225k\t0.01\t\t0.01\t\t0.172\t\t0.853\t\t0.59m - 9.8m / 21.2m                                                                 \n",
      "VAL f1\t0.2060520605986532 - (0.2060520605986532)                                                                       \n",
      "VAL loss\t0.013551785660260267                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013551785660260267\n",
      "        | \\     )|_\tf1: 0.2060520605986532\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\5  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 13.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         13                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0006801327576324076               |\n",
      "|  noam_learning_rate_warmup   |                        1921                       |\n",
      "|  noam_learning_rate_factor   |                 3.3706171568524654                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.735910644773664                 |\n",
      "|     pointwise_layer_size     |                        254                        |\n",
      "|      last_layer_dropout      |                 0.1718307457897101                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  1%|▎                                            | 1/150 [10:23<25:48:10, 623.42s/it, best loss: 0.017560921004311527]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed962f34fe04d0eb066d6dcf00c1540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.10\t\t0.263\t\t0.739\t\t0.73m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.13\t\t0.193\t\t0.741\t\t0.73m - 1.5m / 25.5m                                                                   \n",
      "3\t42k\t0.05\t\t0.11\t\t0.252\t\t0.770\t\t0.73m - 2.2m / 25.6m                                                                   \n",
      "4\t56k\t0.05\t\t0.10\t\t0.341\t\t0.810\t\t0.73m - 3.0m / 25.5m                                                                   \n",
      "5\t70k\t0.05\t\t0.11\t\t0.274\t\t0.761\t\t0.70m - 3.7m / 25.8m                                                                   \n",
      "6\t84k\t0.05\t\t0.11\t\t0.344\t\t0.818\t\t0.70m - 4.4m / 24.7m                                                                   \n",
      "7\t98k\t0.05\t\t0.11\t\t0.319\t\t0.802\t\t0.74m - 5.2m / 24.9m                                                                   \n",
      "8\t112k\t0.05\t\t0.13\t\t0.333\t\t0.807\t\t0.73m - 5.9m / 25.9m                                                                  \n",
      "9\t126k\t0.05\t\t0.11\t\t0.283\t\t0.775\t\t0.72m - 6.6m / 25.7m                                                                  \n",
      "10\t141k\t0.05\t\t0.12\t\t0.268\t\t0.765\t\t0.75m - 7.4m / 25.3m                                                                 \n",
      "11\t155k\t0.05\t\t0.12\t\t0.234\t\t0.751\t\t0.73m - 8.1m / 26.2m                                                                 \n",
      "VAL f1\t0.34358686172920794 - (0.34358686172920794)                                                                     \n",
      "VAL loss\t0.09643691383875334                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.09643691383875334\n",
      "        | \\     )|_\tf1: 0.34358686172920794\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\6  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 19.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         19                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.10846535283174406                |\n",
      "|  noam_learning_rate_warmup   |                        5000                       |\n",
      "|  noam_learning_rate_factor   |                 1.3128215946542767                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.0839089011493762                |\n",
      "|     pointwise_layer_size     |                        157                        |\n",
      "|      last_layer_dropout      |                0.23939248579859973                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  1%|▌                                            | 2/150 [19:10<24:26:08, 594.38s/it, best loss: 0.017560921004311527]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d519e76deb46e7b54affb8031e0547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.03\t\t0.380\t\t0.880\t\t0.82m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.476\t\t0.917\t\t0.84m - 1.7m / 28.8m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.380\t\t0.881\t\t0.81m - 2.5m / 29.4m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.496\t\t0.924\t\t0.82m - 3.3m / 28.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.414\t\t0.896\t\t0.85m - 4.2m / 28.6m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.398\t\t0.889\t\t0.84m - 5.1m / 29.9m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.461\t\t0.913\t\t0.83m - 5.9m / 29.4m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.469\t\t0.914\t\t0.82m - 6.7m / 29.1m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.411\t\t0.891\t\t0.82m - 7.6m / 28.9m                                                                  \n",
      "VAL f1\t0.4963057935401667 - (0.4963057935401667)                                                                       \n",
      "VAL loss\t0.018476793373652222                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.018476793373652222\n",
      "        | \\     )|_\tf1: 0.4963057935401667\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\7  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 54.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         54                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0003543321026078788               |\n",
      "|  noam_learning_rate_warmup   |                        5206                       |\n",
      "|  noam_learning_rate_factor   |                 0.9414907832878805                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.3108211393729999                |\n",
      "|     pointwise_layer_size     |                        143                        |\n",
      "|      last_layer_dropout      |                 0.5030414001256545                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  2%|▉                                            | 3/150 [27:23<23:02:01, 564.09s/it, best loss: 0.017560921004311527]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f46b8b858f34fcdbd1862de6e75ca4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.114\t\t0.802\t\t0.49m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.067\t\t0.716\t\t0.50m - 1.0m / 17.3m                                                                   \n",
      "3\t42k\t0.02\t\t0.01\t\t0.135\t\t0.835\t\t0.49m - 1.5m / 17.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.192\t\t0.881\t\t0.50m - 2.0m / 17.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.213\t\t0.893\t\t0.49m - 2.6m / 17.5m                                                                   \n",
      "6\t85k\t0.01\t\t0.01\t\t0.189\t\t0.880\t\t0.49m - 3.1m / 17.3m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.154\t\t0.858\t\t0.49m - 3.6m / 17.2m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.181\t\t0.877\t\t0.49m - 4.1m / 17.4m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.197\t\t0.889\t\t0.50m - 4.6m / 17.4m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.197\t\t0.887\t\t0.50m - 5.1m / 17.5m                                                                 \n",
      "VAL f1\t0.21305313565559642 - (0.21305313565559642)                                                                     \n",
      "VAL loss\t0.008298209003773904                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.008298209003773904\n",
      "        | \\     )|_\tf1: 0.21305313565559642\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\8  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 51.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         51                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.5467485814997763                |\n",
      "|  noam_learning_rate_warmup   |                        8577                       |\n",
      "|  noam_learning_rate_factor   |                0.40827167350032006                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.3730264382177427                |\n",
      "|     pointwise_layer_size     |                         37                        |\n",
      "|      last_layer_dropout      |                 0.4671592302611104                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  3%|█▏                                           | 4/150 [33:05<20:10:47, 497.59s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a82c34ff4343fb9a4e16b22385c209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.105\t\t0.782\t\t0.26m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.106\t\t0.784\t\t0.26m - 0.5m / 9.0m                                                                    \n",
      "3\t42k\t0.03\t\t0.03\t\t0.115\t\t0.796\t\t0.25m - 0.8m / 9.2m                                                                    \n",
      "4\t56k\t0.02\t\t0.02\t\t0.136\t\t0.827\t\t0.26m - 1.1m / 8.9m                                                                    \n",
      "5\t70k\t0.02\t\t0.02\t\t0.150\t\t0.844\t\t0.26m - 1.4m / 9.1m                                                                    \n",
      "6\t84k\t0.01\t\t0.02\t\t0.152\t\t0.846\t\t0.26m - 1.6m / 9.0m                                                                    \n",
      "7\t99k\t0.01\t\t0.02\t\t0.154\t\t0.848\t\t0.25m - 1.9m / 9.1m                                                                    \n",
      "8\t113k\t0.01\t\t0.01\t\t0.154\t\t0.849\t\t0.26m - 2.2m / 8.9m                                                                   \n",
      "9\t127k\t0.01\t\t0.01\t\t0.153\t\t0.852\t\t0.25m - 2.4m / 9.2m                                                                   \n",
      "10\t141k\t0.01\t\t0.01\t\t0.154\t\t0.855\t\t0.26m - 2.7m / 9.0m                                                                  \n",
      "11\t155k\t0.01\t\t0.01\t\t0.161\t\t0.860\t\t0.26m - 3.0m / 9.2m                                                                  \n",
      "12\t169k\t0.00\t\t0.01\t\t0.151\t\t0.856\t\t0.26m - 3.3m / 9.1m                                                                  \n",
      "13\t183k\t0.00\t\t0.01\t\t0.148\t\t0.852\t\t0.26m - 3.5m / 9.2m                                                                  \n",
      "14\t197k\t0.00\t\t0.01\t\t0.171\t\t0.868\t\t0.26m - 3.8m / 9.2m                                                                  \n",
      "15\t211k\t0.00\t\t0.01\t\t0.166\t\t0.867\t\t0.25m - 4.1m / 9.2m                                                                  \n",
      "16\t225k\t0.00\t\t0.01\t\t0.163\t\t0.862\t\t0.25m - 4.3m / 9.1m                                                                  \n",
      "17\t239k\t0.00\t\t0.01\t\t0.166\t\t0.864\t\t0.26m - 4.6m / 9.2m                                                                  \n",
      "18\t253k\t0.00\t\t0.01\t\t0.180\t\t0.874\t\t0.26m - 4.9m / 9.2m                                                                  \n",
      "19\t267k\t0.00\t\t0.01\t\t0.175\t\t0.870\t\t0.25m - 5.2m / 9.3m                                                                  \n",
      "20\t282k\t0.00\t\t0.01\t\t0.181\t\t0.873\t\t0.26m - 5.4m / 9.2m                                                                  \n",
      "21\t296k\t0.00\t\t0.01\t\t0.166\t\t0.863\t\t0.25m - 5.7m / 9.3m                                                                  \n",
      "22\t310k\t0.00\t\t0.01\t\t0.186\t\t0.876\t\t0.26m - 6.0m / 9.3m                                                                  \n",
      "23\t324k\t0.00\t\t0.01\t\t0.181\t\t0.873\t\t0.26m - 6.2m / 9.3m                                                                  \n",
      "24\t338k\t0.00\t\t0.01\t\t0.178\t\t0.873\t\t0.26m - 6.5m / 9.4m                                                                  \n",
      "25\t352k\t0.00\t\t0.01\t\t0.186\t\t0.876\t\t0.26m - 6.8m / 9.3m                                                                  \n",
      "26\t366k\t0.00\t\t0.01\t\t0.160\t\t0.864\t\t0.27m - 7.1m / 9.4m                                                                  \n",
      "27\t380k\t0.00\t\t0.01\t\t0.182\t\t0.875\t\t0.27m - 7.4m / 9.5m                                                                  \n",
      "VAL f1\t0.18644776616937314 - (0.18644776616937314)                                                                     \n",
      "VAL loss\t0.00981925703201662                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.00981925703201662\n",
      "        | \\     )|_\tf1: 0.18644776616937314\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\9  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0007027115859188041               |\n",
      "|  noam_learning_rate_warmup   |                        1397                       |\n",
      "|  noam_learning_rate_factor   |                 1.1628603761275549                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.4497787611664212                |\n",
      "|     pointwise_layer_size     |                        193                        |\n",
      "|      last_layer_dropout      |                 0.2642522177820162                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      "  3%|█▌                                           | 5/150 [40:56<19:42:53, 489.47s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820aa2c0c8c84150af51a84f6bb90249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.06\t\t0.249\t\t0.773\t\t1.53m - 1.5m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.09\t\t0.304\t\t0.817\t\t1.56m - 3.1m / 53.6m                                                                   \n",
      "3\t42k\t0.08\t\t0.09\t\t0.304\t\t0.817\t\t1.51m - 4.6m / 54.5m                                                                   \n",
      "4\t56k\t0.08\t\t0.09\t\t0.304\t\t0.817\t\t1.60m - 6.3m / 53.1m                                                                   \n",
      "5\t70k\t0.08\t\t0.09\t\t0.304\t\t0.817\t\t1.62m - 7.9m / 55.9m                                                                   \n",
      "6\t84k\t0.08\t\t0.09\t\t0.304\t\t0.817\t\t1.53m - 9.4m / 56.5m                                                                   \n",
      "7\t98k\t0.08\t\t0.09\t\t0.304\t\t0.817\t\t1.52m - 11.0m / 53.9m                                                                  \n",
      "VAL f1\t0.3037556731804399 - (0.3037556731804399)                                                                       \n",
      "VAL loss\t0.06323352854358781                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.06323352854358781\n",
      "        | \\     )|_\tf1: 0.3037556731804399\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\10 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 21.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         21                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.033329115044588985               |\n",
      "|  noam_learning_rate_warmup   |                        7963                       |\n",
      "|  noam_learning_rate_factor   |                 3.2136331153759548                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.3256494528487104                |\n",
      "|     pointwise_layer_size     |                         58                        |\n",
      "|      last_layer_dropout      |                 0.2810853609029178                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  4%|█▊                                           | 6/150 [52:53<22:18:32, 557.73s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c052e242c148dc8822320657cb93f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.04\t\t0.168\t\t0.727\t\t1.23m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.341\t\t0.874\t\t1.25m - 2.5m / 43.2m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.373\t\t0.888\t\t1.25m - 3.8m / 43.7m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.375\t\t0.894\t\t1.25m - 5.0m / 43.9m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.364\t\t0.883\t\t1.23m - 6.3m / 43.9m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.285\t\t0.845\t\t1.23m - 7.5m / 43.1m                                                                   \n",
      "7\t98k\t0.03\t\t0.05\t\t0.230\t\t0.794\t\t1.23m - 8.8m / 43.2m                                                                   \n",
      "8\t112k\t0.05\t\t0.07\t\t0.223\t\t0.815\t\t1.23m - 10.0m / 43.2m                                                                 \n",
      "9\t126k\t0.06\t\t0.07\t\t0.254\t\t0.814\t\t1.28m - 11.3m / 43.2m                                                                 \n",
      "VAL f1\t0.3749397697250708 - (0.3749397697250708)                                                                       \n",
      "VAL loss\t0.021928242610026433                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.021928242610026433\n",
      "        | \\     )|_\tf1: 0.3749397697250708\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\11 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 20.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         20                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00442734172871695                |\n",
      "|  noam_learning_rate_warmup   |                        5785                       |\n",
      "|  noam_learning_rate_factor   |                 1.2163244971905178                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.49100116347941286                |\n",
      "|     pointwise_layer_size     |                        315                        |\n",
      "|      last_layer_dropout      |                 0.7249532661296322                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  5%|██                                         | 7/150 [1:05:05<24:13:55, 610.04s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc31c137c7946698173c1472feca63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.06\t\t0.226\t\t0.803\t\t1.34m - 1.3m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.05\t\t0.242\t\t0.791\t\t1.34m - 2.7m / 46.9m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.362\t\t0.869\t\t1.34m - 4.1m / 47.0m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.396\t\t0.886\t\t1.34m - 5.4m / 47.0m                                                                   \n",
      "5\t70k\t0.02\t\t0.05\t\t0.433\t\t0.901\t\t1.33m - 6.8m / 47.0m                                                                   \n",
      "6\t84k\t0.02\t\t0.04\t\t0.447\t\t0.906\t\t1.34m - 8.1m / 46.7m                                                                   \n",
      "7\t98k\t0.02\t\t0.04\t\t0.429\t\t0.900\t\t1.36m - 9.5m / 47.1m                                                                   \n",
      "8\t112k\t0.02\t\t0.05\t\t0.410\t\t0.895\t\t1.32m - 10.8m / 47.7m                                                                 \n",
      "9\t127k\t0.02\t\t0.05\t\t0.380\t\t0.881\t\t1.33m - 12.2m / 46.5m                                                                 \n",
      "10\t141k\t0.02\t\t0.05\t\t0.397\t\t0.886\t\t1.33m - 13.5m / 46.7m                                                                \n",
      "11\t155k\t0.02\t\t0.05\t\t0.394\t\t0.887\t\t1.35m - 14.9m / 46.8m                                                                \n",
      "VAL f1\t0.44655023234742103 - (0.44655023234742103)                                                                     \n",
      "VAL loss\t0.039139299752887775                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.039139299752887775\n",
      "        | \\     )|_\tf1: 0.44655023234742103\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\12 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 15.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         15                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0010564039179748205               |\n",
      "|  noam_learning_rate_warmup   |                        6727                       |\n",
      "|  noam_learning_rate_factor   |                 1.5909501290416483                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.4233379393252724                |\n",
      "|     pointwise_layer_size     |                        319                        |\n",
      "|      last_layer_dropout      |                 0.2539968050529133                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  5%|██▎                                        | 8/150 [1:20:55<28:05:01, 711.98s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895334c8e3834a94b3efd10d28ed3242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.07\t\t0.204\t\t0.712\t\t1.73m - 1.7m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.05\t\t0.338\t\t0.824\t\t1.77m - 3.5m / 60.5m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.492\t\t0.896\t\t1.73m - 5.3m / 61.8m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.414\t\t0.873\t\t1.77m - 7.0m / 60.8m                                                                   \n",
      "5\t70k\t0.03\t\t0.05\t\t0.415\t\t0.879\t\t1.76m - 8.8m / 61.8m                                                                   \n",
      "6\t84k\t0.03\t\t0.06\t\t0.342\t\t0.838\t\t1.80m - 10.6m / 61.6m                                                                  \n",
      "7\t98k\t0.05\t\t0.07\t\t0.258\t\t0.764\t\t1.77m - 12.4m / 63.0m                                                                  \n",
      "8\t112k\t0.06\t\t0.06\t\t0.185\t\t0.670\t\t1.77m - 14.2m / 61.9m                                                                 \n",
      "VAL f1\t0.4915747813214653 - (0.4915747813214653)                                                                       \n",
      "VAL loss\t0.035616806840750116                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.035616806840750116\n",
      "        | \\     )|_\tf1: 0.4915747813214653\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\13 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 51.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         51                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.01031892753150927                |\n",
      "|  noam_learning_rate_warmup   |                        6731                       |\n",
      "|  noam_learning_rate_factor   |                 1.9851463308560005                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.04433851063707089                |\n",
      "|     pointwise_layer_size     |                        280                        |\n",
      "|      last_layer_dropout      |                0.36915068647638893                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  6%|██▌                                        | 9/150 [1:36:21<30:24:21, 776.32s/it, best loss: 0.010560442404578362]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2991de2de2b43a683623b1b369d5b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.127\t\t0.809\t\t0.25m - 0.2m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.156\t\t0.846\t\t0.25m - 0.5m / 8.7m                                                                    \n",
      "3\t42k\t0.01\t\t0.01\t\t0.192\t\t0.876\t\t0.25m - 0.8m / 9.0m                                                                    \n",
      "4\t56k\t0.00\t\t0.01\t\t0.204\t\t0.885\t\t0.25m - 1.1m / 8.7m                                                                    \n",
      "5\t70k\t0.00\t\t0.01\t\t0.174\t\t0.865\t\t0.25m - 1.3m / 8.8m                                                                    \n",
      "6\t84k\t0.00\t\t0.01\t\t0.201\t\t0.883\t\t0.24m - 1.6m / 8.7m                                                                    \n",
      "7\t99k\t0.00\t\t0.01\t\t0.187\t\t0.877\t\t0.25m - 1.8m / 8.7m                                                                    \n",
      "8\t113k\t0.00\t\t0.01\t\t0.165\t\t0.856\t\t0.25m - 2.1m / 8.8m                                                                   \n",
      "9\t127k\t0.00\t\t0.01\t\t0.171\t\t0.860\t\t0.25m - 2.4m / 8.8m                                                                   \n",
      "VAL f1\t0.20399647307999075 - (0.20399647307999075)                                                                     \n",
      "VAL loss\t0.007256374223039066                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.007256374223039066\n",
      "        | \\     )|_\tf1: 0.20399647307999075\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\14 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 35.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         35                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0008937839485428716               |\n",
      "|  noam_learning_rate_warmup   |                        3405                       |\n",
      "|  noam_learning_rate_factor   |                 2.6804948659217653                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7228890487699329                |\n",
      "|     pointwise_layer_size     |                        216                        |\n",
      "|      last_layer_dropout      |                0.04999531741628918                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  7%|██▊                                       | 10/150 [1:39:07<23:04:09, 593.21s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d01cd6140442694a6bc0ac3102f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.155\t\t0.798\t\t0.33m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.05\t\t0.161\t\t0.800\t\t0.34m - 0.7m / 11.6m                                                                   \n",
      "3\t42k\t0.02\t\t0.04\t\t0.192\t\t0.835\t\t0.34m - 1.0m / 11.8m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.184\t\t0.826\t\t0.34m - 1.4m / 11.8m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.185\t\t0.831\t\t0.33m - 1.7m / 12.0m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.159\t\t0.800\t\t0.33m - 2.1m / 11.8m                                                                   \n",
      "7\t98k\t0.02\t\t0.04\t\t0.119\t\t0.741\t\t0.33m - 2.4m / 11.8m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.182\t\t0.831\t\t0.34m - 2.8m / 11.8m                                                                  \n",
      "VAL f1\t0.1924862111127643 - (0.1924862111127643)                                                                       \n",
      "VAL loss\t0.02872827890373412                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02872827890373412\n",
      "        | \\     )|_\tf1: 0.1924862111127643\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\15 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 62.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         62                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.017752809733280868               |\n",
      "|  noam_learning_rate_warmup   |                        1649                       |\n",
      "|  noam_learning_rate_factor   |                 0.9142336249876934                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7255383005299294                |\n",
      "|     pointwise_layer_size     |                        169                        |\n",
      "|      last_layer_dropout      |                 0.0229806267446401                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  7%|███                                       | 11/150 [1:42:20<18:15:58, 473.08s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d2f05b8292402296d0bcb5b568c407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.093\t\t0.787\t\t0.33m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.094\t\t0.788\t\t0.33m - 0.7m / 11.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.112\t\t0.810\t\t0.32m - 1.0m / 11.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.082\t\t0.768\t\t0.33m - 1.4m / 11.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.123\t\t0.824\t\t0.33m - 1.7m / 11.7m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.123\t\t0.826\t\t0.32m - 2.0m / 11.7m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.142\t\t0.849\t\t0.33m - 2.4m / 11.4m                                                                   \n",
      "8\t113k\t0.01\t\t0.01\t\t0.140\t\t0.849\t\t0.32m - 2.7m / 11.6m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.154\t\t0.862\t\t0.32m - 3.1m / 11.5m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.140\t\t0.849\t\t0.33m - 3.4m / 11.5m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.163\t\t0.871\t\t0.33m - 3.8m / 11.8m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.125\t\t0.848\t\t0.32m - 4.2m / 11.9m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.151\t\t0.860\t\t0.32m - 4.5m / 11.5m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.144\t\t0.855\t\t0.32m - 4.8m / 11.5m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.147\t\t0.858\t\t0.32m - 5.2m / 11.6m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.143\t\t0.853\t\t0.32m - 5.5m / 11.6m                                                                 \n",
      "VAL f1\t0.16256259268693993 - (0.16256259268693993)                                                                     \n",
      "VAL loss\t0.01301168220495205                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01301168220495205\n",
      "        | \\     )|_\tf1: 0.16256259268693993\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\16 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 22.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         22                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.016923845204248177               |\n",
      "|  noam_learning_rate_warmup   |                        3207                       |\n",
      "|  noam_learning_rate_factor   |                 1.4308059084499292                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7290657854839666                |\n",
      "|     pointwise_layer_size     |                         99                        |\n",
      "|      last_layer_dropout      |                 0.4468696274254462                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  8%|███▎                                      | 12/150 [1:48:15<16:46:33, 437.63s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b52f334a8842cbbee8c03f27d5e78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.08\t\t0.250\t\t0.813\t\t0.75m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.05\t\t0.258\t\t0.827\t\t0.77m - 1.5m / 26.2m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.250\t\t0.811\t\t0.75m - 2.3m / 26.8m                                                                   \n",
      "4\t56k\t0.04\t\t0.05\t\t0.256\t\t0.814\t\t0.78m - 3.1m / 26.3m                                                                   \n",
      "5\t70k\t0.04\t\t0.05\t\t0.254\t\t0.811\t\t0.75m - 3.9m / 27.3m                                                                   \n",
      "6\t84k\t0.04\t\t0.05\t\t0.288\t\t0.846\t\t0.75m - 4.6m / 26.3m                                                                   \n",
      "7\t98k\t0.04\t\t0.05\t\t0.299\t\t0.845\t\t0.76m - 5.4m / 26.3m                                                                   \n",
      "8\t112k\t0.04\t\t0.05\t\t0.277\t\t0.834\t\t0.74m - 6.1m / 26.8m                                                                  \n",
      "9\t127k\t0.03\t\t0.05\t\t0.301\t\t0.847\t\t0.74m - 6.9m / 26.1m                                                                  \n",
      "10\t141k\t0.03\t\t0.06\t\t0.292\t\t0.842\t\t0.75m - 7.7m / 26.3m                                                                 \n",
      "11\t155k\t0.03\t\t0.05\t\t0.314\t\t0.856\t\t0.76m - 8.4m / 26.5m                                                                 \n",
      "12\t169k\t0.03\t\t0.05\t\t0.320\t\t0.858\t\t0.74m - 9.2m / 26.6m                                                                 \n",
      "13\t183k\t0.03\t\t0.06\t\t0.318\t\t0.859\t\t0.75m - 10.0m / 26.2m                                                                \n",
      "14\t197k\t0.03\t\t0.05\t\t0.330\t\t0.866\t\t0.74m - 10.7m / 26.5m                                                                \n",
      "15\t211k\t0.03\t\t0.05\t\t0.302\t\t0.850\t\t0.74m - 11.5m / 26.4m                                                                \n",
      "16\t225k\t0.03\t\t0.05\t\t0.308\t\t0.854\t\t0.74m - 12.2m / 26.3m                                                                \n",
      "17\t239k\t0.03\t\t0.05\t\t0.307\t\t0.853\t\t0.76m - 13.0m / 26.3m                                                                \n",
      "18\t253k\t0.03\t\t0.05\t\t0.302\t\t0.850\t\t0.76m - 13.8m / 26.6m                                                                \n",
      "19\t267k\t0.03\t\t0.05\t\t0.308\t\t0.854\t\t0.74m - 14.5m / 26.6m                                                                \n",
      "VAL f1\t0.3298463355812131 - (0.3298463355812131)                                                                       \n",
      "VAL loss\t0.047148294633034736                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.047148294633034736\n",
      "        | \\     )|_\tf1: 0.3298463355812131\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\17 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 20.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         20                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00530802920167985                |\n",
      "|  noam_learning_rate_warmup   |                        8524                       |\n",
      "|  noam_learning_rate_factor   |                 3.623937381980588                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.48856371522531944                |\n",
      "|     pointwise_layer_size     |                         93                        |\n",
      "|      last_layer_dropout      |                 0.5308005846629092                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  9%|███▋                                      | 13/150 [2:03:25<22:03:04, 579.45s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329f44e03750436da4a30a1483ece1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.06\t\t0.270\t\t0.824\t\t1.29m - 1.3m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.04\t\t0.327\t\t0.852\t\t1.30m - 2.6m / 45.3m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.382\t\t0.880\t\t1.28m - 3.9m / 45.5m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.370\t\t0.875\t\t1.30m - 5.2m / 45.0m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.425\t\t0.900\t\t1.30m - 6.5m / 45.5m                                                                   \n",
      "6\t84k\t0.03\t\t0.05\t\t0.376\t\t0.879\t\t1.32m - 7.9m / 45.7m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.337\t\t0.860\t\t1.31m - 9.2m / 46.3m                                                                   \n",
      "8\t112k\t0.04\t\t0.05\t\t0.263\t\t0.812\t\t1.29m - 10.5m / 46.0m                                                                 \n",
      "9\t127k\t0.04\t\t0.07\t\t0.312\t\t0.840\t\t1.31m - 11.8m / 45.4m                                                                 \n",
      "10\t141k\t0.05\t\t0.06\t\t0.152\t\t0.682\t\t1.31m - 13.2m / 46.0m                                                                \n",
      "VAL f1\t0.42524059835262323 - (0.42524059835262323)                                                                     \n",
      "VAL loss\t0.03409919696888584                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03409919696888584\n",
      "        | \\     )|_\tf1: 0.42524059835262323\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\18 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 27.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         27                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.008393771405944519               |\n",
      "|  noam_learning_rate_warmup   |                        6866                       |\n",
      "|  noam_learning_rate_factor   |                 2.6366999892082914                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.13631858114297302                |\n",
      "|     pointwise_layer_size     |                        125                        |\n",
      "|      last_layer_dropout      |                 0.7054042199767137                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "  9%|███▉                                      | 14/150 [2:17:29<24:52:49, 658.60s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e78409bf4043f59f0edc6c675b1663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.02\t\t0.284\t\t0.866\t\t0.68m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.335\t\t0.892\t\t0.67m - 1.4m / 23.9m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.339\t\t0.896\t\t0.64m - 2.0m / 23.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.431\t\t0.923\t\t0.66m - 2.7m / 22.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.376\t\t0.909\t\t0.65m - 3.4m / 23.1m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.295\t\t0.876\t\t0.66m - 4.0m / 22.9m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.373\t\t0.907\t\t0.66m - 4.7m / 23.1m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.298\t\t0.877\t\t0.65m - 5.4m / 23.3m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.326\t\t0.899\t\t0.64m - 6.0m / 23.0m                                                                  \n",
      "VAL f1\t0.4309624479648767 - (0.4309624479648767)                                                                       \n",
      "VAL loss\t0.014885142559592134                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014885142559592134\n",
      "        | \\     )|_\tf1: 0.4309624479648767\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\19 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 59.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         59                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005616204910732535               |\n",
      "|  noam_learning_rate_warmup   |                        5281                       |\n",
      "|  noam_learning_rate_factor   |                 3.640965777235631                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.2412908323397298                |\n",
      "|     pointwise_layer_size     |                         40                        |\n",
      "|      last_layer_dropout      |                 0.7716518379829388                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 10%|████▏                                     | 15/150 [2:24:08<21:47:03, 580.91s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1651a146710a4373b55c1244a7531d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.01\t\t0.113\t\t0.821\t\t0.23m - 0.2m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.111\t\t0.823\t\t0.23m - 0.5m / 8.0m                                                                    \n",
      "3\t42k\t0.00\t\t0.01\t\t0.135\t\t0.853\t\t0.23m - 0.7m / 8.1m                                                                    \n",
      "4\t56k\t0.00\t\t0.01\t\t0.137\t\t0.854\t\t0.23m - 1.0m / 8.1m                                                                    \n",
      "5\t70k\t0.00\t\t0.01\t\t0.119\t\t0.838\t\t0.23m - 1.2m / 8.1m                                                                    \n",
      "6\t84k\t0.00\t\t0.01\t\t0.138\t\t0.863\t\t0.23m - 1.5m / 8.2m                                                                    \n",
      "7\t98k\t0.00\t\t0.01\t\t0.134\t\t0.850\t\t0.23m - 1.7m / 8.1m                                                                    \n",
      "8\t112k\t0.00\t\t0.01\t\t0.129\t\t0.854\t\t0.23m - 1.9m / 8.0m                                                                   \n",
      "9\t126k\t0.00\t\t0.01\t\t0.152\t\t0.870\t\t0.23m - 2.2m / 8.0m                                                                   \n",
      "10\t140k\t0.00\t\t0.01\t\t0.131\t\t0.855\t\t0.23m - 2.4m / 8.0m                                                                  \n",
      "11\t154k\t0.00\t\t0.01\t\t0.159\t\t0.880\t\t0.23m - 2.7m / 8.2m                                                                  \n",
      "12\t169k\t0.00\t\t0.01\t\t0.148\t\t0.863\t\t0.22m - 2.9m / 8.2m                                                                  \n",
      "13\t183k\t0.00\t\t0.01\t\t0.151\t\t0.867\t\t0.22m - 3.2m / 8.1m                                                                  \n",
      "14\t197k\t0.00\t\t0.01\t\t0.144\t\t0.866\t\t0.23m - 3.4m / 8.1m                                                                  \n",
      "15\t211k\t0.00\t\t0.01\t\t0.124\t\t0.844\t\t0.23m - 3.6m / 8.2m                                                                  \n",
      "16\t225k\t0.00\t\t0.01\t\t0.132\t\t0.852\t\t0.23m - 3.9m / 8.2m                                                                  \n",
      "VAL f1\t0.1592319996192781 - (0.1592319996192781)                                                                       \n",
      "VAL loss\t0.007684230910429221                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.007684230910429221\n",
      "        | \\     )|_\tf1: 0.1592319996192781\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\20 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 52.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         52                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.1490499999782736                |\n",
      "|  noam_learning_rate_warmup   |                        3600                       |\n",
      "|  noam_learning_rate_factor   |                 3.492179705265326                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.748479320106654                 |\n",
      "|     pointwise_layer_size     |                        329                        |\n",
      "|      last_layer_dropout      |                 0.2849960710383928                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 11%|████▍                                     | 16/150 [2:28:25<18:00:00, 483.58s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5b8975233244519c1faa6ebfa1f0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.113\t\t0.793\t\t0.26m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.127\t\t0.814\t\t0.26m - 0.5m / 9.0m                                                                    \n",
      "3\t42k\t0.02\t\t0.03\t\t0.118\t\t0.799\t\t0.25m - 0.8m / 9.0m                                                                    \n",
      "4\t56k\t0.01\t\t0.02\t\t0.142\t\t0.829\t\t0.26m - 1.1m / 8.9m                                                                    \n",
      "5\t70k\t0.01\t\t0.02\t\t0.150\t\t0.839\t\t0.25m - 1.3m / 9.0m                                                                    \n",
      "6\t85k\t0.01\t\t0.02\t\t0.167\t\t0.859\t\t0.25m - 1.6m / 8.9m                                                                    \n",
      "7\t99k\t0.01\t\t0.02\t\t0.168\t\t0.859\t\t0.25m - 1.9m / 8.9m                                                                    \n",
      "8\t113k\t0.01\t\t0.02\t\t0.171\t\t0.862\t\t0.25m - 2.1m / 8.9m                                                                   \n",
      "9\t127k\t0.01\t\t0.02\t\t0.178\t\t0.868\t\t0.25m - 2.4m / 9.0m                                                                   \n",
      "10\t141k\t0.01\t\t0.02\t\t0.160\t\t0.855\t\t0.25m - 2.7m / 8.9m                                                                  \n",
      "11\t155k\t0.01\t\t0.02\t\t0.177\t\t0.867\t\t0.25m - 2.9m / 8.9m                                                                  \n",
      "12\t169k\t0.01\t\t0.02\t\t0.158\t\t0.852\t\t0.25m - 3.2m / 9.0m                                                                  \n",
      "13\t183k\t0.01\t\t0.02\t\t0.158\t\t0.852\t\t0.25m - 3.5m / 8.9m                                                                  \n",
      "14\t197k\t0.01\t\t0.02\t\t0.175\t\t0.868\t\t0.25m - 3.7m / 8.9m                                                                  \n",
      "VAL f1\t0.17791374326992446 - (0.17791374326992446)                                                                     \n",
      "VAL loss\t0.017298547246280754                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.017298547246280754\n",
      "        | \\     )|_\tf1: 0.17791374326992446\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\21 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00023337491070251113              |\n",
      "|  noam_learning_rate_warmup   |                        4010                       |\n",
      "|  noam_learning_rate_factor   |                  2.89202104090236                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7928154489401148                |\n",
      "|     pointwise_layer_size     |                        203                        |\n",
      "|      last_layer_dropout      |                 0.3315786964351646                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 11%|████▊                                     | 17/150 [2:32:37<15:18:00, 414.14s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e336c33bb74e96a3e1935a214325f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.135\t\t0.799\t\t0.80m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.04\t\t0.135\t\t0.799\t\t0.80m - 1.6m / 27.9m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.135\t\t0.799\t\t0.79m - 2.4m / 27.9m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.135\t\t0.799\t\t0.77m - 3.2m / 27.8m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.135\t\t0.799\t\t0.79m - 4.0m / 27.2m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.135\t\t0.799\t\t0.77m - 4.8m / 27.8m                                                                   \n",
      "VAL f1\t0.13502363699347208 - (0.13502363699347208)                                                                     \n",
      "VAL loss\t0.03806721839502071                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03806721839502071\n",
      "        | \\     )|_\tf1: 0.13502363699347208\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\22 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 45.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         45                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03433384254065044                |\n",
      "|  noam_learning_rate_warmup   |                        6873                       |\n",
      "|  noam_learning_rate_factor   |                 1.088917768053118                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6882219887796084                |\n",
      "|     pointwise_layer_size     |                        197                        |\n",
      "|      last_layer_dropout      |                 0.7142824584611461                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 12%|█████                                     | 18/150 [2:38:01<14:11:46, 387.17s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df05de8cc8e4ce0b3887fea1ba182ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.138\t\t0.810\t\t0.45m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.138\t\t0.810\t\t0.47m - 0.9m / 15.6m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.138\t\t0.810\t\t0.44m - 1.4m / 16.5m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.165\t\t0.835\t\t0.44m - 1.8m / 15.6m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.162\t\t0.841\t\t0.44m - 2.3m / 15.6m                                                                   \n",
      "6\t85k\t0.02\t\t0.03\t\t0.143\t\t0.813\t\t0.43m - 2.7m / 15.5m                                                                   \n",
      "7\t99k\t0.02\t\t0.03\t\t0.161\t\t0.832\t\t0.45m - 3.2m / 15.4m                                                                   \n",
      "8\t113k\t0.01\t\t0.03\t\t0.167\t\t0.836\t\t0.45m - 3.7m / 15.8m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.208\t\t0.870\t\t0.44m - 4.1m / 15.9m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.203\t\t0.868\t\t0.44m - 4.6m / 15.7m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.221\t\t0.878\t\t0.45m - 5.1m / 15.7m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.241\t\t0.892\t\t0.44m - 5.5m / 15.9m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.256\t\t0.900\t\t0.44m - 6.0m / 15.7m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.252\t\t0.899\t\t0.44m - 6.4m / 15.7m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.247\t\t0.893\t\t0.44m - 6.9m / 15.7m                                                                 \n",
      "16\t225k\t0.01\t\t0.02\t\t0.257\t\t0.900\t\t0.45m - 7.3m / 15.7m                                                                 \n",
      "17\t239k\t0.01\t\t0.02\t\t0.264\t\t0.904\t\t0.45m - 7.8m / 15.9m                                                                 \n",
      "18\t254k\t0.01\t\t0.02\t\t0.263\t\t0.905\t\t0.45m - 8.3m / 16.0m                                                                 \n",
      "19\t268k\t0.01\t\t0.01\t\t0.275\t\t0.909\t\t0.46m - 8.7m / 15.9m                                                                 \n",
      "20\t282k\t0.01\t\t0.01\t\t0.261\t\t0.904\t\t0.45m - 9.2m / 16.1m                                                                 \n",
      "21\t296k\t0.01\t\t0.01\t\t0.271\t\t0.907\t\t0.46m - 9.7m / 15.9m                                                                 \n",
      "22\t310k\t0.01\t\t0.01\t\t0.266\t\t0.903\t\t0.45m - 10.1m / 16.1m                                                                \n",
      "23\t324k\t0.01\t\t0.02\t\t0.250\t\t0.896\t\t0.45m - 10.6m / 16.0m                                                                \n",
      "24\t338k\t0.01\t\t0.01\t\t0.248\t\t0.896\t\t0.45m - 11.1m / 16.0m                                                                \n",
      "VAL f1\t0.2747194083488304 - (0.2747194083488304)                                                                       \n",
      "VAL loss\t0.010823869836038969                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.010823869836038969\n",
      "        | \\     )|_\tf1: 0.2747194083488304\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\23 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 44.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         44                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04758465641833792                |\n",
      "|  noam_learning_rate_warmup   |                        1707                       |\n",
      "|  noam_learning_rate_factor   |                 0.6820148540151122                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.28253014227931095                |\n",
      "|     pointwise_layer_size     |                        324                        |\n",
      "|      last_layer_dropout      |                 0.7013476404870481                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 13%|█████▎                                    | 19/150 [2:49:35<17:26:01, 479.09s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc516229161a4152830ff1b906bd379c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.111\t\t0.776\t\t0.66m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.163\t\t0.839\t\t0.68m - 1.4m / 23.3m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.176\t\t0.856\t\t0.68m - 2.1m / 24.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.185\t\t0.870\t\t0.73m - 2.8m / 23.7m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.170\t\t0.861\t\t0.68m - 3.5m / 25.3m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.203\t\t0.877\t\t0.68m - 4.2m / 24.0m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.205\t\t0.882\t\t0.67m - 5.0m / 24.0m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.200\t\t0.876\t\t0.65m - 5.7m / 23.8m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.170\t\t0.867\t\t0.66m - 6.4m / 23.4m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.159\t\t0.855\t\t0.65m - 7.1m / 23.5m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.207\t\t0.879\t\t0.67m - 7.7m / 23.3m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.214\t\t0.883\t\t0.66m - 8.4m / 23.9m                                                                 \n",
      "13\t183k\t0.00\t\t0.02\t\t0.210\t\t0.882\t\t0.66m - 9.1m / 23.7m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.229\t\t0.892\t\t0.65m - 9.8m / 23.7m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.215\t\t0.885\t\t0.68m - 10.5m / 23.4m                                                                \n",
      "16\t225k\t0.00\t\t0.01\t\t0.189\t\t0.867\t\t0.68m - 11.2m / 24.2m                                                                \n",
      "17\t239k\t0.00\t\t0.02\t\t0.206\t\t0.886\t\t0.71m - 11.9m / 24.1m                                                                \n",
      "18\t253k\t0.00\t\t0.02\t\t0.170\t\t0.866\t\t0.69m - 12.6m / 24.7m                                                                \n",
      "19\t268k\t0.00\t\t0.01\t\t0.202\t\t0.883\t\t0.68m - 13.3m / 24.4m                                                                \n",
      "VAL f1\t0.22919338691180985 - (0.22919338691180985)                                                                     \n",
      "VAL loss\t0.010701253362622395                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.010701253362622395\n",
      "        | \\     )|_\tf1: 0.22919338691180985\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\24 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 45.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         45                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.29669237637552537                |\n",
      "|  noam_learning_rate_warmup   |                        6458                       |\n",
      "|  noam_learning_rate_factor   |                 1.6394653271892075                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.34070599481651637                |\n",
      "|     pointwise_layer_size     |                        102                        |\n",
      "|      last_layer_dropout      |                 0.3700576515355609                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 13%|█████▌                                    | 20/150 [3:03:37<21:14:12, 588.10s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fedc99060d42de8c3bb37d5152af63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.138\t\t0.810\t\t0.72m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.124\t\t0.789\t\t0.69m - 1.4m / 25.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.176\t\t0.846\t\t0.73m - 2.2m / 24.4m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.179\t\t0.855\t\t0.65m - 2.9m / 25.6m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.137\t\t0.827\t\t0.68m - 3.6m / 23.1m                                                                   \n",
      "6\t85k\t0.01\t\t0.02\t\t0.114\t\t0.793\t\t0.69m - 4.3m / 23.9m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.173\t\t0.865\t\t0.68m - 5.0m / 24.2m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.187\t\t0.867\t\t0.68m - 5.7m / 24.0m                                                                  \n",
      "9\t127k\t0.00\t\t0.02\t\t0.232\t\t0.891\t\t0.70m - 6.4m / 24.2m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.210\t\t0.881\t\t0.66m - 7.1m / 24.5m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.282\t\t0.912\t\t0.72m - 7.8m / 23.6m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.213\t\t0.887\t\t0.67m - 8.5m / 25.0m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.218\t\t0.894\t\t0.64m - 9.1m / 24.0m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.208\t\t0.880\t\t0.68m - 9.8m / 23.2m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.240\t\t0.896\t\t0.67m - 10.5m / 24.0m                                                                \n",
      "16\t225k\t0.00\t\t0.01\t\t0.272\t\t0.908\t\t0.68m - 11.2m / 24.0m                                                                \n",
      "VAL f1\t0.2821178955158604 - (0.2821178955158604)                                                                       \n",
      "VAL loss\t0.01223251583732245                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01223251583732245\n",
      "        | \\     )|_\tf1: 0.2821178955158604\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\25 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 57.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         57                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.14500577541410936                |\n",
      "|  noam_learning_rate_warmup   |                        3987                       |\n",
      "|  noam_learning_rate_factor   |                 3.323150369368736                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7305295065645483                |\n",
      "|     pointwise_layer_size     |                        178                        |\n",
      "|      last_layer_dropout      |                0.32660535173991784                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 14%|█████▉                                    | 21/150 [3:15:37<22:29:35, 627.71s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3974b08b47d141658d0661ad147ac897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.084\t\t0.768\t\t0.28m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.086\t\t0.774\t\t0.30m - 0.6m / 10.0m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.098\t\t0.797\t\t0.29m - 0.9m / 10.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.115\t\t0.825\t\t0.28m - 1.2m / 10.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.126\t\t0.838\t\t0.31m - 1.5m / 9.9m                                                                    \n",
      "6\t84k\t0.01\t\t0.02\t\t0.126\t\t0.837\t\t0.30m - 1.9m / 10.8m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.128\t\t0.845\t\t0.29m - 2.2m / 10.5m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.132\t\t0.845\t\t0.30m - 2.5m / 10.3m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.136\t\t0.848\t\t0.28m - 2.8m / 10.7m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.136\t\t0.851\t\t0.29m - 3.1m / 10.2m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.133\t\t0.844\t\t0.29m - 3.4m / 10.3m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.140\t\t0.856\t\t0.33m - 3.8m / 10.4m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.133\t\t0.849\t\t0.29m - 4.1m / 11.3m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.122\t\t0.829\t\t0.28m - 4.4m / 10.4m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.133\t\t0.846\t\t0.27m - 4.7m / 10.3m                                                                 \n",
      "16\t225k\t0.01\t\t0.01\t\t0.124\t\t0.828\t\t0.27m - 4.9m / 10.1m                                                                 \n",
      "17\t239k\t0.01\t\t0.01\t\t0.123\t\t0.832\t\t0.28m - 5.2m / 10.2m                                                                 \n",
      "VAL f1\t0.14037718819127318 - (0.14037718819127318)                                                                     \n",
      "VAL loss\t0.011824117528350152                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011824117528350152\n",
      "        | \\     )|_\tf1: 0.14037718819127318\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\26 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 23.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         23                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00037265941582510586              |\n",
      "|  noam_learning_rate_warmup   |                        7688                       |\n",
      "|  noam_learning_rate_factor   |                 2.2606848203928864                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6102932131662426                |\n",
      "|     pointwise_layer_size     |                        340                        |\n",
      "|      last_layer_dropout      |                0.31136562673774404                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 15%|██████▏                                   | 22/150 [3:21:21<19:17:19, 542.50s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd9bf4727dc4f5ba79cc0302907a9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.05\t\t0.241\t\t0.810\t\t0.53m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.04\t\t0.289\t\t0.848\t\t0.59m - 1.1m / 18.7m                                                                   \n",
      "3\t42k\t0.03\t\t0.05\t\t0.253\t\t0.834\t\t0.59m - 1.8m / 20.7m                                                                   \n",
      "4\t56k\t0.02\t\t0.05\t\t0.235\t\t0.819\t\t0.61m - 2.4m / 20.7m                                                                   \n",
      "5\t70k\t0.02\t\t0.04\t\t0.275\t\t0.850\t\t0.53m - 2.9m / 21.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.04\t\t0.278\t\t0.856\t\t0.57m - 3.5m / 18.7m                                                                   \n",
      "7\t98k\t0.01\t\t0.04\t\t0.274\t\t0.857\t\t0.59m - 4.1m / 20.2m                                                                   \n",
      "VAL f1\t0.28880837835049594 - (0.28880837835049594)                                                                     \n",
      "VAL loss\t0.04113665081227549                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04113665081227549\n",
      "        | \\     )|_\tf1: 0.28880837835049594\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\27 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 30.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         30                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.08793242288808983                |\n",
      "|  noam_learning_rate_warmup   |                        1812                       |\n",
      "|  noam_learning_rate_factor   |                 1.357421724471059                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7185219595296193                |\n",
      "|     pointwise_layer_size     |                        326                        |\n",
      "|      last_layer_dropout      |                0.09028428300789698                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 15%|██████▍                                   | 23/150 [3:26:14<16:29:45, 467.60s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca88982186d64805b0cd8ed463e619e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.06\t\t0.196\t\t0.815\t\t0.74m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.03\t\t0.184\t\t0.793\t\t0.75m - 1.5m / 25.9m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.213\t\t0.823\t\t0.75m - 2.3m / 26.4m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.200\t\t0.812\t\t0.75m - 3.1m / 26.4m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.221\t\t0.831\t\t0.73m - 3.8m / 26.4m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.212\t\t0.822\t\t0.73m - 4.6m / 25.9m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.218\t\t0.826\t\t0.77m - 5.3m / 25.9m                                                                   \n",
      "8\t113k\t0.02\t\t0.04\t\t0.226\t\t0.841\t\t0.74m - 6.1m / 26.8m                                                                  \n",
      "9\t127k\t0.02\t\t0.04\t\t0.172\t\t0.814\t\t0.74m - 6.9m / 26.1m                                                                  \n",
      "10\t141k\t0.02\t\t0.04\t\t0.212\t\t0.838\t\t0.77m - 7.6m / 26.1m                                                                 \n",
      "11\t155k\t0.02\t\t0.03\t\t0.230\t\t0.846\t\t0.72m - 8.4m / 26.8m                                                                 \n",
      "12\t169k\t0.02\t\t0.04\t\t0.190\t\t0.823\t\t0.71m - 9.1m / 25.7m                                                                 \n",
      "13\t183k\t0.02\t\t0.04\t\t0.228\t\t0.845\t\t0.71m - 9.8m / 25.5m                                                                 \n",
      "14\t197k\t0.02\t\t0.04\t\t0.186\t\t0.826\t\t0.70m - 10.5m / 25.4m                                                                \n",
      "15\t211k\t0.02\t\t0.04\t\t0.212\t\t0.852\t\t0.73m - 11.3m / 25.2m                                                                \n",
      "16\t225k\t0.02\t\t0.04\t\t0.231\t\t0.844\t\t0.73m - 12.0m / 25.8m                                                                \n",
      "17\t239k\t0.02\t\t0.04\t\t0.231\t\t0.851\t\t0.72m - 12.8m / 25.9m                                                                \n",
      "18\t253k\t0.02\t\t0.04\t\t0.236\t\t0.850\t\t0.72m - 13.5m / 25.7m                                                                \n",
      "19\t267k\t0.02\t\t0.04\t\t0.213\t\t0.849\t\t0.72m - 14.2m / 25.8m                                                                \n",
      "20\t281k\t0.02\t\t0.04\t\t0.236\t\t0.849\t\t0.68m - 14.9m / 25.8m                                                                \n",
      "21\t295k\t0.02\t\t0.04\t\t0.256\t\t0.856\t\t0.69m - 15.7m / 25.1m                                                                \n",
      "22\t310k\t0.02\t\t0.04\t\t0.253\t\t0.855\t\t0.74m - 16.4m / 25.3m                                                                \n",
      "23\t324k\t0.02\t\t0.04\t\t0.258\t\t0.865\t\t0.80m - 17.2m / 26.1m                                                                \n",
      "24\t338k\t0.02\t\t0.04\t\t0.250\t\t0.864\t\t0.65m - 17.9m / 26.9m                                                                \n",
      "25\t352k\t0.02\t\t0.04\t\t0.219\t\t0.858\t\t0.63m - 18.6m / 25.1m                                                                \n",
      "26\t366k\t0.02\t\t0.04\t\t0.279\t\t0.870\t\t0.61m - 19.2m / 24.9m                                                                \n",
      "27\t380k\t0.02\t\t0.04\t\t0.201\t\t0.853\t\t0.61m - 19.8m / 24.7m                                                                \n",
      "28\t394k\t0.02\t\t0.04\t\t0.267\t\t0.872\t\t0.63m - 20.4m / 24.7m                                                                \n",
      "29\t408k\t0.02\t\t0.04\t\t0.253\t\t0.869\t\t0.61m - 21.1m / 24.8m                                                                \n",
      "30\t422k\t0.02\t\t0.04\t\t0.233\t\t0.867\t\t0.62m - 21.7m / 24.8m                                                                \n",
      "31\t436k\t0.02\t\t0.04\t\t0.250\t\t0.870\t\t0.62m - 22.3m / 24.8m                                                                \n",
      "VAL f1\t0.27885458730812224 - (0.27885458730812224)                                                                     \n",
      "VAL loss\t0.03182450731164585                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03182450731164585\n",
      "        | \\     )|_\tf1: 0.27885458730812224\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\28 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.28577817100230984                |\n",
      "|  noam_learning_rate_warmup   |                        1149                       |\n",
      "|  noam_learning_rate_factor   |                 3.6174193926488694                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.33850621591024155                |\n",
      "|     pointwise_layer_size     |                        111                        |\n",
      "|      last_layer_dropout      |                 0.699834023165381                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 16%|██████▋                                   | 24/150 [3:49:10<25:54:41, 740.33s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73873ecc34bd49e8b01d5b5ae0c5968f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.09\t\t0.10\t\t0.316\t\t0.819\t\t1.81m - 1.8m / 0.0m                                                                    \n",
      "2\t28k\t0.09\t\t0.09\t\t0.316\t\t0.819\t\t1.70m - 3.5m / 63.5m                                                                   \n",
      "3\t42k\t0.08\t\t0.08\t\t0.219\t\t0.769\t\t1.64m - 5.2m / 59.6m                                                                   \n",
      "4\t56k\t0.07\t\t0.09\t\t0.238\t\t0.755\t\t1.71m - 6.9m / 57.7m                                                                   \n",
      "5\t70k\t0.07\t\t0.08\t\t0.263\t\t0.777\t\t1.74m - 8.7m / 60.0m                                                                   \n",
      "6\t84k\t0.07\t\t0.07\t\t0.276\t\t0.788\t\t1.72m - 10.4m / 61.0m                                                                  \n",
      "VAL f1\t0.3160025966520403 - (0.3160025966520403)                                                                       \n",
      "VAL loss\t0.07185446733024482                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.07185446733024482\n",
      "        | \\     )|_\tf1: 0.3160025966520403\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\29 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 62.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         62                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.010447153238832238               |\n",
      "|  noam_learning_rate_warmup   |                        4941                       |\n",
      "|  noam_learning_rate_factor   |                 0.8673690607953574                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7312648353935001                |\n",
      "|     pointwise_layer_size     |                        327                        |\n",
      "|      last_layer_dropout      |                0.28792158731214784                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 17%|███████                                   | 25/150 [4:00:42<25:12:07, 725.82s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ad68c1170447a4b8b8971fc16ab1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.093\t\t0.787\t\t0.34m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.093\t\t0.787\t\t0.35m - 0.7m / 12.1m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.093\t\t0.787\t\t0.35m - 1.1m / 12.4m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.093\t\t0.787\t\t0.36m - 1.5m / 12.4m                                                                   \n",
      "5\t70k\t0.02\t\t0.02\t\t0.103\t\t0.796\t\t0.35m - 1.8m / 12.5m                                                                   \n",
      "6\t84k\t0.02\t\t0.02\t\t0.083\t\t0.760\t\t0.35m - 2.2m / 12.4m                                                                   \n",
      "7\t99k\t0.02\t\t0.02\t\t0.105\t\t0.803\t\t0.35m - 2.5m / 12.3m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.114\t\t0.816\t\t0.35m - 2.9m / 12.2m                                                                  \n",
      "9\t127k\t0.01\t\t0.03\t\t0.096\t\t0.789\t\t0.35m - 3.3m / 12.3m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.109\t\t0.804\t\t0.36m - 3.6m / 12.3m                                                                 \n",
      "11\t155k\t0.01\t\t0.03\t\t0.105\t\t0.796\t\t0.37m - 4.0m / 12.6m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.124\t\t0.828\t\t0.35m - 4.4m / 12.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.136\t\t0.843\t\t0.37m - 4.8m / 12.6m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.146\t\t0.853\t\t0.36m - 5.2m / 13.0m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.145\t\t0.853\t\t0.36m - 5.6m / 12.8m                                                                 \n",
      "16\t225k\t0.01\t\t0.01\t\t0.154\t\t0.862\t\t0.38m - 6.0m / 12.7m                                                                 \n",
      "17\t239k\t0.01\t\t0.01\t\t0.153\t\t0.862\t\t0.35m - 6.3m / 13.2m                                                                 \n",
      "18\t253k\t0.01\t\t0.01\t\t0.151\t\t0.862\t\t0.35m - 6.7m / 12.6m                                                                 \n",
      "19\t267k\t0.01\t\t0.02\t\t0.155\t\t0.867\t\t0.36m - 7.1m / 12.7m                                                                 \n",
      "20\t281k\t0.01\t\t0.01\t\t0.157\t\t0.865\t\t0.35m - 7.4m / 12.9m                                                                 \n",
      "21\t296k\t0.01\t\t0.02\t\t0.160\t\t0.869\t\t0.34m - 7.8m / 12.6m                                                                 \n",
      "22\t310k\t0.00\t\t0.01\t\t0.169\t\t0.876\t\t0.34m - 8.2m / 12.6m                                                                 \n",
      "23\t324k\t0.00\t\t0.01\t\t0.169\t\t0.875\t\t0.34m - 8.5m / 12.6m                                                                 \n",
      "24\t338k\t0.00\t\t0.02\t\t0.164\t\t0.871\t\t0.34m - 8.9m / 12.6m                                                                 \n",
      "25\t352k\t0.00\t\t0.02\t\t0.171\t\t0.876\t\t0.34m - 9.2m / 12.7m                                                                 \n",
      "26\t366k\t0.00\t\t0.02\t\t0.169\t\t0.874\t\t0.34m - 9.6m / 12.7m                                                                 \n",
      "27\t380k\t0.00\t\t0.02\t\t0.169\t\t0.875\t\t0.35m - 9.9m / 12.6m                                                                 \n",
      "28\t394k\t0.00\t\t0.02\t\t0.170\t\t0.877\t\t0.35m - 10.3m / 12.7m                                                                \n",
      "29\t408k\t0.00\t\t0.02\t\t0.169\t\t0.875\t\t0.35m - 10.7m / 12.7m                                                                \n",
      "30\t422k\t0.00\t\t0.02\t\t0.169\t\t0.874\t\t0.35m - 11.0m / 12.8m                                                                \n",
      "VAL f1\t0.1707478166406306 - (0.1707478166406306)                                                                       \n",
      "VAL loss\t0.01328333733434439                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01328333733434439\n",
      "        | \\     )|_\tf1: 0.1707478166406306\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\30 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 23.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         23                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00011019402982379858              |\n",
      "|  noam_learning_rate_warmup   |                        6502                       |\n",
      "|  noam_learning_rate_factor   |                 1.4194793378726163                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7541947651302826                |\n",
      "|     pointwise_layer_size     |                        342                        |\n",
      "|      last_layer_dropout      |                 0.5172001370830889                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 17%|███████▎                                  | 26/150 [4:12:19<24:42:10, 717.18s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14b573a15b245b3bc68247dc926aee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.09\t\t0.08\t\t0.245\t\t0.819\t\t0.80m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.07\t\t0.245\t\t0.819\t\t0.81m - 1.6m / 27.9m                                                                   \n",
      "3\t42k\t0.06\t\t0.06\t\t0.226\t\t0.802\t\t0.79m - 2.4m / 28.4m                                                                   \n",
      "4\t56k\t0.05\t\t0.05\t\t0.215\t\t0.786\t\t0.81m - 3.2m / 27.7m                                                                   \n",
      "5\t70k\t0.04\t\t0.06\t\t0.229\t\t0.793\t\t0.79m - 4.0m / 28.2m                                                                   \n",
      "6\t84k\t0.03\t\t0.05\t\t0.278\t\t0.836\t\t0.80m - 4.9m / 27.9m                                                                   \n",
      "7\t98k\t0.03\t\t0.05\t\t0.249\t\t0.809\t\t0.80m - 5.7m / 28.2m                                                                   \n",
      "8\t112k\t0.03\t\t0.05\t\t0.269\t\t0.825\t\t0.78m - 6.5m / 28.0m                                                                  \n",
      "9\t126k\t0.03\t\t0.07\t\t0.261\t\t0.821\t\t0.80m - 7.3m / 27.5m                                                                  \n",
      "10\t141k\t0.03\t\t0.05\t\t0.304\t\t0.854\t\t0.78m - 8.1m / 28.0m                                                                 \n",
      "11\t155k\t0.03\t\t0.05\t\t0.263\t\t0.827\t\t0.77m - 8.9m / 27.6m                                                                 \n",
      "12\t169k\t0.03\t\t0.05\t\t0.304\t\t0.854\t\t0.76m - 9.6m / 27.4m                                                                 \n",
      "13\t183k\t0.03\t\t0.05\t\t0.302\t\t0.854\t\t0.76m - 10.4m / 27.2m                                                                \n",
      "14\t197k\t0.03\t\t0.05\t\t0.259\t\t0.826\t\t0.76m - 11.2m / 27.2m                                                                \n",
      "15\t211k\t0.03\t\t0.04\t\t0.304\t\t0.857\t\t0.82m - 12.0m / 27.2m                                                                \n",
      "16\t225k\t0.03\t\t0.04\t\t0.300\t\t0.854\t\t0.82m - 12.9m / 28.5m                                                                \n",
      "17\t239k\t0.03\t\t0.04\t\t0.291\t\t0.848\t\t0.80m - 13.7m / 28.5m                                                                \n",
      "18\t253k\t0.03\t\t0.05\t\t0.312\t\t0.860\t\t0.76m - 14.5m / 28.1m                                                                \n",
      "19\t267k\t0.03\t\t0.05\t\t0.313\t\t0.863\t\t0.74m - 15.2m / 27.4m                                                                \n",
      "20\t281k\t0.03\t\t0.05\t\t0.325\t\t0.866\t\t0.75m - 16.0m / 27.2m                                                                \n",
      "21\t295k\t0.03\t\t0.04\t\t0.336\t\t0.873\t\t0.75m - 16.8m / 27.3m                                                                \n",
      "22\t309k\t0.03\t\t0.04\t\t0.320\t\t0.864\t\t0.75m - 17.5m / 27.2m                                                                \n",
      "23\t323k\t0.03\t\t0.04\t\t0.320\t\t0.864\t\t0.75m - 18.3m / 27.2m                                                                \n",
      "24\t337k\t0.03\t\t0.04\t\t0.320\t\t0.864\t\t0.74m - 19.0m / 27.3m                                                                \n",
      "25\t351k\t0.03\t\t0.04\t\t0.312\t\t0.861\t\t0.75m - 19.8m / 27.2m                                                                \n",
      "26\t365k\t0.03\t\t0.04\t\t0.331\t\t0.871\t\t0.74m - 20.5m / 27.3m                                                                \n",
      "VAL f1\t0.33550928166965993 - (0.33550928166965993)                                                                     \n",
      "VAL loss\t0.03806997118402267                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03806997118402267\n",
      "        | \\     )|_\tf1: 0.33550928166965993\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\31 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 12.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         12                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.5225407438574639                |\n",
      "|  noam_learning_rate_warmup   |                        3491                       |\n",
      "|  noam_learning_rate_factor   |                 0.446872550036599                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.16874945558098312                |\n",
      "|     pointwise_layer_size     |                        287                        |\n",
      "|      last_layer_dropout      |                0.038439832425660736               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 18%|███████▌                                  | 27/150 [4:33:36<30:14:11, 884.97s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9ca6fbf5044115be0b169f3ab61ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.04\t\t0.528\t\t0.895\t\t1.24m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.559\t\t0.907\t\t1.24m - 2.5m / 43.3m                                                                   \n",
      "3\t42k\t0.02\t\t0.04\t\t0.492\t\t0.893\t\t1.20m - 3.7m / 43.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.635\t\t0.932\t\t1.20m - 4.9m / 42.0m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.618\t\t0.926\t\t1.22m - 6.2m / 42.1m                                                                   \n",
      "6\t84k\t0.01\t\t0.04\t\t0.595\t\t0.919\t\t1.24m - 7.4m / 42.9m                                                                   \n",
      "7\t98k\t0.01\t\t0.03\t\t0.629\t\t0.928\t\t1.28m - 8.7m / 43.4m                                                                   \n",
      "8\t112k\t0.01\t\t0.04\t\t0.637\t\t0.930\t\t1.28m - 10.0m / 44.7m                                                                 \n",
      "9\t126k\t0.01\t\t0.04\t\t0.603\t\t0.920\t\t1.22m - 11.2m / 44.7m                                                                 \n",
      "10\t141k\t0.01\t\t0.04\t\t0.638\t\t0.930\t\t1.24m - 12.5m / 43.0m                                                                \n",
      "11\t155k\t0.01\t\t0.04\t\t0.582\t\t0.913\t\t1.26m - 13.8m / 43.4m                                                                \n",
      "12\t169k\t0.01\t\t0.04\t\t0.661\t\t0.939\t\t1.24m - 15.0m / 44.0m                                                                \n",
      "13\t183k\t0.01\t\t0.04\t\t0.589\t\t0.915\t\t1.21m - 16.2m / 43.6m                                                                \n",
      "14\t197k\t0.01\t\t0.04\t\t0.651\t\t0.935\t\t1.26m - 17.5m / 42.9m                                                                \n",
      "15\t211k\t0.01\t\t0.04\t\t0.606\t\t0.922\t\t1.27m - 18.8m / 43.9m                                                                \n",
      "16\t225k\t0.01\t\t0.04\t\t0.643\t\t0.931\t\t1.19m - 20.0m / 44.2m                                                                \n",
      "17\t239k\t0.01\t\t0.04\t\t0.635\t\t0.930\t\t1.19m - 21.2m / 42.6m                                                                \n",
      "VAL f1\t0.6612234942452752 - (0.6612234942452752)                                                                       \n",
      "VAL loss\t0.02989519264905637                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02989519264905637\n",
      "        | \\     )|_\tf1: 0.6612234942452752\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\32 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 53.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         53                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.34626758786008394                |\n",
      "|  noam_learning_rate_warmup   |                        5246                       |\n",
      "|  noam_learning_rate_factor   |                 1.1032886059458271                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.2377029942951647                |\n",
      "|     pointwise_layer_size     |                         45                        |\n",
      "|      last_layer_dropout      |                0.014438852003063829               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 19%|███████▋                                 | 28/150 [4:55:49<34:32:50, 1019.43s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dd7097ba66479cb7f8eb5947c68935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.116\t\t0.802\t\t0.37m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.01\t\t0.159\t\t0.855\t\t0.38m - 0.8m / 12.9m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.149\t\t0.849\t\t0.39m - 1.2m / 13.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.171\t\t0.870\t\t0.38m - 1.6m / 13.8m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.162\t\t0.861\t\t0.37m - 2.0m / 13.2m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.111\t\t0.817\t\t0.37m - 2.3m / 13.0m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.124\t\t0.831\t\t0.36m - 2.7m / 13.0m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.142\t\t0.859\t\t0.36m - 3.1m / 12.9m                                                                  \n",
      "9\t126k\t0.00\t\t0.01\t\t0.205\t\t0.887\t\t0.36m - 3.4m / 12.7m                                                                  \n",
      "10\t140k\t0.00\t\t0.01\t\t0.146\t\t0.857\t\t0.35m - 3.8m / 12.8m                                                                 \n",
      "11\t154k\t0.00\t\t0.01\t\t0.145\t\t0.852\t\t0.35m - 4.2m / 12.7m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.158\t\t0.867\t\t0.36m - 4.5m / 12.7m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.197\t\t0.884\t\t0.35m - 4.9m / 12.7m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.204\t\t0.887\t\t0.35m - 5.3m / 12.7m                                                                 \n",
      "VAL f1\t0.20531817135393654 - (0.20531817135393654)                                                                     \n",
      "VAL loss\t0.009782923960279416                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009782923960279416\n",
      "        | \\     )|_\tf1: 0.20531817135393654\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\33 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 37.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         37                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0005839273137825719               |\n",
      "|  noam_learning_rate_warmup   |                        4761                       |\n",
      "|  noam_learning_rate_factor   |                 2.390882728793354                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.41600340434583893                |\n",
      "|     pointwise_layer_size     |                        208                        |\n",
      "|      last_layer_dropout      |                0.00682524348317477                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 19%|████████                                  | 29/150 [5:01:36<27:29:04, 817.72s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8002cd8026f14cdfb280458db880156c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.133\t\t0.794\t\t0.70m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.180\t\t0.833\t\t0.71m - 1.4m / 24.7m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.166\t\t0.829\t\t0.71m - 2.2m / 24.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.199\t\t0.850\t\t0.71m - 2.9m / 24.7m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.210\t\t0.860\t\t0.76m - 3.6m / 24.8m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.253\t\t0.886\t\t0.75m - 4.4m / 26.5m                                                                   \n",
      "7\t98k\t0.01\t\t0.01\t\t0.215\t\t0.863\t\t0.74m - 5.2m / 26.1m                                                                   \n",
      "8\t112k\t0.01\t\t0.01\t\t0.256\t\t0.889\t\t0.68m - 5.9m / 26.0m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.261\t\t0.890\t\t0.70m - 6.6m / 24.2m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.248\t\t0.885\t\t0.70m - 7.3m / 24.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.253\t\t0.885\t\t0.70m - 8.0m / 24.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.234\t\t0.875\t\t0.71m - 8.8m / 24.9m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.198\t\t0.849\t\t0.71m - 9.5m / 25.1m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.238\t\t0.876\t\t0.71m - 10.2m / 25.1m                                                                \n",
      "VAL f1\t0.2609166492060019 - (0.2609166492060019)                                                                       \n",
      "VAL loss\t0.011615272932308346                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011615272932308346\n",
      "        | \\     )|_\tf1: 0.2609166492060019\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\34 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 35.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         35                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03338196287148793                |\n",
      "|  noam_learning_rate_warmup   |                        8375                       |\n",
      "|  noam_learning_rate_factor   |                 2.550239732486807                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.2630883221503861                |\n",
      "|     pointwise_layer_size     |                         74                        |\n",
      "|      last_layer_dropout      |                0.07306065349669906                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 20%|████████▍                                 | 30/150 [5:12:25<25:34:04, 767.03s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e979f6e84a954027aa4dbaefe7e4cd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.158\t\t0.809\t\t0.69m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.231\t\t0.868\t\t0.71m - 1.4m / 24.1m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.244\t\t0.874\t\t0.69m - 2.1m / 24.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.243\t\t0.874\t\t0.70m - 2.8m / 24.1m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.281\t\t0.896\t\t0.71m - 3.6m / 24.6m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.239\t\t0.872\t\t0.67m - 4.3m / 24.9m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.244\t\t0.879\t\t0.69m - 5.0m / 23.8m                                                                   \n",
      "8\t113k\t0.00\t\t0.02\t\t0.263\t\t0.886\t\t0.69m - 5.7m / 24.2m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.274\t\t0.893\t\t0.68m - 6.4m / 24.4m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.293\t\t0.902\t\t0.68m - 7.0m / 24.0m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.261\t\t0.884\t\t0.73m - 7.8m / 24.1m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.241\t\t0.875\t\t0.72m - 8.5m / 25.3m                                                                 \n",
      "13\t183k\t0.00\t\t0.02\t\t0.261\t\t0.884\t\t0.74m - 9.3m / 25.1m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.279\t\t0.893\t\t0.69m - 10.0m / 25.5m                                                                \n",
      "15\t211k\t0.00\t\t0.01\t\t0.248\t\t0.876\t\t0.66m - 10.7m / 24.4m                                                                \n",
      "VAL f1\t0.2925874368718508 - (0.2925874368718508)                                                                       \n",
      "VAL loss\t0.012302768025289757                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012302768025289757\n",
      "        | \\     )|_\tf1: 0.2925874368718508\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\35 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 21.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         21                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.004892917175649418               |\n",
      "|  noam_learning_rate_warmup   |                        7817                       |\n",
      "|  noam_learning_rate_factor   |                 2.987872190620645                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.39305893192194835                |\n",
      "|     pointwise_layer_size     |                        207                        |\n",
      "|      last_layer_dropout      |                 0.4472670564123141                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 21%|████████▋                                 | 31/150 [5:23:37<24:25:02, 738.68s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff8b8c9be414dedbcd330713c209f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.05\t\t0.157\t\t0.731\t\t1.39m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.271\t\t0.827\t\t1.36m - 2.8m / 48.6m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.335\t\t0.874\t\t1.37m - 4.2m / 47.7m                                                                   \n",
      "4\t56k\t0.02\t\t0.04\t\t0.272\t\t0.851\t\t1.37m - 5.5m / 47.9m                                                                   \n",
      "5\t70k\t0.02\t\t0.05\t\t0.263\t\t0.845\t\t1.36m - 6.9m / 48.0m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.363\t\t0.885\t\t1.37m - 8.3m / 47.8m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.339\t\t0.867\t\t1.34m - 9.7m / 48.1m                                                                   \n",
      "8\t112k\t0.04\t\t0.05\t\t0.191\t\t0.754\t\t1.33m - 11.0m / 47.1m                                                                 \n",
      "9\t126k\t0.06\t\t0.07\t\t0.254\t\t0.814\t\t1.34m - 12.4m / 47.0m                                                                 \n",
      "10\t140k\t0.07\t\t0.07\t\t0.254\t\t0.814\t\t1.46m - 13.8m / 47.3m                                                                \n",
      "11\t155k\t0.07\t\t0.07\t\t0.254\t\t0.814\t\t1.44m - 15.3m / 50.4m                                                                \n",
      "VAL f1\t0.3632747270363904 - (0.3632747270363904)                                                                       \n",
      "VAL loss\t0.031688040595347154                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.031688040595347154\n",
      "        | \\     )|_\tf1: 0.3632747270363904\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\36 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 52.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         52                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0025906745419314358               |\n",
      "|  noam_learning_rate_warmup   |                        6332                       |\n",
      "|  noam_learning_rate_factor   |                 1.9256890058391192                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.4756325234331186                |\n",
      "|     pointwise_layer_size     |                        123                        |\n",
      "|      last_layer_dropout      |                 0.7054617535326277                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 21%|████████▉                                 | 32/150 [5:39:57<26:35:02, 811.04s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd766ba878b494e93199f79c2e2a26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.113\t\t0.793\t\t0.50m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.126\t\t0.820\t\t0.51m - 1.0m / 17.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.159\t\t0.851\t\t0.49m - 1.6m / 17.8m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.156\t\t0.846\t\t0.51m - 2.1m / 17.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.187\t\t0.873\t\t0.49m - 2.6m / 17.9m                                                                   \n",
      "6\t85k\t0.01\t\t0.01\t\t0.177\t\t0.863\t\t0.50m - 3.1m / 17.4m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.153\t\t0.856\t\t0.51m - 3.6m / 17.7m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.173\t\t0.861\t\t0.51m - 4.1m / 17.9m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.187\t\t0.877\t\t0.49m - 4.6m / 17.9m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.216\t\t0.892\t\t0.50m - 5.2m / 17.3m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.195\t\t0.879\t\t0.51m - 5.7m / 17.7m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.203\t\t0.886\t\t0.51m - 6.2m / 18.0m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.197\t\t0.881\t\t0.50m - 6.7m / 17.8m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.191\t\t0.881\t\t0.51m - 7.2m / 17.7m                                                                 \n",
      "15\t211k\t0.00\t\t0.02\t\t0.184\t\t0.873\t\t0.51m - 7.8m / 17.9m                                                                 \n",
      "VAL f1\t0.2164928968340485 - (0.2164928968340485)                                                                       \n",
      "VAL loss\t0.0104542383810412                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0104542383810412\n",
      "        | \\     )|_\tf1: 0.2164928968340485\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190428\\37 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.15077095001436683                |\n",
      "|  noam_learning_rate_warmup   |                        3056                       |\n",
      "|  noam_learning_rate_factor   |                 1.6154241255420378                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5374821665723016                |\n",
      "|     pointwise_layer_size     |                        292                        |\n",
      "|      last_layer_dropout      |                 0.6163281482826289                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 22%|█████████▏                                | 33/150 [5:48:13<23:16:55, 716.37s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3882e6362d4032be93c3276a95cbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.142\t\t0.800\t\t0.46m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.155\t\t0.819\t\t0.44m - 0.9m / 16.0m                                                                   \n",
      "3\t42k\t0.01\t\t0.03\t\t0.177\t\t0.840\t\t0.45m - 1.4m / 15.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.248\t\t0.891\t\t0.45m - 1.9m / 15.8m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.250\t\t0.894\t\t0.44m - 2.3m / 15.8m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.229\t\t0.882\t\t0.48m - 2.8m / 15.5m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.228\t\t0.883\t\t0.47m - 3.3m / 16.6m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.223\t\t0.878\t\t0.48m - 3.8m / 16.5m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.245\t\t0.889\t\t0.47m - 4.3m / 16.8m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.228\t\t0.882\t\t0.49m - 4.8m / 16.4m                                                                 \n",
      "VAL f1\t0.2497810899539537 - (0.2497810899539537)                                                                       \n",
      "VAL loss\t0.015104799046930078                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.015104799046930078\n",
      "        | \\     )|_\tf1: 0.2497810899539537\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\0  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.004374523556466374               |\n",
      "|  noam_learning_rate_warmup   |                        4330                       |\n",
      "|  noam_learning_rate_factor   |                 3.2471970650109476                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.32109599932150634                |\n",
      "|     pointwise_layer_size     |                         46                        |\n",
      "|      last_layer_dropout      |                 0.3307030177821886                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 23%|█████████▌                                | 34/150 [5:53:34<19:15:52, 597.87s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabe95e5526a40ae84a6c138c7d6781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.112\t\t0.791\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.208\t\t0.883\t\t0.40m - 0.8m / 14.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.209\t\t0.885\t\t0.42m - 1.3m / 14.2m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.215\t\t0.887\t\t0.42m - 1.7m / 14.6m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.192\t\t0.873\t\t0.41m - 2.1m / 14.7m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.208\t\t0.885\t\t0.41m - 2.6m / 14.4m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.200\t\t0.886\t\t0.40m - 3.0m / 14.4m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.212\t\t0.885\t\t0.41m - 3.4m / 14.2m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.222\t\t0.893\t\t0.41m - 3.8m / 14.4m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.223\t\t0.892\t\t0.41m - 4.2m / 14.6m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.191\t\t0.876\t\t0.40m - 4.7m / 14.6m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.191\t\t0.872\t\t0.42m - 5.1m / 14.4m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.217\t\t0.888\t\t0.42m - 5.5m / 14.7m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.202\t\t0.878\t\t0.43m - 6.0m / 14.8m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.188\t\t0.870\t\t0.42m - 6.4m / 15.1m                                                                 \n",
      "VAL f1\t0.22294941678852842 - (0.22294941678852842)                                                                     \n",
      "VAL loss\t0.009292045450152928                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009292045450152928\n",
      "        | \\     )|_\tf1: 0.22294941678852842\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\1  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.14499787285036342                |\n",
      "|  noam_learning_rate_warmup   |                        5849                       |\n",
      "|  noam_learning_rate_factor   |                 3.8317996863784027                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.19808562243070532                |\n",
      "|     pointwise_layer_size     |                        200                        |\n",
      "|      last_layer_dropout      |                0.15234202067642633                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 23%|█████████▊                                | 35/150 [6:00:28<17:20:17, 542.76s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d7b1c64f984cb6bcc3426f4992465a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.03\t\t0.432\t\t0.884\t\t1.00m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.487\t\t0.910\t\t1.01m - 2.0m / 35.0m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.382\t\t0.874\t\t0.98m - 3.0m / 35.5m                                                                   \n",
      "4\t56k\t0.03\t\t0.05\t\t0.334\t\t0.840\t\t0.98m - 4.0m / 34.4m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.370\t\t0.851\t\t1.05m - 5.1m / 34.3m                                                                   \n",
      "6\t84k\t0.04\t\t0.05\t\t0.414\t\t0.873\t\t1.05m - 6.1m / 36.5m                                                                   \n",
      "7\t98k\t0.05\t\t0.05\t\t0.297\t\t0.814\t\t0.98m - 7.1m / 36.5m                                                                   \n",
      "VAL f1\t0.48684004426638294 - (0.48684004426638294)                                                                     \n",
      "VAL loss\t0.029097323513626323                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.029097323513626323\n",
      "        | \\     )|_\tf1: 0.48684004426638294\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\2  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 26.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         26                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.027635936309929016               |\n",
      "|  noam_learning_rate_warmup   |                        4055                       |\n",
      "|  noam_learning_rate_factor   |                 2.4721267424314175                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.4974212673430131                |\n",
      "|     pointwise_layer_size     |                        228                        |\n",
      "|      last_layer_dropout      |                 0.4073963208566383                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 24%|██████████                                | 36/150 [6:08:22<16:31:34, 521.88s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5182106cd7b54efa81a862458a038ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.03\t\t0.248\t\t0.844\t\t0.48m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.202\t\t0.817\t\t0.48m - 1.0m / 16.7m                                                                   \n",
      "3\t42k\t0.01\t\t0.03\t\t0.227\t\t0.836\t\t0.46m - 1.4m / 16.8m                                                                   \n",
      "4\t56k\t0.01\t\t0.03\t\t0.207\t\t0.825\t\t0.46m - 1.9m / 16.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.03\t\t0.225\t\t0.843\t\t0.46m - 2.4m / 16.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.224\t\t0.846\t\t0.46m - 2.9m / 16.3m                                                                   \n",
      "VAL f1\t0.2482827496528645 - (0.2482827496528645)                                                                       \n",
      "VAL loss\t0.025557055211984193                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.025557055211984193\n",
      "        | \\     )|_\tf1: 0.2482827496528645\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\3  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 15.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         15                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.010914715948387776               |\n",
      "|  noam_learning_rate_warmup   |                        6889                       |\n",
      "|  noam_learning_rate_factor   |                 2.8894945758683486                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.580062385974159                 |\n",
      "|     pointwise_layer_size     |                         49                        |\n",
      "|      last_layer_dropout      |                0.32881843383950216                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 25%|██████████▎                               | 37/150 [6:11:50<13:26:02, 427.98s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a20738609c422a97cf06d64aeffaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.08\t\t0.320\t\t0.823\t\t1.33m - 1.3m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.05\t\t0.385\t\t0.846\t\t1.36m - 2.7m / 46.7m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.364\t\t0.836\t\t1.34m - 4.1m / 47.8m                                                                   \n",
      "4\t56k\t0.04\t\t0.06\t\t0.351\t\t0.837\t\t1.33m - 5.4m / 47.0m                                                                   \n",
      "5\t70k\t0.05\t\t0.06\t\t0.358\t\t0.841\t\t1.29m - 6.7m / 46.7m                                                                   \n",
      "6\t84k\t0.05\t\t0.09\t\t0.399\t\t0.860\t\t1.28m - 8.0m / 45.5m                                                                   \n",
      "7\t98k\t0.06\t\t0.13\t\t0.328\t\t0.826\t\t1.41m - 9.4m / 45.3m                                                                   \n",
      "8\t112k\t0.06\t\t0.10\t\t0.324\t\t0.831\t\t1.39m - 10.9m / 48.8m                                                                 \n",
      "9\t126k\t0.07\t\t0.09\t\t0.140\t\t0.803\t\t1.35m - 12.2m / 48.5m                                                                 \n",
      "10\t141k\t0.07\t\t0.10\t\t0.162\t\t0.802\t\t1.35m - 13.6m / 47.5m                                                                \n",
      "11\t155k\t0.07\t\t0.10\t\t0.192\t\t0.792\t\t1.35m - 14.9m / 47.4m                                                                \n",
      "VAL f1\t0.39910075930746747 - (0.39910075930746747)                                                                     \n",
      "VAL loss\t0.05027979249320638                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.05027979249320638\n",
      "        | \\     )|_\tf1: 0.39910075930746747\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\4  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 36.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         36                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0022528140950917263               |\n",
      "|  noam_learning_rate_warmup   |                        3935                       |\n",
      "|  noam_learning_rate_factor   |                 0.6436357212118603                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6991153782673778                |\n",
      "|     pointwise_layer_size     |                        180                        |\n",
      "|      last_layer_dropout      |                 0.615540718119608                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 25%|██████████▋                               | 38/150 [6:27:42<18:12:16, 585.14s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6347e4d4fdfd472ca39387b35fec5cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.05\t\t0.167\t\t0.812\t\t0.68m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.05\t\t0.167\t\t0.812\t\t0.70m - 1.4m / 24.0m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.150\t\t0.799\t\t0.71m - 2.1m / 24.4m                                                                   \n",
      "4\t56k\t0.04\t\t0.04\t\t0.159\t\t0.809\t\t0.73m - 2.9m / 24.9m                                                                   \n",
      "5\t70k\t0.03\t\t0.05\t\t0.202\t\t0.841\t\t0.71m - 3.6m / 25.6m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.187\t\t0.827\t\t0.70m - 4.3m / 25.0m                                                                   \n",
      "7\t99k\t0.02\t\t0.03\t\t0.151\t\t0.794\t\t0.69m - 5.0m / 24.5m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.182\t\t0.824\t\t0.70m - 5.7m / 24.4m                                                                  \n",
      "9\t127k\t0.02\t\t0.04\t\t0.191\t\t0.832\t\t0.69m - 6.4m / 24.6m                                                                  \n",
      "10\t141k\t0.02\t\t0.04\t\t0.194\t\t0.842\t\t0.69m - 7.1m / 24.3m                                                                 \n",
      "VAL f1\t0.2018105264030377 - (0.2018105264030377)                                                                       \n",
      "VAL loss\t0.03127216880683934                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03127216880683934\n",
      "        | \\     )|_\tf1: 0.2018105264030377\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\5  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 57.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         57                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00972309942454448                |\n",
      "|  noam_learning_rate_warmup   |                        6268                       |\n",
      "|  noam_learning_rate_factor   |                 0.7928002424940338                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.4237567221818336                |\n",
      "|     pointwise_layer_size     |                        167                        |\n",
      "|      last_layer_dropout      |                0.20335936375382246                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 26%|██████████▉                               | 39/150 [6:35:24<16:53:46, 547.99s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef020cb5903437da35affae3e7e531e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.084\t\t0.768\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.092\t\t0.781\t\t0.41m - 0.8m / 14.3m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.077\t\t0.752\t\t0.40m - 1.3m / 14.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.01\t\t0.076\t\t0.756\t\t0.39m - 1.7m / 14.0m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.081\t\t0.767\t\t0.38m - 2.1m / 13.6m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.082\t\t0.772\t\t0.38m - 2.4m / 13.4m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.077\t\t0.757\t\t0.38m - 2.8m / 13.4m                                                                   \n",
      "VAL f1\t0.09197306879988813 - (0.09197306879988813)                                                                     \n",
      "VAL loss\t0.013260160635365767                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013260160635365767\n",
      "        | \\     )|_\tf1: 0.09197306879988813\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\6  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 58.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         58                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.05919353036027891                |\n",
      "|  noam_learning_rate_warmup   |                        8120                       |\n",
      "|  noam_learning_rate_factor   |                 1.4880192411132727                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6718728576663182                |\n",
      "|     pointwise_layer_size     |                        235                        |\n",
      "|      last_layer_dropout      |                 0.4933906931756366                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 27%|███████████▏                              | 40/150 [6:38:41<13:31:35, 442.69s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df26d08259c54008b416cc3ca36bec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.090\t\t0.780\t\t0.35m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.35m - 0.7m / 12.1m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.35m - 1.1m / 12.4m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.097\t\t0.791\t\t0.35m - 1.4m / 12.4m                                                                   \n",
      "5\t70k\t0.02\t\t0.02\t\t0.095\t\t0.794\t\t0.35m - 1.8m / 12.3m                                                                   \n",
      "6\t85k\t0.02\t\t0.02\t\t0.097\t\t0.802\t\t0.36m - 2.2m / 12.3m                                                                   \n",
      "7\t99k\t0.01\t\t0.03\t\t0.098\t\t0.796\t\t0.36m - 2.6m / 12.6m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.107\t\t0.810\t\t0.36m - 3.0m / 12.6m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.117\t\t0.825\t\t0.37m - 3.3m / 12.7m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.127\t\t0.839\t\t0.35m - 3.7m / 12.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.132\t\t0.848\t\t0.35m - 4.1m / 12.5m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.134\t\t0.850\t\t0.36m - 4.5m / 12.5m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.137\t\t0.854\t\t0.35m - 4.8m / 12.8m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.149\t\t0.868\t\t0.36m - 5.2m / 12.6m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.148\t\t0.868\t\t0.35m - 5.6m / 12.8m                                                                 \n",
      "16\t226k\t0.00\t\t0.01\t\t0.151\t\t0.872\t\t0.35m - 5.9m / 12.6m                                                                 \n",
      "17\t240k\t0.00\t\t0.01\t\t0.147\t\t0.868\t\t0.36m - 6.4m / 12.7m                                                                 \n",
      "18\t254k\t0.00\t\t0.01\t\t0.148\t\t0.870\t\t0.37m - 6.8m / 12.9m                                                                 \n",
      "19\t268k\t0.00\t\t0.01\t\t0.143\t\t0.863\t\t0.35m - 7.1m / 13.0m                                                                 \n",
      "20\t282k\t0.00\t\t0.01\t\t0.143\t\t0.864\t\t0.35m - 7.5m / 12.8m                                                                 \n",
      "21\t296k\t0.00\t\t0.02\t\t0.142\t\t0.860\t\t0.35m - 7.9m / 12.8m                                                                 \n",
      "VAL f1\t0.15118310231190527 - (0.15118310231190527)                                                                     \n",
      "VAL loss\t0.01142113430447216                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01142113430447216\n",
      "        | \\     )|_\tf1: 0.15118310231190527\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\7  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 38.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         38                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00039836659610055627              |\n",
      "|  noam_learning_rate_warmup   |                        3910                       |\n",
      "|  noam_learning_rate_factor   |                 2.653999447796505                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7853141909887648                |\n",
      "|     pointwise_layer_size     |                        190                        |\n",
      "|      last_layer_dropout      |                 0.7877714175817282                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 27%|███████████▍                              | 41/150 [6:46:59<13:54:40, 459.46s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8aba5a68bd49b6b2cdb8351fbf1bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.155\t\t0.804\t\t0.52m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.05\t\t0.155\t\t0.804\t\t0.52m - 1.1m / 18.4m                                                                   \n",
      "3\t42k\t0.04\t\t0.03\t\t0.143\t\t0.786\t\t0.51m - 1.6m / 18.2m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.144\t\t0.783\t\t0.52m - 2.2m / 18.0m                                                                   \n",
      "5\t70k\t0.02\t\t0.04\t\t0.148\t\t0.788\t\t0.53m - 2.7m / 18.3m                                                                   \n",
      "6\t84k\t0.02\t\t0.04\t\t0.161\t\t0.803\t\t0.55m - 3.3m / 18.7m                                                                   \n",
      "7\t98k\t0.02\t\t0.04\t\t0.194\t\t0.829\t\t0.55m - 3.8m / 19.2m                                                                   \n",
      "8\t112k\t0.02\t\t0.04\t\t0.172\t\t0.814\t\t0.54m - 4.4m / 19.2m                                                                  \n",
      "9\t127k\t0.02\t\t0.04\t\t0.188\t\t0.833\t\t0.53m - 5.0m / 19.0m                                                                  \n",
      "10\t141k\t0.02\t\t0.04\t\t0.150\t\t0.789\t\t0.51m - 5.5m / 18.7m                                                                 \n",
      "11\t155k\t0.02\t\t0.05\t\t0.191\t\t0.829\t\t0.52m - 6.0m / 18.3m                                                                 \n",
      "12\t169k\t0.02\t\t0.05\t\t0.141\t\t0.768\t\t0.52m - 6.6m / 18.6m                                                                 \n",
      "VAL f1\t0.1938176171148231 - (0.1938176171148231)                                                                       \n",
      "VAL loss\t0.0345311862310552                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0345311862310552\n",
      "        | \\     )|_\tf1: 0.1938176171148231\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\8  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 41.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         41                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.004288572017146162               |\n",
      "|  noam_learning_rate_warmup   |                        4735                       |\n",
      "|  noam_learning_rate_factor   |                 3.346062371823612                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.43679649798140824                |\n",
      "|     pointwise_layer_size     |                        167                        |\n",
      "|      last_layer_dropout      |                 0.6943785246155343                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 28%|███████████▊                              | 42/150 [6:54:03<13:27:52, 448.82s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c768f00ee18e47d5a817bdd3bb9b1678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.158\t\t0.823\t\t0.49m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.115\t\t0.772\t\t0.50m - 1.0m / 17.1m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.141\t\t0.820\t\t0.50m - 1.5m / 17.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.125\t\t0.794\t\t0.50m - 2.0m / 17.6m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.147\t\t0.829\t\t0.49m - 2.5m / 17.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.153\t\t0.831\t\t0.49m - 3.0m / 17.3m                                                                   \n",
      "VAL f1\t0.15846677537753165 - (0.15846677537753165)                                                                     \n",
      "VAL loss\t0.01951020572152807                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01951020572152807\n",
      "        | \\     )|_\tf1: 0.15846677537753165\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\9  \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03704130831956849                |\n",
      "|  noam_learning_rate_warmup   |                        4619                       |\n",
      "|  noam_learning_rate_factor   |                 2.697045744012705                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.3906278857875787                |\n",
      "|     pointwise_layer_size     |                        348                        |\n",
      "|      last_layer_dropout      |                0.42545907863424626                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 29%|████████████                              | 43/150 [6:57:41<11:17:02, 379.65s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67067221d5c8416db00768ef4501b80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.101\t\t0.753\t\t0.47m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.213\t\t0.872\t\t0.47m - 0.9m / 16.3m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.185\t\t0.860\t\t0.46m - 1.4m / 16.3m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.241\t\t0.887\t\t0.47m - 1.9m / 16.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.184\t\t0.860\t\t0.46m - 2.4m / 16.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.180\t\t0.856\t\t0.47m - 2.9m / 16.3m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.174\t\t0.849\t\t0.48m - 3.4m / 16.4m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.206\t\t0.874\t\t0.49m - 3.9m / 16.8m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.139\t\t0.815\t\t0.47m - 4.4m / 17.2m                                                                  \n",
      "VAL f1\t0.24108900398372227 - (0.24108900398372227)                                                                     \n",
      "VAL loss\t0.013552653208270102                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013552653208270102\n",
      "        | \\     )|_\tf1: 0.24108900398372227\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\10 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 32.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         32                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.008401047540315707               |\n",
      "|  noam_learning_rate_warmup   |                        5595                       |\n",
      "|  noam_learning_rate_factor   |                 0.3698387772461935                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.6000983099243048                |\n",
      "|     pointwise_layer_size     |                        248                        |\n",
      "|      last_layer_dropout      |                 0.7118473272623521                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 29%|████████████▎                             | 44/150 [7:02:38<10:26:38, 354.70s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dca684ba02b4036a0a738f84c9bd7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.06\t\t0.182\t\t0.809\t\t0.98m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.05\t\t0.182\t\t0.809\t\t1.06m - 2.1m / 34.4m                                                                   \n",
      "3\t42k\t0.05\t\t0.05\t\t0.182\t\t0.809\t\t1.06m - 3.1m / 37.2m                                                                   \n",
      "4\t56k\t0.04\t\t0.05\t\t0.109\t\t0.747\t\t1.05m - 4.2m / 37.1m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.095\t\t0.734\t\t1.01m - 5.2m / 36.8m                                                                   \n",
      "6\t84k\t0.03\t\t0.03\t\t0.133\t\t0.764\t\t1.01m - 6.3m / 35.4m                                                                   \n",
      "VAL f1\t0.1824699017138206 - (0.1824699017138206)                                                                       \n",
      "VAL loss\t0.03477815148311064                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03477815148311064\n",
      "        | \\     )|_\tf1: 0.1824699017138206\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\11 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 45.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         45                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.017705739437600027               |\n",
      "|  noam_learning_rate_warmup   |                        4355                       |\n",
      "|  noam_learning_rate_factor   |                 2.836873724341554                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.12804362472831823                |\n",
      "|     pointwise_layer_size     |                        134                        |\n",
      "|      last_layer_dropout      |                0.19070943219335357                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 30%|████████████▌                             | 45/150 [7:09:42<10:57:01, 375.44s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a7671839c4f7aa1e6ea100a09e03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.125\t\t0.791\t\t0.47m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.189\t\t0.862\t\t0.46m - 0.9m / 16.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.223\t\t0.884\t\t0.44m - 1.4m / 16.0m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.234\t\t0.893\t\t0.44m - 1.9m / 15.5m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.254\t\t0.904\t\t0.43m - 2.3m / 15.6m                                                                   \n",
      "6\t85k\t0.00\t\t0.01\t\t0.244\t\t0.896\t\t0.43m - 2.8m / 15.3m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.221\t\t0.884\t\t0.45m - 3.2m / 15.4m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.250\t\t0.899\t\t0.44m - 3.7m / 15.7m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.241\t\t0.893\t\t0.44m - 4.1m / 15.7m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.234\t\t0.888\t\t0.44m - 4.6m / 15.6m                                                                 \n",
      "VAL f1\t0.2542753453237955 - (0.2542753453237955)                                                                       \n",
      "VAL loss\t0.00857496118354448                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.00857496118354448\n",
      "        | \\     )|_\tf1: 0.2542753453237955\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\12 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 41.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         41                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005737205680584533               |\n",
      "|  noam_learning_rate_warmup   |                        5026                       |\n",
      "|  noam_learning_rate_factor   |                 1.7931879674368607                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.22259968280219705                |\n",
      "|     pointwise_layer_size     |                         73                        |\n",
      "|      last_layer_dropout      |                 0.6337062027315001                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 31%|████████████▉                             | 46/150 [7:14:51<10:16:07, 355.45s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3110819f4b9240d085ca2ebc3f38b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.177\t\t0.839\t\t0.63m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.176\t\t0.846\t\t0.64m - 1.3m / 22.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.246\t\t0.889\t\t0.64m - 1.9m / 22.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.261\t\t0.894\t\t0.65m - 2.6m / 22.6m                                                                   \n",
      "5\t70k\t0.00\t\t0.02\t\t0.153\t\t0.830\t\t0.65m - 3.3m / 22.8m                                                                   \n",
      "6\t84k\t0.00\t\t0.02\t\t0.230\t\t0.876\t\t0.64m - 3.9m / 22.8m                                                                   \n",
      "7\t98k\t0.00\t\t0.02\t\t0.208\t\t0.867\t\t0.66m - 4.6m / 22.5m                                                                   \n",
      "8\t113k\t0.00\t\t0.02\t\t0.238\t\t0.882\t\t0.65m - 5.3m / 23.0m                                                                  \n",
      "9\t127k\t0.00\t\t0.02\t\t0.188\t\t0.864\t\t0.64m - 5.9m / 22.7m                                                                  \n",
      "VAL f1\t0.2605911055660087 - (0.2605911055660087)                                                                       \n",
      "VAL loss\t0.013258112585399209                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013258112585399209\n",
      "        | \\     )|_\tf1: 0.2605911055660087\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\13 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 39.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         39                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.01291937380222228                |\n",
      "|  noam_learning_rate_warmup   |                        4536                       |\n",
      "|  noam_learning_rate_factor   |                 2.2318230334059312                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.6011865437067229                |\n",
      "|     pointwise_layer_size     |                        203                        |\n",
      "|      last_layer_dropout      |                 0.713436358035371                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 31%|█████████████▏                            | 47/150 [7:21:19<10:27:08, 365.33s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaa2e00137443c78ac3bf3f8835ac58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.161\t\t0.814\t\t0.34m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.237\t\t0.875\t\t0.33m - 0.7m / 11.8m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.258\t\t0.885\t\t0.34m - 1.0m / 11.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.258\t\t0.887\t\t0.35m - 1.4m / 12.1m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.252\t\t0.890\t\t0.34m - 1.8m / 12.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.281\t\t0.899\t\t0.34m - 2.1m / 12.0m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.293\t\t0.904\t\t0.36m - 2.5m / 12.0m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.217\t\t0.885\t\t0.33m - 2.9m / 12.6m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.227\t\t0.884\t\t0.35m - 3.3m / 12.0m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.204\t\t0.873\t\t0.35m - 3.7m / 12.5m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.188\t\t0.854\t\t0.35m - 4.0m / 12.3m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.201\t\t0.867\t\t0.35m - 4.4m / 12.4m                                                                 \n",
      "VAL f1\t0.2928941386561066 - (0.2928941386561066)                                                                       \n",
      "VAL loss\t0.014527942703284039                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014527942703284039\n",
      "        | \\     )|_\tf1: 0.2928941386561066\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\14 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 54.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         54                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0015370588653448917               |\n",
      "|  noam_learning_rate_warmup   |                        1433                       |\n",
      "|  noam_learning_rate_factor   |                 3.4442232005568476                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6988268685256718                |\n",
      "|     pointwise_layer_size     |                         33                        |\n",
      "|      last_layer_dropout      |                 0.3862533617316296                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 32%|█████████████▊                             | 48/150 [7:26:16<9:46:17, 344.88s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a5fed3e4b14a8fa360280d62c5b085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.04\t\t0.123\t\t0.813\t\t0.37m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.143\t\t0.837\t\t0.38m - 0.8m / 13.1m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.150\t\t0.848\t\t0.38m - 1.2m / 13.2m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.149\t\t0.847\t\t0.37m - 1.5m / 13.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.099\t\t0.803\t\t0.38m - 1.9m / 12.9m                                                                   \n",
      "6\t85k\t0.02\t\t0.03\t\t0.076\t\t0.758\t\t0.37m - 2.3m / 13.3m                                                                   \n",
      "7\t99k\t0.02\t\t0.03\t\t0.030\t\t0.709\t\t0.38m - 2.7m / 13.1m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.099\t\t0.784\t\t0.38m - 3.1m / 13.2m                                                                  \n",
      "VAL f1\t0.14990470356705232 - (0.14990470356705232)                                                                     \n",
      "VAL loss\t0.015645603813868838                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.015645603813868838\n",
      "        | \\     )|_\tf1: 0.14990470356705232\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\15 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 48.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         48                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0001693775977794027               |\n",
      "|  noam_learning_rate_warmup   |                        3591                       |\n",
      "|  noam_learning_rate_factor   |                 0.4617659514711803                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2853991409709143                |\n",
      "|     pointwise_layer_size     |                        264                        |\n",
      "|      last_layer_dropout      |                0.31424682982993724                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 33%|██████████████                             | 49/150 [7:29:48<8:33:36, 305.11s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e838f7e9504497b6bc908d6a13a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.117\t\t0.789\t\t0.59m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.125\t\t0.803\t\t0.59m - 1.2m / 20.7m                                                                   \n",
      "3\t42k\t0.02\t\t0.01\t\t0.167\t\t0.850\t\t0.58m - 1.8m / 20.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.171\t\t0.853\t\t0.61m - 2.4m / 20.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.136\t\t0.825\t\t0.59m - 3.1m / 21.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.143\t\t0.843\t\t0.57m - 3.6m / 20.9m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.137\t\t0.831\t\t0.56m - 4.2m / 20.1m                                                                   \n",
      "8\t113k\t0.00\t\t0.02\t\t0.113\t\t0.796\t\t0.60m - 4.8m / 20.0m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.147\t\t0.841\t\t0.61m - 5.5m / 21.0m                                                                  \n",
      "VAL f1\t0.17144474565494636 - (0.17144474565494636)                                                                     \n",
      "VAL loss\t0.011189692064791043                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011189692064791043\n",
      "        | \\     )|_\tf1: 0.17144474565494636\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\16 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 29.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         29                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.18330137938784588                |\n",
      "|  noam_learning_rate_warmup   |                        5188                       |\n",
      "|  noam_learning_rate_factor   |                 0.6907806576781086                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.24527492297634215                |\n",
      "|     pointwise_layer_size     |                        260                        |\n",
      "|      last_layer_dropout      |                 0.7831583478052908                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 33%|██████████████▎                            | 50/150 [7:35:56<8:59:45, 323.85s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37942f273a2d4de782ae834fd5aa5cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.04\t\t0.201\t\t0.817\t\t0.90m - 0.9m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.197\t\t0.815\t\t0.89m - 1.8m / 31.6m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.291\t\t0.881\t\t0.90m - 2.7m / 31.3m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.267\t\t0.868\t\t0.89m - 3.6m / 31.5m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.228\t\t0.848\t\t0.86m - 4.5m / 31.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.314\t\t0.891\t\t0.87m - 5.4m / 30.4m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.267\t\t0.871\t\t0.89m - 6.3m / 30.6m                                                                   \n",
      "8\t113k\t0.00\t\t0.02\t\t0.310\t\t0.891\t\t0.89m - 7.2m / 31.4m                                                                  \n",
      "9\t127k\t0.00\t\t0.02\t\t0.283\t\t0.879\t\t0.90m - 8.1m / 31.2m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.274\t\t0.877\t\t0.87m - 9.0m / 31.4m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.282\t\t0.889\t\t0.87m - 9.9m / 30.7m                                                                 \n",
      "VAL f1\t0.3135802098123253 - (0.3135802098123253)                                                                       \n",
      "VAL loss\t0.016321665659969745                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.016321665659969745\n",
      "        | \\     )|_\tf1: 0.3135802098123253\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\17 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 18.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         18                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005091862758564181               |\n",
      "|  noam_learning_rate_warmup   |                        3999                       |\n",
      "|  noam_learning_rate_factor   |                0.021334766262501272               |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.19687932649500217                |\n",
      "|     pointwise_layer_size     |                        159                        |\n",
      "|      last_layer_dropout      |                0.025426782305297026               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 34%|██████████████▎                           | 51/150 [7:46:27<11:26:16, 415.93s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d612e7e27344038f1840eb1904e542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.08\t\t0.295\t\t0.818\t\t0.87m - 0.9m / 0.0m                                                                    \n",
      "2\t28k\t0.08\t\t0.07\t\t0.297\t\t0.820\t\t0.88m - 1.8m / 30.5m                                                                   \n",
      "3\t42k\t0.07\t\t0.06\t\t0.328\t\t0.837\t\t0.85m - 2.6m / 30.7m                                                                   \n",
      "4\t56k\t0.06\t\t0.05\t\t0.352\t\t0.855\t\t0.85m - 3.5m / 30.0m                                                                   \n",
      "5\t70k\t0.05\t\t0.04\t\t0.385\t\t0.871\t\t0.89m - 4.4m / 29.8m                                                                   \n",
      "6\t84k\t0.04\t\t0.04\t\t0.407\t\t0.882\t\t0.89m - 5.3m / 31.1m                                                                   \n",
      "7\t98k\t0.03\t\t0.03\t\t0.431\t\t0.891\t\t0.89m - 6.2m / 31.1m                                                                   \n",
      "8\t112k\t0.03\t\t0.03\t\t0.419\t\t0.887\t\t0.87m - 7.1m / 31.2m                                                                  \n",
      "9\t127k\t0.02\t\t0.03\t\t0.400\t\t0.877\t\t0.86m - 8.0m / 30.5m                                                                  \n",
      "10\t141k\t0.02\t\t0.03\t\t0.440\t\t0.895\t\t0.86m - 8.9m / 30.4m                                                                 \n",
      "11\t155k\t0.02\t\t0.03\t\t0.441\t\t0.895\t\t0.87m - 9.8m / 30.4m                                                                 \n",
      "12\t169k\t0.02\t\t0.03\t\t0.466\t\t0.904\t\t0.85m - 10.6m / 30.6m                                                                \n",
      "13\t183k\t0.02\t\t0.03\t\t0.453\t\t0.899\t\t0.86m - 11.5m / 30.1m                                                                \n",
      "14\t197k\t0.02\t\t0.03\t\t0.485\t\t0.910\t\t0.87m - 12.4m / 30.4m                                                                \n",
      "15\t211k\t0.02\t\t0.03\t\t0.471\t\t0.904\t\t0.88m - 13.3m / 30.6m                                                                \n",
      "16\t225k\t0.02\t\t0.03\t\t0.475\t\t0.906\t\t0.87m - 14.1m / 30.8m                                                                \n",
      "17\t239k\t0.01\t\t0.03\t\t0.484\t\t0.909\t\t0.87m - 15.0m / 30.6m                                                                \n",
      "18\t253k\t0.01\t\t0.03\t\t0.482\t\t0.908\t\t0.87m - 15.9m / 30.8m                                                                \n",
      "19\t267k\t0.01\t\t0.03\t\t0.478\t\t0.907\t\t0.88m - 16.8m / 30.8m                                                                \n",
      "VAL f1\t0.48547253204853213 - (0.48547253204853213)                                                                     \n",
      "VAL loss\t0.027973760494263696                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.027973760494263696\n",
      "        | \\     )|_\tf1: 0.48547253204853213\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\18 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 24.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         24                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0032490412034984904               |\n",
      "|  noam_learning_rate_warmup   |                        1664                       |\n",
      "|  noam_learning_rate_factor   |                 3.8124092230799054                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.22100336982117527                |\n",
      "|     pointwise_layer_size     |                        305                        |\n",
      "|      last_layer_dropout      |                 0.769750150553191                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 35%|██████████████▌                           | 52/150 [8:04:00<16:31:39, 607.14s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c250266e510d40b0958b6f561bc63d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.387\t\t0.900\t\t1.08m - 1.1m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.332\t\t0.878\t\t1.09m - 2.2m / 37.9m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.360\t\t0.888\t\t1.07m - 3.3m / 38.1m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.358\t\t0.891\t\t1.06m - 4.3m / 37.5m                                                                   \n",
      "5\t70k\t0.02\t\t0.02\t\t0.316\t\t0.870\t\t1.03m - 5.4m / 37.2m                                                                   \n",
      "6\t84k\t0.02\t\t0.02\t\t0.411\t\t0.910\t\t1.03m - 6.4m / 36.4m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.266\t\t0.842\t\t1.01m - 7.5m / 36.4m                                                                   \n",
      "8\t113k\t0.02\t\t0.02\t\t0.396\t\t0.905\t\t0.99m - 8.5m / 35.9m                                                                  \n",
      "9\t127k\t0.02\t\t0.02\t\t0.418\t\t0.913\t\t0.99m - 9.5m / 35.2m                                                                  \n",
      "10\t141k\t0.02\t\t0.03\t\t0.409\t\t0.909\t\t1.00m - 10.5m / 35.3m                                                                \n",
      "11\t155k\t0.02\t\t0.02\t\t0.384\t\t0.900\t\t1.01m - 11.5m / 35.4m                                                                \n",
      "12\t169k\t0.01\t\t0.02\t\t0.403\t\t0.907\t\t0.99m - 12.5m / 35.8m                                                                \n",
      "13\t183k\t0.01\t\t0.02\t\t0.314\t\t0.867\t\t1.00m - 13.5m / 35.4m                                                                \n",
      "14\t197k\t0.01\t\t0.03\t\t0.357\t\t0.890\t\t0.98m - 14.5m / 35.6m                                                                \n",
      "VAL f1\t0.4175897669354427 - (0.4175897669354427)                                                                       \n",
      "VAL loss\t0.019964108513508397                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.019964108513508397\n",
      "        | \\     )|_\tf1: 0.4175897669354427\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\19 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 35.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         35                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0003683207446691435               |\n",
      "|  noam_learning_rate_warmup   |                        8213                       |\n",
      "|  noam_learning_rate_factor   |                 3.6234217800455384                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.43269715036307566                |\n",
      "|     pointwise_layer_size     |                        232                        |\n",
      "|      last_layer_dropout      |                 0.5199745706888557                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 35%|██████████████▊                           | 53/150 [8:19:23<18:54:58, 702.04s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd2cc5a4fde4bada74ea2d1a4957205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.154\t\t0.792\t\t0.55m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.221\t\t0.860\t\t0.53m - 1.1m / 19.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.200\t\t0.849\t\t0.53m - 1.7m / 18.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.183\t\t0.835\t\t0.54m - 2.2m / 18.7m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.251\t\t0.881\t\t0.53m - 2.7m / 18.8m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.210\t\t0.855\t\t0.55m - 3.3m / 18.6m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.221\t\t0.871\t\t0.54m - 3.9m / 19.4m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.230\t\t0.870\t\t0.54m - 4.4m / 19.0m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.221\t\t0.873\t\t0.55m - 5.0m / 19.1m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.184\t\t0.837\t\t0.56m - 5.6m / 19.2m                                                                 \n",
      "VAL f1\t0.25132198189564847 - (0.25132198189564847)                                                                     \n",
      "VAL loss\t0.015306295076822905                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.015306295076822905\n",
      "        | \\     )|_\tf1: 0.25132198189564847\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\20 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 32.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         32                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.010698648136444264               |\n",
      "|  noam_learning_rate_warmup   |                        7253                       |\n",
      "|  noam_learning_rate_factor   |                 2.784938242125335                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.1632988781117903                |\n",
      "|     pointwise_layer_size     |                        261                        |\n",
      "|      last_layer_dropout      |                 0.1730587081847011                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 36%|███████████████                           | 54/150 [8:25:36<16:05:05, 603.19s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8c5b889984432f81c7e70ccbfb1ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.278\t\t0.880\t\t0.40m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.272\t\t0.875\t\t0.40m - 0.8m / 13.9m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.336\t\t0.906\t\t0.39m - 1.2m / 14.2m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.363\t\t0.915\t\t0.37m - 1.6m / 13.8m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.285\t\t0.884\t\t0.37m - 2.0m / 13.0m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.337\t\t0.907\t\t0.37m - 2.4m / 13.2m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.277\t\t0.880\t\t0.36m - 2.8m / 13.1m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.318\t\t0.902\t\t0.37m - 3.1m / 13.0m                                                                  \n",
      "9\t126k\t0.00\t\t0.02\t\t0.263\t\t0.870\t\t0.37m - 3.5m / 13.0m                                                                  \n",
      "VAL f1\t0.3625518467421495 - (0.3625518467421495)                                                                       \n",
      "VAL loss\t0.011091266258018533                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011091266258018533\n",
      "        | \\     )|_\tf1: 0.3625518467421495\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\21 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 51.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         51                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.002835727586072753               |\n",
      "|  noam_learning_rate_warmup   |                        2334                       |\n",
      "|  noam_learning_rate_factor   |                0.45941463098053115                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.6332209050275427                |\n",
      "|     pointwise_layer_size     |                         79                        |\n",
      "|      last_layer_dropout      |                0.20039769597559262                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 37%|███████████████▍                          | 55/150 [8:29:34<13:01:41, 493.70s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1427a9b769134bdeaa1aaf7d67bbf4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.106\t\t0.784\t\t0.55m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.106\t\t0.784\t\t0.55m - 1.1m / 19.4m                                                                   \n",
      "3\t42k\t0.03\t\t0.02\t\t0.087\t\t0.779\t\t0.55m - 1.7m / 19.4m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.139\t\t0.831\t\t0.55m - 2.2m / 19.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.133\t\t0.824\t\t0.54m - 2.8m / 19.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.117\t\t0.805\t\t0.55m - 3.4m / 19.1m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.137\t\t0.832\t\t0.55m - 3.9m / 19.4m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.135\t\t0.832\t\t0.56m - 4.5m / 19.3m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.152\t\t0.852\t\t0.55m - 5.1m / 19.7m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.154\t\t0.857\t\t0.58m - 5.7m / 19.3m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.181\t\t0.871\t\t0.56m - 6.3m / 20.1m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.161\t\t0.863\t\t0.57m - 6.9m / 19.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.154\t\t0.855\t\t0.55m - 7.5m / 19.9m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.173\t\t0.868\t\t0.54m - 8.0m / 19.5m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.170\t\t0.865\t\t0.55m - 8.6m / 19.3m                                                                 \n",
      "16\t225k\t0.00\t\t0.02\t\t0.181\t\t0.873\t\t0.54m - 9.1m / 19.5m                                                                 \n",
      "17\t239k\t0.00\t\t0.01\t\t0.177\t\t0.870\t\t0.55m - 9.7m / 19.5m                                                                 \n",
      "18\t253k\t0.00\t\t0.02\t\t0.183\t\t0.872\t\t0.54m - 10.2m / 19.5m                                                                \n",
      "19\t267k\t0.00\t\t0.01\t\t0.188\t\t0.875\t\t0.53m - 10.8m / 19.4m                                                                \n",
      "20\t282k\t0.00\t\t0.01\t\t0.176\t\t0.869\t\t0.54m - 11.3m / 19.3m                                                                \n",
      "21\t296k\t0.00\t\t0.02\t\t0.181\t\t0.871\t\t0.53m - 11.9m / 19.5m                                                                \n",
      "22\t310k\t0.00\t\t0.01\t\t0.180\t\t0.869\t\t0.53m - 12.4m / 19.3m                                                                \n",
      "23\t324k\t0.00\t\t0.01\t\t0.192\t\t0.876\t\t0.54m - 13.0m / 19.3m                                                                \n",
      "24\t338k\t0.00\t\t0.02\t\t0.193\t\t0.877\t\t0.53m - 13.5m / 19.5m                                                                \n",
      "25\t352k\t0.00\t\t0.01\t\t0.192\t\t0.876\t\t0.53m - 14.1m / 19.3m                                                                \n",
      "26\t366k\t0.00\t\t0.01\t\t0.182\t\t0.870\t\t0.53m - 14.6m / 19.3m                                                                \n",
      "27\t380k\t0.00\t\t0.01\t\t0.197\t\t0.880\t\t0.53m - 15.2m / 19.4m                                                                \n",
      "28\t394k\t0.00\t\t0.01\t\t0.193\t\t0.877\t\t0.53m - 15.7m / 19.5m                                                                \n",
      "29\t408k\t0.00\t\t0.01\t\t0.190\t\t0.873\t\t0.52m - 16.2m / 19.4m                                                                \n",
      "30\t422k\t0.00\t\t0.01\t\t0.193\t\t0.878\t\t0.53m - 16.8m / 19.4m                                                                \n",
      "31\t436k\t0.00\t\t0.01\t\t0.191\t\t0.877\t\t0.53m - 17.3m / 19.5m                                                                \n",
      "32\t450k\t0.00\t\t0.01\t\t0.194\t\t0.877\t\t0.53m - 17.9m / 19.5m                                                                \n",
      "VAL f1\t0.19724401542491965 - (0.19724401542491965)                                                                     \n",
      "VAL loss\t0.01301804205122251                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01301804205122251\n",
      "        | \\     )|_\tf1: 0.19724401542491965\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\22 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 58.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         58                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.5102494420129279                |\n",
      "|  noam_learning_rate_warmup   |                        8851                       |\n",
      "|  noam_learning_rate_factor   |                0.10059202101378552                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.28019391623234374                |\n",
      "|     pointwise_layer_size     |                        184                        |\n",
      "|      last_layer_dropout      |                  0.12834098280056                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 37%|███████████████▋                          | 56/150 [8:47:58<17:40:17, 676.78s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a14a46a712472797d159f11a82f6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.090\t\t0.780\t\t0.37m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.37m - 0.8m / 13.1m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.37m - 1.1m / 13.0m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.37m - 1.5m / 13.1m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.39m - 1.9m / 13.1m                                                                   \n",
      "6\t85k\t0.02\t\t0.02\t\t0.092\t\t0.784\t\t0.37m - 2.3m / 13.5m                                                                   \n",
      "7\t99k\t0.02\t\t0.02\t\t0.104\t\t0.800\t\t0.40m - 2.7m / 13.1m                                                                   \n",
      "8\t113k\t0.02\t\t0.02\t\t0.108\t\t0.808\t\t0.41m - 3.2m / 14.0m                                                                  \n",
      "9\t127k\t0.02\t\t0.02\t\t0.114\t\t0.821\t\t0.40m - 3.6m / 14.2m                                                                  \n",
      "10\t141k\t0.02\t\t0.01\t\t0.122\t\t0.833\t\t0.39m - 4.0m / 14.0m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.128\t\t0.838\t\t0.38m - 4.4m / 13.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.132\t\t0.842\t\t0.38m - 4.8m / 13.4m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.135\t\t0.846\t\t0.37m - 5.2m / 13.5m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.140\t\t0.853\t\t0.36m - 5.6m / 13.3m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.139\t\t0.851\t\t0.36m - 6.0m / 13.2m                                                                 \n",
      "16\t226k\t0.01\t\t0.01\t\t0.145\t\t0.858\t\t0.37m - 6.3m / 13.2m                                                                 \n",
      "17\t240k\t0.01\t\t0.01\t\t0.144\t\t0.858\t\t0.37m - 6.7m / 13.3m                                                                 \n",
      "18\t254k\t0.01\t\t0.01\t\t0.142\t\t0.856\t\t0.36m - 7.1m / 13.3m                                                                 \n",
      "19\t268k\t0.01\t\t0.01\t\t0.148\t\t0.864\t\t0.36m - 7.5m / 13.3m                                                                 \n",
      "20\t282k\t0.00\t\t0.01\t\t0.149\t\t0.865\t\t0.37m - 7.9m / 13.3m                                                                 \n",
      "21\t296k\t0.00\t\t0.01\t\t0.147\t\t0.862\t\t0.37m - 8.2m / 13.4m                                                                 \n",
      "22\t310k\t0.00\t\t0.01\t\t0.151\t\t0.867\t\t0.36m - 8.6m / 13.4m                                                                 \n",
      "23\t324k\t0.00\t\t0.01\t\t0.144\t\t0.861\t\t0.37m - 9.0m / 13.3m                                                                 \n",
      "24\t338k\t0.00\t\t0.01\t\t0.137\t\t0.853\t\t0.37m - 9.4m / 13.4m                                                                 \n",
      "25\t352k\t0.00\t\t0.01\t\t0.158\t\t0.874\t\t0.38m - 9.8m / 13.4m                                                                 \n",
      "26\t366k\t0.00\t\t0.01\t\t0.152\t\t0.869\t\t0.36m - 10.1m / 13.5m                                                                \n",
      "27\t381k\t0.00\t\t0.01\t\t0.162\t\t0.876\t\t0.36m - 10.5m / 13.4m                                                                \n",
      "28\t395k\t0.00\t\t0.01\t\t0.156\t\t0.872\t\t0.37m - 10.9m / 13.4m                                                                \n",
      "29\t409k\t0.00\t\t0.01\t\t0.154\t\t0.870\t\t0.37m - 11.3m / 13.5m                                                                \n",
      "30\t423k\t0.00\t\t0.01\t\t0.150\t\t0.869\t\t0.37m - 11.7m / 13.5m                                                                \n",
      "31\t437k\t0.00\t\t0.01\t\t0.148\t\t0.866\t\t0.37m - 12.1m / 13.5m                                                                \n",
      "32\t451k\t0.00\t\t0.01\t\t0.155\t\t0.873\t\t0.37m - 12.4m / 13.6m                                                                \n",
      "VAL f1\t0.16157021586687992 - (0.16157021586687992)                                                                     \n",
      "VAL loss\t0.009867298440632782                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009867298440632782\n",
      "        | \\     )|_\tf1: 0.16157021586687992\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\23 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 23.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         23                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.117259975924834                 |\n",
      "|  noam_learning_rate_warmup   |                        5621                       |\n",
      "|  noam_learning_rate_factor   |                 2.520977263472685                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7327942737592054                |\n",
      "|     pointwise_layer_size     |                        323                        |\n",
      "|      last_layer_dropout      |                 0.7436447098698524                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 38%|███████████████▉                          | 57/150 [9:00:53<18:14:45, 706.29s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48961ae1003b470ca70e27f578a6da81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.08\t\t0.245\t\t0.819\t\t1.02m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.07\t\t0.216\t\t0.770\t\t1.03m - 2.1m / 35.7m                                                                   \n",
      "3\t42k\t0.06\t\t0.05\t\t0.279\t\t0.838\t\t1.04m - 3.1m / 36.0m                                                                   \n",
      "4\t56k\t0.05\t\t0.05\t\t0.242\t\t0.812\t\t1.07m - 4.2m / 36.3m                                                                   \n",
      "5\t70k\t0.04\t\t0.07\t\t0.239\t\t0.804\t\t1.09m - 5.3m / 37.3m                                                                   \n",
      "6\t84k\t0.04\t\t0.06\t\t0.274\t\t0.839\t\t1.07m - 6.4m / 38.0m                                                                   \n",
      "7\t98k\t0.04\t\t0.06\t\t0.241\t\t0.807\t\t1.01m - 7.4m / 37.3m                                                                   \n",
      "8\t112k\t0.04\t\t0.08\t\t0.288\t\t0.845\t\t1.02m - 8.4m / 35.7m                                                                  \n",
      "9\t126k\t0.04\t\t0.08\t\t0.238\t\t0.807\t\t1.01m - 9.5m / 36.0m                                                                  \n",
      "10\t141k\t0.04\t\t0.10\t\t0.274\t\t0.803\t\t1.02m - 10.5m / 35.7m                                                                \n",
      "11\t155k\t0.04\t\t0.07\t\t0.265\t\t0.820\t\t1.01m - 11.5m / 36.0m                                                                \n",
      "12\t169k\t0.04\t\t0.06\t\t0.246\t\t0.821\t\t1.01m - 12.5m / 35.7m                                                                \n",
      "13\t183k\t0.03\t\t0.07\t\t0.286\t\t0.845\t\t1.03m - 13.6m / 35.8m                                                                \n",
      "VAL f1\t0.28808812699234687 - (0.28808812699234687)                                                                     \n",
      "VAL loss\t0.04875824167475844                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04875824167475844\n",
      "        | \\     )|_\tf1: 0.28808812699234687\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\24 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 40.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         40                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.018745846170495413               |\n",
      "|  noam_learning_rate_warmup   |                        2440                       |\n",
      "|  noam_learning_rate_factor   |                 0.4080288658422562                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7388959696716492                |\n",
      "|     pointwise_layer_size     |                         86                        |\n",
      "|      last_layer_dropout      |                 0.2110883451199296                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 39%|████████████████▏                         | 58/150 [9:15:11<19:12:39, 751.74s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d97eadae14a45a68f203f1681a0cf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.154\t\t0.810\t\t0.50m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.154\t\t0.810\t\t0.51m - 1.0m / 17.5m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.155\t\t0.810\t\t0.49m - 1.5m / 17.8m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.175\t\t0.828\t\t0.49m - 2.0m / 17.2m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.159\t\t0.822\t\t0.49m - 2.5m / 17.3m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.167\t\t0.821\t\t0.49m - 3.0m / 17.2m                                                                   \n",
      "7\t99k\t0.02\t\t0.04\t\t0.159\t\t0.805\t\t0.49m - 3.5m / 17.1m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.171\t\t0.823\t\t0.48m - 4.0m / 17.2m                                                                  \n",
      "9\t127k\t0.01\t\t0.03\t\t0.214\t\t0.862\t\t0.50m - 4.5m / 17.1m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.227\t\t0.871\t\t0.49m - 5.1m / 17.5m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.237\t\t0.876\t\t0.52m - 5.6m / 17.4m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.238\t\t0.877\t\t0.50m - 6.1m / 18.0m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.249\t\t0.886\t\t0.48m - 6.6m / 17.6m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.247\t\t0.884\t\t0.50m - 7.2m / 17.3m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.264\t\t0.892\t\t0.47m - 7.7m / 17.8m                                                                 \n",
      "16\t225k\t0.01\t\t0.02\t\t0.261\t\t0.891\t\t0.47m - 8.1m / 17.1m                                                                 \n",
      "17\t239k\t0.01\t\t0.02\t\t0.265\t\t0.892\t\t0.46m - 8.6m / 17.0m                                                                 \n",
      "18\t253k\t0.01\t\t0.02\t\t0.249\t\t0.886\t\t0.47m - 9.1m / 16.9m                                                                 \n",
      "19\t268k\t0.01\t\t0.02\t\t0.264\t\t0.892\t\t0.47m - 9.6m / 17.1m                                                                 \n",
      "20\t282k\t0.01\t\t0.02\t\t0.261\t\t0.892\t\t0.47m - 10.1m / 17.0m                                                                \n",
      "21\t296k\t0.01\t\t0.02\t\t0.260\t\t0.891\t\t0.46m - 10.5m / 17.0m                                                                \n",
      "22\t310k\t0.01\t\t0.02\t\t0.263\t\t0.893\t\t0.46m - 11.0m / 17.0m                                                                \n",
      "VAL f1\t0.2647787234719955 - (0.2647787234719955)                                                                       \n",
      "VAL loss\t0.016989368745466558                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.016989368745466558\n",
      "        | \\     )|_\tf1: 0.2647787234719955\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\25 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 48.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         48                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.002219071244955911               |\n",
      "|  noam_learning_rate_warmup   |                        1863                       |\n",
      "|  noam_learning_rate_factor   |                 3.6946969002586267                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5787321370469987                |\n",
      "|     pointwise_layer_size     |                         87                        |\n",
      "|      last_layer_dropout      |                 0.5063405430421062                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 39%|████████████████▌                         | 59/150 [9:26:49<18:35:40, 735.61s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32db4d13788441fa405396c2fc0e2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.173\t\t0.859\t\t0.28m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.214\t\t0.885\t\t0.28m - 0.6m / 9.8m                                                                    \n",
      "3\t42k\t0.01\t\t0.01\t\t0.152\t\t0.844\t\t0.28m - 0.9m / 10.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.184\t\t0.863\t\t0.27m - 1.2m / 9.8m                                                                    \n",
      "5\t70k\t0.01\t\t0.01\t\t0.152\t\t0.847\t\t0.27m - 1.4m / 9.7m                                                                    \n",
      "6\t84k\t0.01\t\t0.01\t\t0.148\t\t0.839\t\t0.28m - 1.7m / 9.6m                                                                    \n",
      "7\t98k\t0.01\t\t0.01\t\t0.147\t\t0.838\t\t0.27m - 2.0m / 9.7m                                                                    \n",
      "VAL f1\t0.21400290650260473 - (0.21400290650260473)                                                                     \n",
      "VAL loss\t0.012263339460261312                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012263339460261312\n",
      "        | \\     )|_\tf1: 0.21400290650260473\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\26 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 18.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         18                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.13419593200392188                |\n",
      "|  noam_learning_rate_warmup   |                        3746                       |\n",
      "|  noam_learning_rate_factor   |                  3.45195853663887                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5840047560960818                |\n",
      "|     pointwise_layer_size     |                        140                        |\n",
      "|      last_layer_dropout      |                 0.7062100120533296                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 40%|████████████████▊                         | 60/150 [9:29:21<14:00:53, 560.59s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11fbdfdd4464aaeaf6c8a39a9ee2a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.06\t\t0.419\t\t0.887\t\t0.58m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.04\t\t0.372\t\t0.865\t\t0.58m - 1.2m / 20.2m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.395\t\t0.877\t\t0.60m - 1.8m / 20.2m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.416\t\t0.881\t\t0.59m - 2.4m / 21.0m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.341\t\t0.846\t\t0.59m - 3.0m / 20.8m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.442\t\t0.895\t\t0.59m - 3.6m / 20.6m                                                                   \n",
      "7\t98k\t0.03\t\t0.07\t\t0.375\t\t0.870\t\t0.55m - 4.2m / 20.6m                                                                   \n",
      "8\t112k\t0.03\t\t0.04\t\t0.373\t\t0.861\t\t0.56m - 4.7m / 19.6m                                                                  \n",
      "9\t127k\t0.03\t\t0.06\t\t0.368\t\t0.861\t\t0.56m - 5.3m / 19.8m                                                                  \n",
      "10\t141k\t0.03\t\t0.03\t\t0.430\t\t0.890\t\t0.56m - 5.9m / 19.8m                                                                 \n",
      "11\t155k\t0.03\t\t0.03\t\t0.357\t\t0.857\t\t0.58m - 6.5m / 20.0m                                                                 \n",
      "VAL f1\t0.4421856533673443 - (0.4421856533673443)                                                                       \n",
      "VAL loss\t0.03430512268725094                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03430512268725094\n",
      "        | \\     )|_\tf1: 0.4421856533673443\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\27 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 47.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         47                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.259331808870705                 |\n",
      "|  noam_learning_rate_warmup   |                        6231                       |\n",
      "|  noam_learning_rate_factor   |                 3.377382219620407                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.05176137783950799                |\n",
      "|     pointwise_layer_size     |                         37                        |\n",
      "|      last_layer_dropout      |                0.27894736339297427                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 41%|█████████████████                         | 61/150 [9:36:29<12:52:28, 520.77s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcecc4b6b704d8599628b947f75d127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.166\t\t0.847\t\t0.70m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.238\t\t0.897\t\t0.73m - 1.5m / 24.6m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.237\t\t0.898\t\t0.70m - 2.3m / 25.7m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.204\t\t0.879\t\t0.70m - 3.0m / 24.6m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.257\t\t0.907\t\t0.67m - 3.7m / 24.8m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.255\t\t0.905\t\t0.67m - 4.3m / 23.7m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.246\t\t0.905\t\t0.68m - 5.0m / 23.8m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.261\t\t0.908\t\t0.67m - 5.7m / 24.1m                                                                  \n",
      "9\t126k\t0.00\t\t0.01\t\t0.256\t\t0.907\t\t0.63m - 6.4m / 23.8m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.262\t\t0.907\t\t0.65m - 7.0m / 22.8m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.270\t\t0.912\t\t0.65m - 7.7m / 23.2m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.277\t\t0.916\t\t0.64m - 8.4m / 23.4m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.253\t\t0.905\t\t0.65m - 9.0m / 23.2m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.270\t\t0.912\t\t0.65m - 9.7m / 23.3m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.243\t\t0.900\t\t0.65m - 10.3m / 23.3m                                                                \n",
      "16\t225k\t0.00\t\t0.01\t\t0.253\t\t0.905\t\t0.66m - 11.0m / 23.3m                                                                \n",
      "17\t239k\t0.00\t\t0.01\t\t0.256\t\t0.908\t\t0.67m - 11.7m / 23.5m                                                                \n",
      "VAL f1\t0.2769185785008601 - (0.2769185785008601)                                                                       \n",
      "VAL loss\t0.007614031610699049                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.007614031610699049\n",
      "        | \\     )|_\tf1: 0.2769185785008601\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\28 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 50.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         50                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0010128373666161347               |\n",
      "|  noam_learning_rate_warmup   |                        2164                       |\n",
      "|  noam_learning_rate_factor   |                 2.7481931464159683                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.642648416744663                 |\n",
      "|     pointwise_layer_size     |                        140                        |\n",
      "|      last_layer_dropout      |                0.08312408145409585                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 41%|█████████████████▎                        | 62/150 [9:48:57<14:23:31, 588.77s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0297151276894c5aba147798b91a4fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.104\t\t0.781\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.104\t\t0.786\t\t0.41m - 0.8m / 14.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.135\t\t0.839\t\t0.41m - 1.3m / 14.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.146\t\t0.845\t\t0.41m - 1.7m / 14.5m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.136\t\t0.836\t\t0.44m - 2.2m / 14.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.134\t\t0.830\t\t0.44m - 2.6m / 15.4m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.116\t\t0.811\t\t0.43m - 3.0m / 15.3m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.140\t\t0.835\t\t0.44m - 3.5m / 15.1m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.111\t\t0.795\t\t0.43m - 3.9m / 15.4m                                                                  \n",
      "VAL f1\t0.14607805450062705 - (0.14607805450062705)                                                                     \n",
      "VAL loss\t0.0124436819255352                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0124436819255352\n",
      "        | \\     )|_\tf1: 0.14607805450062705\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\29 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 33.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         33                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.009511560108179606               |\n",
      "|  noam_learning_rate_warmup   |                        8449                       |\n",
      "|  noam_learning_rate_factor   |                 1.158097937153799                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.0340312405388028                |\n",
      "|     pointwise_layer_size     |                         53                        |\n",
      "|      last_layer_dropout      |                 0.6008843905942252                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 42%|█████████████████▋                        | 63/150 [9:53:22<11:52:51, 491.63s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3e075568cf4d319dfc507574faee11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.147\t\t0.785\t\t0.77m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.277\t\t0.883\t\t0.78m - 1.6m / 27.0m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.321\t\t0.903\t\t0.78m - 2.4m / 27.2m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.303\t\t0.896\t\t0.76m - 3.1m / 27.2m                                                                   \n",
      "5\t70k\t0.00\t\t0.02\t\t0.281\t\t0.887\t\t0.75m - 3.9m / 26.8m                                                                   \n",
      "6\t84k\t0.00\t\t0.02\t\t0.303\t\t0.898\t\t0.75m - 4.7m / 26.3m                                                                   \n",
      "7\t98k\t0.00\t\t0.02\t\t0.315\t\t0.904\t\t0.76m - 5.4m / 26.6m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.349\t\t0.915\t\t0.75m - 6.2m / 26.6m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.327\t\t0.905\t\t0.74m - 6.9m / 26.5m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.351\t\t0.914\t\t0.74m - 7.7m / 26.1m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.349\t\t0.912\t\t0.75m - 8.5m / 26.3m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.343\t\t0.913\t\t0.75m - 9.2m / 26.4m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.342\t\t0.914\t\t0.75m - 10.0m / 26.5m                                                                \n",
      "14\t197k\t0.00\t\t0.01\t\t0.257\t\t0.875\t\t0.75m - 10.8m / 26.5m                                                                \n",
      "15\t211k\t0.00\t\t0.01\t\t0.368\t\t0.920\t\t0.76m - 11.5m / 26.6m                                                                \n",
      "16\t225k\t0.00\t\t0.01\t\t0.336\t\t0.908\t\t0.77m - 12.3m / 26.7m                                                                \n",
      "17\t239k\t0.00\t\t0.02\t\t0.297\t\t0.891\t\t0.80m - 13.1m / 27.0m                                                                \n",
      "18\t253k\t0.00\t\t0.01\t\t0.344\t\t0.912\t\t0.78m - 13.9m / 27.5m                                                                \n",
      "19\t267k\t0.00\t\t0.01\t\t0.311\t\t0.899\t\t0.75m - 14.7m / 27.2m                                                                \n",
      "20\t281k\t0.00\t\t0.02\t\t0.271\t\t0.879\t\t0.76m - 15.4m / 26.6m                                                                \n",
      "VAL f1\t0.36807713394267955 - (0.36807713394267955)                                                                     \n",
      "VAL loss\t0.012204240161479703                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012204240161479703\n",
      "        | \\     )|_\tf1: 0.36807713394267955\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\30 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 39.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         39                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0004244663640585369               |\n",
      "|  noam_learning_rate_warmup   |                        7129                       |\n",
      "|  noam_learning_rate_factor   |                0.01077850421329474                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.454292701437912                 |\n",
      "|     pointwise_layer_size     |                        202                        |\n",
      "|      last_layer_dropout      |                 0.7478706058053035                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 43%|█████████████████▍                       | 64/150 [10:09:28<15:08:36, 633.92s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fab79fd4d5648329d864c10d444b702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.07\t\t0.007\t\t0.022\t\t0.53m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.05\t\t0.154\t\t0.806\t\t0.52m - 1.1m / 18.4m                                                                   \n",
      "3\t42k\t0.05\t\t0.04\t\t0.156\t\t0.810\t\t0.50m - 1.6m / 18.4m                                                                   \n",
      "4\t56k\t0.05\t\t0.04\t\t0.156\t\t0.810\t\t0.52m - 2.1m / 17.7m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.53m - 2.7m / 18.3m                                                                   \n",
      "6\t84k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.51m - 3.2m / 18.7m                                                                   \n",
      "7\t99k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.52m - 3.7m / 18.1m                                                                   \n",
      "8\t113k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.51m - 4.3m / 18.4m                                                                  \n",
      "VAL f1\t0.15631479633082307 - (0.15631479633082307)                                                                     \n",
      "VAL loss\t0.03875016722195897                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03875016722195897\n",
      "        | \\     )|_\tf1: 0.15631479633082307\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\31 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 19.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         19                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.013786837670942116               |\n",
      "|  noam_learning_rate_warmup   |                        6122                       |\n",
      "|  noam_learning_rate_factor   |                 2.000759183088626                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.7826645940079295                |\n",
      "|     pointwise_layer_size     |                        224                        |\n",
      "|      last_layer_dropout      |                0.43236066620394076                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 43%|█████████████████▊                       | 65/150 [10:14:20<12:33:01, 531.55s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adca63f5a2d54c3480d11685dbaee48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.09\t\t0.270\t\t0.813\t\t1.17m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.08\t\t0.09\t\t0.270\t\t0.813\t\t1.18m - 2.4m / 41.0m                                                                   \n",
      "3\t42k\t0.08\t\t0.09\t\t0.270\t\t0.813\t\t1.16m - 3.5m / 41.4m                                                                   \n",
      "4\t56k\t0.07\t\t0.09\t\t0.270\t\t0.813\t\t1.17m - 4.7m / 40.7m                                                                   \n",
      "5\t70k\t0.07\t\t0.09\t\t0.270\t\t0.813\t\t1.25m - 6.0m / 41.0m                                                                   \n",
      "6\t84k\t0.07\t\t0.09\t\t0.270\t\t0.813\t\t1.26m - 7.3m / 43.5m                                                                   \n",
      "VAL f1\t0.2697702466638855 - (0.2697702466638855)                                                                       \n",
      "VAL loss\t0.08638743788113355                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.08638743788113355\n",
      "        | \\     )|_\tf1: 0.2697702466638855\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\32 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 18.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         18                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0014834945709870928               |\n",
      "|  noam_learning_rate_warmup   |                        6167                       |\n",
      "|  noam_learning_rate_factor   |                 3.9707830012188055                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6460917779709323                |\n",
      "|     pointwise_layer_size     |                        119                        |\n",
      "|      last_layer_dropout      |                0.15525311954103727                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 44%|██████████████████                       | 66/150 [10:22:27<12:05:24, 518.15s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ecdde8327b4b59b67fa91bf0da5f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.09\t\t0.08\t\t0.300\t\t0.824\t\t1.19m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.06\t\t0.366\t\t0.859\t\t1.20m - 2.4m / 41.8m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.435\t\t0.893\t\t1.15m - 3.6m / 42.1m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.427\t\t0.885\t\t1.19m - 4.8m / 40.6m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.465\t\t0.904\t\t1.19m - 6.0m / 41.7m                                                                   \n",
      "6\t84k\t0.03\t\t0.03\t\t0.478\t\t0.908\t\t1.14m - 7.2m / 41.8m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.408\t\t0.885\t\t1.16m - 8.3m / 40.3m                                                                   \n",
      "8\t112k\t0.03\t\t0.04\t\t0.352\t\t0.849\t\t1.17m - 9.5m / 40.9m                                                                  \n",
      "9\t127k\t0.03\t\t0.04\t\t0.448\t\t0.894\t\t1.16m - 10.7m / 41.1m                                                                 \n",
      "10\t141k\t0.03\t\t0.04\t\t0.473\t\t0.906\t\t1.15m - 11.9m / 40.8m                                                                \n",
      "11\t155k\t0.03\t\t0.06\t\t0.243\t\t0.771\t\t1.15m - 13.0m / 40.6m                                                                \n",
      "VAL f1\t0.47808585171898094 - (0.47808585171898094)                                                                     \n",
      "VAL loss\t0.031064435522351583                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.031064435522351583\n",
      "        | \\     )|_\tf1: 0.47808585171898094\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\33 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 38.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         38                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.014761174420837943               |\n",
      "|  noam_learning_rate_warmup   |                        8255                       |\n",
      "|  noam_learning_rate_factor   |                 2.6766647496090776                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6704507932421803                |\n",
      "|     pointwise_layer_size     |                        123                        |\n",
      "|      last_layer_dropout      |                 0.4605932788820698                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 45%|██████████████████▎                      | 67/150 [10:36:20<14:07:26, 612.61s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7726bc8c6d04a208d1799edb1604d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.155\t\t0.804\t\t0.65m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.155\t\t0.804\t\t0.71m - 1.4m / 22.9m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.121\t\t0.779\t\t0.66m - 2.1m / 25.0m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.181\t\t0.828\t\t0.68m - 2.9m / 23.4m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.166\t\t0.816\t\t0.67m - 3.6m / 23.9m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.180\t\t0.832\t\t0.65m - 4.3m / 23.8m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.190\t\t0.839\t\t0.65m - 4.9m / 23.2m                                                                   \n",
      "8\t112k\t0.01\t\t0.03\t\t0.218\t\t0.861\t\t0.62m - 5.6m / 23.3m                                                                  \n",
      "9\t127k\t0.01\t\t0.03\t\t0.206\t\t0.852\t\t0.64m - 6.2m / 22.4m                                                                  \n",
      "10\t141k\t0.01\t\t0.04\t\t0.218\t\t0.863\t\t0.64m - 6.9m / 22.8m                                                                 \n",
      "11\t155k\t0.01\t\t0.04\t\t0.207\t\t0.857\t\t0.61m - 7.5m / 22.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.03\t\t0.221\t\t0.865\t\t0.62m - 8.1m / 22.3m                                                                 \n",
      "13\t183k\t0.01\t\t0.04\t\t0.203\t\t0.860\t\t0.62m - 8.8m / 22.3m                                                                 \n",
      "14\t197k\t0.01\t\t0.03\t\t0.228\t\t0.868\t\t0.62m - 9.4m / 22.5m                                                                 \n",
      "15\t211k\t0.01\t\t0.03\t\t0.225\t\t0.865\t\t0.61m - 10.0m / 22.5m                                                                \n",
      "16\t225k\t0.01\t\t0.03\t\t0.226\t\t0.866\t\t0.61m - 10.7m / 22.3m                                                                \n",
      "17\t239k\t0.01\t\t0.03\t\t0.207\t\t0.853\t\t0.61m - 11.3m / 22.4m                                                                \n",
      "18\t253k\t0.01\t\t0.03\t\t0.214\t\t0.858\t\t0.62m - 11.9m / 22.4m                                                                \n",
      "19\t267k\t0.01\t\t0.03\t\t0.201\t\t0.846\t\t0.61m - 12.5m / 22.4m                                                                \n",
      "VAL f1\t0.22827862701913842 - (0.22827862701913842)                                                                     \n",
      "VAL loss\t0.027634107012180845                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.027634107012180845\n",
      "        | \\     )|_\tf1: 0.22827862701913842\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\34 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 25.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         25                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.02199906743815764                |\n",
      "|  noam_learning_rate_warmup   |                        2496                       |\n",
      "|  noam_learning_rate_factor   |                 2.0693059823318873                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.040622215188438116               |\n",
      "|     pointwise_layer_size     |                        236                        |\n",
      "|      last_layer_dropout      |                 0.6453813351335849                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 45%|██████████████████▌                      | 68/150 [10:49:26<15:08:14, 664.56s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809a37c00ad34ff2b849814e351dd873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.373\t\t0.903\t\t0.50m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.343\t\t0.897\t\t0.49m - 1.0m / 17.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.297\t\t0.872\t\t0.49m - 1.5m / 17.1m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.345\t\t0.894\t\t0.49m - 2.0m / 17.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.290\t\t0.874\t\t0.51m - 2.5m / 17.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.309\t\t0.880\t\t0.48m - 3.0m / 17.7m                                                                   \n",
      "VAL f1\t0.37304322319266375 - (0.37304322319266375)                                                                     \n",
      "VAL loss\t0.014826405084620301                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014826405084620301\n",
      "        | \\     )|_\tf1: 0.37304322319266375\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\35 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 31.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         31                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0038593635894627514               |\n",
      "|  noam_learning_rate_warmup   |                        1629                       |\n",
      "|  noam_learning_rate_factor   |                 3.4066582434553934                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.052516795172797795               |\n",
      "|     pointwise_layer_size     |                        347                        |\n",
      "|      last_layer_dropout      |                 0.7508431705427777                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 46%|██████████████████▊                      | 69/150 [10:53:05<11:56:45, 530.94s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d857928cf456eb787fd2c056cc56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.02\t\t0.01\t\t0.295\t\t0.889\t\t0.62m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.02\t\t0.168\t\t0.800\t\t0.62m - 1.3m / 21.8m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.222\t\t0.842\t\t0.62m - 1.9m / 21.8m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.148\t\t0.760\t\t0.63m - 2.5m / 21.7m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.150\t\t0.781\t\t0.62m - 3.2m / 22.1m                                                                   \n",
      "6\t84k\t0.03\t\t0.03\t\t0.129\t\t0.761\t\t0.62m - 3.8m / 21.7m                                                                   \n",
      "VAL f1\t0.29506973355209665 - (0.29506973355209665)                                                                     \n",
      "VAL loss\t0.01480805737219648                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01480805737219648\n",
      "        | \\     )|_\tf1: 0.29506973355209665\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\36 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.024433717347491064               |\n",
      "|  noam_learning_rate_warmup   |                        8622                       |\n",
      "|  noam_learning_rate_factor   |                 2.1620049891855904                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7472346119799469                |\n",
      "|     pointwise_layer_size     |                        208                        |\n",
      "|      last_layer_dropout      |                 0.4374338102739268                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 47%|███████████████████▏                     | 70/150 [10:57:27<10:00:11, 450.15s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6b8ca44f3046bab5ebf3ba8b90b765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.122\t\t0.800\t\t0.45m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.122\t\t0.800\t\t0.43m - 0.9m / 15.6m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.122\t\t0.800\t\t0.43m - 1.3m / 15.2m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.122\t\t0.800\t\t0.43m - 1.8m / 15.1m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.108\t\t0.783\t\t0.43m - 2.2m / 15.2m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.118\t\t0.799\t\t0.43m - 2.7m / 15.1m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.144\t\t0.829\t\t0.42m - 3.1m / 15.1m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.145\t\t0.831\t\t0.43m - 3.6m / 14.9m                                                                  \n",
      "9\t127k\t0.01\t\t0.03\t\t0.136\t\t0.814\t\t0.41m - 4.0m / 15.3m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.146\t\t0.822\t\t0.42m - 4.4m / 14.7m                                                                 \n",
      "11\t155k\t0.01\t\t0.03\t\t0.161\t\t0.840\t\t0.41m - 4.9m / 14.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.03\t\t0.163\t\t0.847\t\t0.41m - 5.3m / 14.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.182\t\t0.864\t\t0.41m - 5.7m / 14.7m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.176\t\t0.858\t\t0.41m - 6.1m / 14.8m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.191\t\t0.872\t\t0.42m - 6.6m / 14.8m                                                                 \n",
      "16\t225k\t0.01\t\t0.02\t\t0.198\t\t0.878\t\t0.42m - 7.0m / 15.0m                                                                 \n",
      "17\t239k\t0.01\t\t0.02\t\t0.199\t\t0.878\t\t0.45m - 7.5m / 15.0m                                                                 \n",
      "18\t253k\t0.01\t\t0.02\t\t0.189\t\t0.870\t\t0.43m - 8.0m / 15.6m                                                                 \n",
      "19\t267k\t0.01\t\t0.03\t\t0.177\t\t0.861\t\t0.43m - 8.4m / 15.4m                                                                 \n",
      "20\t281k\t0.01\t\t0.02\t\t0.201\t\t0.877\t\t0.43m - 8.9m / 15.4m                                                                 \n",
      "21\t295k\t0.01\t\t0.02\t\t0.195\t\t0.878\t\t0.44m - 9.3m / 15.3m                                                                 \n",
      "22\t309k\t0.01\t\t0.02\t\t0.208\t\t0.884\t\t0.44m - 9.8m / 15.5m                                                                 \n",
      "23\t323k\t0.01\t\t0.02\t\t0.194\t\t0.874\t\t0.41m - 10.2m / 15.5m                                                                \n",
      "24\t338k\t0.01\t\t0.02\t\t0.205\t\t0.881\t\t0.41m - 10.6m / 15.1m                                                                \n",
      "25\t352k\t0.01\t\t0.02\t\t0.200\t\t0.879\t\t0.41m - 11.0m / 15.1m                                                                \n",
      "26\t366k\t0.01\t\t0.02\t\t0.205\t\t0.881\t\t0.43m - 11.5m / 15.1m                                                                \n",
      "27\t380k\t0.01\t\t0.02\t\t0.192\t\t0.874\t\t0.42m - 11.9m / 15.4m                                                                \n",
      "VAL f1\t0.2080432761597459 - (0.2080432761597459)                                                                       \n",
      "VAL loss\t0.018120694163979063                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.018120694163979063\n",
      "        | \\     )|_\tf1: 0.2080432761597459\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\37 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 28.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         28                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.001923487988314162               |\n",
      "|  noam_learning_rate_warmup   |                        3282                       |\n",
      "|  noam_learning_rate_factor   |                 1.588567958927495                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.14910810898368992                |\n",
      "|     pointwise_layer_size     |                        204                        |\n",
      "|      last_layer_dropout      |                 0.6269594616074423                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 47%|███████████████████▍                     | 71/150 [11:10:03<11:53:45, 542.09s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964c6a9a427d4e988c731527c08b6387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.279\t\t0.869\t\t0.66m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.02\t\t0.370\t\t0.912\t\t0.68m - 1.4m / 23.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.362\t\t0.909\t\t0.69m - 2.1m / 23.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.328\t\t0.896\t\t0.66m - 2.7m / 24.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.334\t\t0.897\t\t0.65m - 3.4m / 23.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.330\t\t0.896\t\t0.66m - 4.1m / 23.1m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.324\t\t0.893\t\t0.66m - 4.8m / 23.1m                                                                   \n",
      "VAL f1\t0.36973400419404545 - (0.36973400419404545)                                                                     \n",
      "VAL loss\t0.013937335336718466                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013937335336718466\n",
      "        | \\     )|_\tf1: 0.36973400419404545\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\38 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 41.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         41                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005913374245154696               |\n",
      "|  noam_learning_rate_warmup   |                        2237                       |\n",
      "|  noam_learning_rate_factor   |                 1.5670772314894101                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.4944120702945318                |\n",
      "|     pointwise_layer_size     |                         70                        |\n",
      "|      last_layer_dropout      |                 0.472087918615409                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 48%|███████████████████▋                     | 72/150 [11:15:23<10:18:01, 475.41s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf693dbab66407a9b8ba8f91531f74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.123\t\t0.794\t\t0.84m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.181\t\t0.841\t\t0.83m - 1.7m / 29.5m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.254\t\t0.890\t\t0.81m - 2.5m / 29.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.270\t\t0.899\t\t0.81m - 3.3m / 28.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.214\t\t0.867\t\t0.83m - 4.2m / 28.3m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.175\t\t0.842\t\t0.85m - 5.1m / 29.2m                                                                   \n",
      "7\t98k\t0.02\t\t0.02\t\t0.099\t\t0.744\t\t0.81m - 5.9m / 29.8m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.105\t\t0.752\t\t0.77m - 6.7m / 28.7m                                                                  \n",
      "9\t127k\t0.02\t\t0.02\t\t0.167\t\t0.830\t\t0.78m - 7.5m / 27.6m                                                                  \n",
      "VAL f1\t0.2702978024901612 - (0.2702978024901612)                                                                       \n",
      "VAL loss\t0.014691323523477809                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014691323523477809\n",
      "        | \\     )|_\tf1: 0.2702978024901612\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\39 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 63.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         63                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.01030162864010051                |\n",
      "|  noam_learning_rate_warmup   |                        1746                       |\n",
      "|  noam_learning_rate_factor   |                 2.1363264701804567                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5348418763420926                |\n",
      "|     pointwise_layer_size     |                        168                        |\n",
      "|      last_layer_dropout      |                 0.7793883165088449                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 49%|███████████████████▉                     | 73/150 [11:23:35<10:16:28, 480.37s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bacf5ded06e42aa89654912ba5e18c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.01\t\t0.097\t\t0.788\t\t0.33m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.111\t\t0.819\t\t0.33m - 0.7m / 11.5m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.147\t\t0.862\t\t0.33m - 1.0m / 11.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.159\t\t0.873\t\t0.33m - 1.4m / 11.6m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.130\t\t0.835\t\t0.34m - 1.7m / 11.6m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.153\t\t0.865\t\t0.34m - 2.1m / 11.9m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.137\t\t0.850\t\t0.33m - 2.4m / 11.9m                                                                   \n",
      "8\t112k\t0.01\t\t0.01\t\t0.156\t\t0.868\t\t0.33m - 2.8m / 11.7m                                                                  \n",
      "9\t126k\t0.00\t\t0.01\t\t0.152\t\t0.868\t\t0.33m - 3.1m / 11.7m                                                                  \n",
      "VAL f1\t0.15863979175639512 - (0.15863979175639512)                                                                     \n",
      "VAL loss\t0.007287349354621293                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.007287349354621293\n",
      "        | \\     )|_\tf1: 0.15863979175639512\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\40 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 55.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         55                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.003191296695247767               |\n",
      "|  noam_learning_rate_warmup   |                        8585                       |\n",
      "|  noam_learning_rate_factor   |                 3.7236460474203676                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.35875105788662326                |\n",
      "|     pointwise_layer_size     |                        179                        |\n",
      "|      last_layer_dropout      |                0.057922180410381864               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 49%|████████████████████▋                     | 74/150 [11:27:07<8:26:30, 399.88s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788e5e478e5478e90194801c50538a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.100\t\t0.793\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.01\t\t0.127\t\t0.831\t\t0.40m - 0.8m / 14.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.122\t\t0.831\t\t0.40m - 1.2m / 14.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.148\t\t0.858\t\t0.39m - 1.6m / 13.9m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.154\t\t0.868\t\t0.39m - 2.1m / 13.6m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.165\t\t0.874\t\t0.40m - 2.5m / 13.9m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.123\t\t0.840\t\t0.40m - 2.9m / 14.1m                                                                   \n",
      "8\t113k\t0.00\t\t0.02\t\t0.141\t\t0.854\t\t0.39m - 3.3m / 14.0m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.164\t\t0.870\t\t0.39m - 3.7m / 13.9m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.141\t\t0.853\t\t0.39m - 4.1m / 13.9m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.162\t\t0.874\t\t0.39m - 4.5m / 13.9m                                                                 \n",
      "VAL f1\t0.16546989545389715 - (0.16546989545389715)                                                                     \n",
      "VAL loss\t0.009729088580969606                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009729088580969606\n",
      "        | \\     )|_\tf1: 0.16546989545389715\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\41 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 28.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         28                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.039610604754566105               |\n",
      "|  noam_learning_rate_warmup   |                        8671                       |\n",
      "|  noam_learning_rate_factor   |                 3.253456665767324                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.23742368151471088                |\n",
      "|     pointwise_layer_size     |                        338                        |\n",
      "|      last_layer_dropout      |                0.18685046751671486                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 50%|█████████████████████                     | 75/150 [11:32:11<7:43:49, 371.06s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0d8abab5d74909be50e01daf25e5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.208\t\t0.822\t\t1.21m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.315\t\t0.888\t\t1.19m - 2.4m / 42.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.321\t\t0.889\t\t1.18m - 3.6m / 41.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.325\t\t0.894\t\t1.24m - 4.9m / 41.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.326\t\t0.893\t\t1.19m - 6.1m / 43.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.304\t\t0.881\t\t1.12m - 7.2m / 41.7m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.313\t\t0.890\t\t1.16m - 8.4m / 39.8m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.269\t\t0.861\t\t1.17m - 9.6m / 40.9m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.232\t\t0.852\t\t1.13m - 10.7m / 41.3m                                                                 \n",
      "10\t141k\t0.01\t\t0.03\t\t0.222\t\t0.840\t\t1.15m - 11.9m / 40.1m                                                                \n",
      "VAL f1\t0.3263667917270864 - (0.3263667917270864)                                                                       \n",
      "VAL loss\t0.014712156673184889                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014712156673184889\n",
      "        | \\     )|_\tf1: 0.3263667917270864\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\42 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 62.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         62                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.028618979985144073               |\n",
      "|  noam_learning_rate_warmup   |                        2616                       |\n",
      "|  noam_learning_rate_factor   |                 3.428560994278079                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7442121988396502                |\n",
      "|     pointwise_layer_size     |                        123                        |\n",
      "|      last_layer_dropout      |                0.32037057040804595                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 51%|████████████████████▊                    | 76/150 [11:44:59<10:04:36, 490.23s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9107962b9b463e89b9333aa618701c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.093\t\t0.787\t\t0.36m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.097\t\t0.793\t\t0.36m - 0.7m / 12.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.098\t\t0.797\t\t0.35m - 1.1m / 12.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.081\t\t0.759\t\t0.35m - 1.5m / 12.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.116\t\t0.814\t\t0.35m - 1.8m / 12.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.117\t\t0.826\t\t0.35m - 2.2m / 12.2m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.102\t\t0.807\t\t0.35m - 2.6m / 12.4m                                                                   \n",
      "8\t113k\t0.01\t\t0.01\t\t0.120\t\t0.823\t\t0.34m - 2.9m / 12.4m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.138\t\t0.848\t\t0.34m - 3.3m / 12.3m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.132\t\t0.840\t\t0.34m - 3.6m / 12.1m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.143\t\t0.852\t\t0.34m - 4.0m / 12.3m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.136\t\t0.844\t\t0.34m - 4.4m / 12.1m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.132\t\t0.839\t\t0.34m - 4.7m / 12.2m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.119\t\t0.833\t\t0.33m - 5.0m / 12.1m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.117\t\t0.838\t\t0.34m - 5.4m / 12.0m                                                                 \n",
      "16\t225k\t0.01\t\t0.02\t\t0.114\t\t0.829\t\t0.36m - 5.8m / 12.1m                                                                 \n",
      "VAL f1\t0.14328050287769276 - (0.14328050287769276)                                                                     \n",
      "VAL loss\t0.013927321370897394                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013927321370897394\n",
      "        | \\     )|_\tf1: 0.14328050287769276\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\43 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 12.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         12                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00973442757147185                |\n",
      "|  noam_learning_rate_warmup   |                        7093                       |\n",
      "|  noam_learning_rate_factor   |                 2.6987561994704397                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.40778124125647175                |\n",
      "|     pointwise_layer_size     |                        305                        |\n",
      "|      last_layer_dropout      |                 0.7753005612559325                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 51%|█████████████████████▌                    | 77/150 [11:51:21<9:16:38, 457.52s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9d69c551ca4c58863789b1557c9a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.06\t\t0.407\t\t0.838\t\t1.82m - 1.8m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.04\t\t0.570\t\t0.910\t\t1.76m - 3.6m / 63.8m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.477\t\t0.870\t\t1.73m - 5.3m / 61.7m                                                                   \n",
      "4\t56k\t0.05\t\t0.07\t\t0.390\t\t0.824\t\t1.69m - 7.1m / 60.8m                                                                   \n",
      "5\t70k\t0.07\t\t0.09\t\t0.362\t\t0.814\t\t1.69m - 8.8m / 59.6m                                                                   \n",
      "6\t84k\t0.09\t\t0.12\t\t0.267\t\t0.754\t\t1.69m - 10.5m / 59.6m                                                                  \n",
      "7\t98k\t0.11\t\t0.13\t\t0.382\t\t0.820\t\t1.70m - 12.2m / 59.6m                                                                  \n",
      "VAL f1\t0.5696803048130338 - (0.5696803048130338)                                                                       \n",
      "VAL loss\t0.04124798052444502                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04124798052444502\n",
      "        | \\     )|_\tf1: 0.5696803048130338\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\44 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 12.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         12                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0018875758037523922               |\n",
      "|  noam_learning_rate_warmup   |                        4076                       |\n",
      "|  noam_learning_rate_factor   |                 0.9761928868122869                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.42938751129619945                |\n",
      "|     pointwise_layer_size     |                        304                        |\n",
      "|      last_layer_dropout      |                0.15222752222023478                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 52%|█████████████████████▎                   | 78/150 [12:04:42<11:12:56, 560.79s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7767aef6dab2409782842fa8b74f5504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.05\t\t0.465\t\t0.866\t\t0.85m - 0.9m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.05\t\t0.537\t\t0.899\t\t0.86m - 1.7m / 29.8m                                                                   \n",
      "3\t42k\t0.03\t\t0.05\t\t0.447\t\t0.868\t\t0.87m - 2.6m / 30.1m                                                                   \n",
      "4\t56k\t0.03\t\t0.05\t\t0.530\t\t0.901\t\t0.81m - 3.5m / 30.4m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.614\t\t0.924\t\t0.81m - 4.3m / 28.6m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.548\t\t0.908\t\t0.80m - 5.1m / 28.5m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.594\t\t0.921\t\t0.82m - 5.9m / 28.2m                                                                   \n",
      "8\t112k\t0.03\t\t0.04\t\t0.559\t\t0.914\t\t0.82m - 6.8m / 28.9m                                                                  \n",
      "9\t126k\t0.03\t\t0.05\t\t0.510\t\t0.897\t\t0.81m - 7.6m / 29.0m                                                                  \n",
      "10\t141k\t0.03\t\t0.04\t\t0.537\t\t0.903\t\t0.81m - 8.4m / 28.6m                                                                 \n",
      "VAL f1\t0.6144146470535107 - (0.6144146470535107)                                                                       \n",
      "VAL loss\t0.039927664930848594                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.039927664930848594\n",
      "        | \\     )|_\tf1: 0.6144146470535107\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\45 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 44.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         44                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.08124207528408069                |\n",
      "|  noam_learning_rate_warmup   |                        3403                       |\n",
      "|  noam_learning_rate_factor   |                 2.426559981495885                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.25323810749374837                |\n",
      "|     pointwise_layer_size     |                        305                        |\n",
      "|      last_layer_dropout      |                0.17633148288477926                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 53%|█████████████████████▌                   | 79/150 [12:13:59<11:02:06, 559.53s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f0621ffb304047bf3255200a0606a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.141\t\t0.818\t\t0.47m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.198\t\t0.873\t\t0.48m - 1.0m / 16.5m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.188\t\t0.867\t\t0.47m - 1.5m / 16.9m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.214\t\t0.883\t\t0.46m - 1.9m / 16.5m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.218\t\t0.887\t\t0.46m - 2.4m / 16.1m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.211\t\t0.881\t\t0.46m - 2.9m / 16.2m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.200\t\t0.875\t\t0.45m - 3.4m / 16.2m                                                                   \n",
      "8\t113k\t0.01\t\t0.01\t\t0.204\t\t0.878\t\t0.46m - 3.8m / 16.0m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.187\t\t0.865\t\t0.45m - 4.3m / 16.2m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.191\t\t0.865\t\t0.47m - 4.8m / 16.1m                                                                 \n",
      "VAL f1\t0.21833722871680722 - (0.21833722871680722)                                                                     \n",
      "VAL loss\t0.00996741487619442                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.00996741487619442\n",
      "        | \\     )|_\tf1: 0.21833722871680722\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\46 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 30.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         30                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.16471156000117204                |\n",
      "|  noam_learning_rate_warmup   |                        3732                       |\n",
      "|  noam_learning_rate_factor   |                0.01662344099158767                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.5136825807712938                |\n",
      "|     pointwise_layer_size     |                        141                        |\n",
      "|      last_layer_dropout      |                 0.7938197206124505                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 53%|██████████████████████▍                   | 80/150 [12:19:22<9:30:04, 488.63s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8870c93c6c44ea91bb94db1e2b0cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.07\t\t0.197\t\t0.809\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.06\t\t0.196\t\t0.815\t\t0.41m - 0.8m / 14.4m                                                                   \n",
      "3\t42k\t0.06\t\t0.06\t\t0.196\t\t0.815\t\t0.41m - 1.3m / 14.5m                                                                   \n",
      "4\t56k\t0.05\t\t0.05\t\t0.196\t\t0.815\t\t0.40m - 1.7m / 14.4m                                                                   \n",
      "5\t70k\t0.05\t\t0.05\t\t0.196\t\t0.815\t\t0.41m - 2.1m / 14.2m                                                                   \n",
      "6\t84k\t0.05\t\t0.04\t\t0.198\t\t0.817\t\t0.43m - 2.5m / 14.3m                                                                   \n",
      "7\t98k\t0.04\t\t0.04\t\t0.228\t\t0.839\t\t0.39m - 3.0m / 14.9m                                                                   \n",
      "8\t113k\t0.04\t\t0.03\t\t0.240\t\t0.848\t\t0.43m - 3.4m / 14.0m                                                                  \n",
      "9\t127k\t0.04\t\t0.03\t\t0.254\t\t0.859\t\t0.42m - 3.8m / 15.1m                                                                  \n",
      "10\t141k\t0.04\t\t0.03\t\t0.267\t\t0.868\t\t0.42m - 4.3m / 14.9m                                                                 \n",
      "11\t155k\t0.03\t\t0.03\t\t0.273\t\t0.872\t\t0.41m - 4.7m / 14.8m                                                                 \n",
      "12\t169k\t0.03\t\t0.03\t\t0.278\t\t0.874\t\t0.41m - 5.2m / 14.6m                                                                 \n",
      "13\t183k\t0.03\t\t0.03\t\t0.283\t\t0.878\t\t0.42m - 5.6m / 14.6m                                                                 \n",
      "14\t197k\t0.03\t\t0.03\t\t0.291\t\t0.881\t\t0.40m - 6.1m / 14.9m                                                                 \n",
      "15\t211k\t0.03\t\t0.03\t\t0.295\t\t0.883\t\t0.39m - 6.5m / 14.4m                                                                 \n",
      "16\t225k\t0.02\t\t0.03\t\t0.295\t\t0.883\t\t0.39m - 6.9m / 14.3m                                                                 \n",
      "17\t239k\t0.02\t\t0.03\t\t0.297\t\t0.883\t\t0.39m - 7.3m / 14.2m                                                                 \n",
      "18\t253k\t0.02\t\t0.03\t\t0.300\t\t0.885\t\t0.39m - 7.7m / 14.3m                                                                 \n",
      "19\t267k\t0.02\t\t0.03\t\t0.304\t\t0.887\t\t0.39m - 8.1m / 14.3m                                                                 \n",
      "20\t281k\t0.02\t\t0.03\t\t0.306\t\t0.887\t\t0.39m - 8.5m / 14.3m                                                                 \n",
      "21\t295k\t0.02\t\t0.03\t\t0.303\t\t0.885\t\t0.39m - 8.9m / 14.4m                                                                 \n",
      "22\t310k\t0.02\t\t0.03\t\t0.303\t\t0.885\t\t0.39m - 9.3m / 14.4m                                                                 \n",
      "23\t324k\t0.02\t\t0.03\t\t0.302\t\t0.884\t\t0.39m - 9.7m / 14.4m                                                                 \n",
      "24\t338k\t0.02\t\t0.03\t\t0.305\t\t0.885\t\t0.39m - 10.1m / 14.4m                                                                \n",
      "25\t352k\t0.02\t\t0.03\t\t0.306\t\t0.886\t\t0.39m - 10.5m / 14.4m                                                                \n",
      "VAL f1\t0.30613104652188466 - (0.30613104652188466)                                                                     \n",
      "VAL loss\t0.027298053710319854                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.027298053710319854\n",
      "        | \\     )|_\tf1: 0.30613104652188466\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\47 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 17.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         17                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.31269205961082164                |\n",
      "|  noam_learning_rate_warmup   |                        8197                       |\n",
      "|  noam_learning_rate_factor   |                 2.5812274251697946                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6155188101778354                |\n",
      "|     pointwise_layer_size     |                        108                        |\n",
      "|      last_layer_dropout      |                 0.6545770852470931                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 54%|██████████████████████▏                  | 81/150 [12:30:29<10:23:37, 542.29s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c7077c43094f3b9c1a7ab91638e970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.06\t\t0.384\t\t0.865\t\t0.60m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.07\t\t0.354\t\t0.851\t\t0.61m - 1.3m / 21.1m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.383\t\t0.867\t\t0.60m - 1.9m / 21.5m                                                                   \n",
      "4\t56k\t0.03\t\t0.05\t\t0.406\t\t0.877\t\t0.62m - 2.5m / 21.2m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.468\t\t0.903\t\t0.60m - 3.1m / 21.7m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.473\t\t0.905\t\t0.59m - 3.7m / 21.2m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.350\t\t0.865\t\t0.62m - 4.4m / 20.8m                                                                   \n",
      "8\t112k\t0.03\t\t0.05\t\t0.337\t\t0.854\t\t0.61m - 5.0m / 21.9m                                                                  \n",
      "9\t126k\t0.04\t\t0.05\t\t0.406\t\t0.887\t\t0.61m - 5.6m / 21.5m                                                                  \n",
      "10\t140k\t0.04\t\t0.06\t\t0.347\t\t0.853\t\t0.58m - 6.2m / 21.4m                                                                 \n",
      "11\t154k\t0.04\t\t0.05\t\t0.359\t\t0.866\t\t0.57m - 6.8m / 20.8m                                                                 \n",
      "VAL f1\t0.47343879819309476 - (0.47343879819309476)                                                                     \n",
      "VAL loss\t0.038836054547288106                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.038836054547288106\n",
      "        | \\     )|_\tf1: 0.47343879819309476\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\48 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 30.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         30                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0004803033001218535               |\n",
      "|  noam_learning_rate_warmup   |                        2511                       |\n",
      "|  noam_learning_rate_factor   |                 2.9271816194645637                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.48210938462828345                |\n",
      "|     pointwise_layer_size     |                        184                        |\n",
      "|      last_layer_dropout      |                 0.3563814222051869                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 55%|██████████████████████▉                   | 82/150 [12:37:59<9:43:12, 514.59s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d1d44dd8894b5e9cdfa1b8cdb2e2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.242\t\t0.852\t\t0.85m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.299\t\t0.884\t\t0.86m - 1.7m / 29.7m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.280\t\t0.873\t\t0.85m - 2.6m / 30.0m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.142\t\t0.765\t\t0.87m - 3.5m / 29.8m                                                                   \n",
      "5\t70k\t0.04\t\t0.05\t\t0.179\t\t0.805\t\t0.89m - 4.4m / 30.4m                                                                   \n",
      "6\t84k\t0.05\t\t0.05\t\t0.196\t\t0.815\t\t0.85m - 5.2m / 31.0m                                                                   \n",
      "7\t98k\t0.05\t\t0.05\t\t0.196\t\t0.815\t\t0.84m - 6.1m / 30.0m                                                                   \n",
      "VAL f1\t0.29903744523098597 - (0.29903744523098597)                                                                     \n",
      "VAL loss\t0.019000788904521445                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.019000788904521445\n",
      "        | \\     )|_\tf1: 0.29903744523098597\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\49 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 21.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         21                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.003048590555094232               |\n",
      "|  noam_learning_rate_warmup   |                        5120                       |\n",
      "|  noam_learning_rate_factor   |                 1.2350155635559013                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7454204450455558                |\n",
      "|     pointwise_layer_size     |                        117                        |\n",
      "|      last_layer_dropout      |                0.14362453068312614                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 55%|███████████████████████▏                  | 83/150 [12:44:45<8:58:11, 481.97s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08075172904f128d925bdf62f12b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.09\t\t0.08\t\t0.254\t\t0.814\t\t1.43m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.08\t\t0.254\t\t0.814\t\t1.39m - 2.8m / 50.1m                                                                   \n",
      "3\t42k\t0.07\t\t0.08\t\t0.222\t\t0.788\t\t1.39m - 4.2m / 48.6m                                                                   \n",
      "4\t56k\t0.06\t\t0.08\t\t0.077\t\t0.673\t\t1.44m - 5.7m / 48.6m                                                                   \n",
      "5\t70k\t0.06\t\t0.08\t\t0.119\t\t0.738\t\t1.42m - 7.1m / 50.4m                                                                   \n",
      "6\t84k\t0.06\t\t0.08\t\t0.074\t\t0.698\t\t1.38m - 8.5m / 49.9m                                                                   \n",
      "VAL f1\t0.2537352115376537 - (0.2537352115376537)                                                                       \n",
      "VAL loss\t0.0768694028693227                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0768694028693227\n",
      "        | \\     )|_\tf1: 0.2537352115376537\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\50 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 63.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         63                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.000802111444411791               |\n",
      "|  noam_learning_rate_warmup   |                        3144                       |\n",
      "|  noam_learning_rate_factor   |                 0.9388360141549061                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7611781568811192                |\n",
      "|     pointwise_layer_size     |                        315                        |\n",
      "|      last_layer_dropout      |                 0.3834470051218225                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 56%|███████████████████████▌                  | 84/150 [12:54:18<9:20:11, 509.27s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8b3c0c646c4170a82a7adb74dc4e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.04\t\t0.089\t\t0.783\t\t0.22m - 0.2m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.089\t\t0.783\t\t0.23m - 0.5m / 7.8m                                                                    \n",
      "3\t42k\t0.02\t\t0.02\t\t0.095\t\t0.791\t\t0.22m - 0.7m / 7.9m                                                                    \n",
      "4\t56k\t0.02\t\t0.02\t\t0.103\t\t0.807\t\t0.22m - 0.9m / 7.9m                                                                    \n",
      "5\t70k\t0.02\t\t0.02\t\t0.098\t\t0.801\t\t0.23m - 1.2m / 7.9m                                                                    \n",
      "6\t84k\t0.01\t\t0.03\t\t0.094\t\t0.786\t\t0.22m - 1.4m / 8.0m                                                                    \n",
      "7\t98k\t0.01\t\t0.02\t\t0.115\t\t0.825\t\t0.22m - 1.7m / 7.8m                                                                    \n",
      "8\t112k\t0.01\t\t0.02\t\t0.126\t\t0.837\t\t0.22m - 1.9m / 7.8m                                                                   \n",
      "9\t126k\t0.01\t\t0.02\t\t0.130\t\t0.841\t\t0.22m - 2.1m / 7.9m                                                                   \n",
      "10\t140k\t0.01\t\t0.01\t\t0.144\t\t0.859\t\t0.22m - 2.4m / 7.8m                                                                  \n",
      "11\t155k\t0.01\t\t0.02\t\t0.140\t\t0.854\t\t0.22m - 2.7m / 7.9m                                                                  \n",
      "12\t169k\t0.01\t\t0.02\t\t0.148\t\t0.862\t\t0.23m - 2.9m / 8.0m                                                                  \n",
      "13\t183k\t0.01\t\t0.02\t\t0.149\t\t0.864\t\t0.22m - 3.1m / 8.2m                                                                  \n",
      "14\t197k\t0.01\t\t0.02\t\t0.134\t\t0.850\t\t0.21m - 3.4m / 8.0m                                                                  \n",
      "15\t211k\t0.00\t\t0.02\t\t0.141\t\t0.856\t\t0.22m - 3.6m / 7.9m                                                                  \n",
      "16\t225k\t0.00\t\t0.02\t\t0.134\t\t0.849\t\t0.22m - 3.8m / 8.0m                                                                  \n",
      "17\t239k\t0.00\t\t0.02\t\t0.122\t\t0.835\t\t0.22m - 4.1m / 8.0m                                                                  \n",
      "18\t253k\t0.00\t\t0.02\t\t0.131\t\t0.846\t\t0.22m - 4.3m / 8.0m                                                                  \n",
      "VAL f1\t0.14894337385468673 - (0.14894337385468673)                                                                     \n",
      "VAL loss\t0.014602997834920447                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014602997834920447\n",
      "        | \\     )|_\tf1: 0.14894337385468673\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\51 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 19.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         19                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04137818995144106                |\n",
      "|  noam_learning_rate_warmup   |                        5474                       |\n",
      "|  noam_learning_rate_factor   |                 0.1364074253661281                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.36540229373768024                |\n",
      "|     pointwise_layer_size     |                        268                        |\n",
      "|      last_layer_dropout      |                 0.5439239326258017                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 57%|███████████████████████▊                  | 85/150 [12:59:00<7:57:48, 441.06s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad5bee5862546428324f770632df081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.07\t\t0.270\t\t0.813\t\t1.16m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.08\t\t0.06\t\t0.238\t\t0.796\t\t1.15m - 2.3m / 40.6m                                                                   \n",
      "3\t42k\t0.06\t\t0.05\t\t0.291\t\t0.831\t\t1.14m - 3.5m / 40.2m                                                                   \n",
      "4\t56k\t0.04\t\t0.05\t\t0.351\t\t0.869\t\t1.10m - 4.6m / 40.0m                                                                   \n",
      "5\t70k\t0.03\t\t0.06\t\t0.342\t\t0.860\t\t1.17m - 5.8m / 38.8m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.325\t\t0.849\t\t1.18m - 7.0m / 40.8m                                                                   \n",
      "7\t98k\t0.02\t\t0.04\t\t0.387\t\t0.882\t\t1.18m - 8.2m / 41.3m                                                                   \n",
      "8\t112k\t0.02\t\t0.04\t\t0.330\t\t0.852\t\t1.10m - 9.3m / 41.2m                                                                  \n",
      "9\t126k\t0.02\t\t0.03\t\t0.396\t\t0.886\t\t1.10m - 10.4m / 39.0m                                                                 \n",
      "10\t140k\t0.02\t\t0.03\t\t0.398\t\t0.888\t\t1.09m - 11.5m / 39.0m                                                                \n",
      "11\t154k\t0.02\t\t0.04\t\t0.395\t\t0.887\t\t1.10m - 12.6m / 38.8m                                                                \n",
      "12\t168k\t0.01\t\t0.04\t\t0.437\t\t0.903\t\t1.11m - 13.8m / 39.0m                                                                \n",
      "13\t183k\t0.01\t\t0.04\t\t0.400\t\t0.890\t\t1.09m - 14.9m / 39.4m                                                                \n",
      "14\t197k\t0.01\t\t0.04\t\t0.406\t\t0.891\t\t1.08m - 16.0m / 38.8m                                                                \n",
      "15\t211k\t0.01\t\t0.03\t\t0.422\t\t0.899\t\t1.09m - 17.1m / 38.8m                                                                \n",
      "16\t225k\t0.01\t\t0.04\t\t0.418\t\t0.896\t\t1.08m - 18.2m / 38.8m                                                                \n",
      "17\t239k\t0.01\t\t0.04\t\t0.438\t\t0.905\t\t1.08m - 19.3m / 38.8m                                                                \n",
      "18\t253k\t0.01\t\t0.03\t\t0.452\t\t0.909\t\t1.07m - 20.4m / 38.8m                                                                \n",
      "19\t267k\t0.01\t\t0.04\t\t0.409\t\t0.894\t\t1.10m - 21.5m / 38.6m                                                                \n",
      "20\t281k\t0.01\t\t0.04\t\t0.415\t\t0.896\t\t1.08m - 22.6m / 39.2m                                                                \n",
      "21\t295k\t0.01\t\t0.04\t\t0.435\t\t0.902\t\t1.13m - 23.7m / 38.7m                                                                \n",
      "22\t309k\t0.01\t\t0.05\t\t0.421\t\t0.897\t\t1.14m - 24.9m / 39.6m                                                                \n",
      "23\t323k\t0.01\t\t0.05\t\t0.436\t\t0.904\t\t1.10m - 26.0m / 39.8m                                                                \n",
      "VAL f1\t0.4515873610600502 - (0.4515873610600502)                                                                       \n",
      "VAL loss\t0.0292572518742234                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0292572518742234\n",
      "        | \\     )|_\tf1: 0.4515873610600502\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\52 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.002253382196619477               |\n",
      "|  noam_learning_rate_warmup   |                        3839                       |\n",
      "|  noam_learning_rate_factor   |                 3.8682286834675126                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.1266366217018561                |\n",
      "|     pointwise_layer_size     |                        323                        |\n",
      "|      last_layer_dropout      |                 0.6554423051799517                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 57%|███████████████████████▌                 | 86/150 [13:25:55<14:06:04, 793.19s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7a933a8d814087963fea65d04525c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.367\t\t0.868\t\t0.64m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.500\t\t0.910\t\t0.64m - 1.3m / 22.5m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.507\t\t0.911\t\t0.63m - 2.0m / 22.5m                                                                   \n",
      "4\t56k\t0.02\t\t0.04\t\t0.438\t\t0.886\t\t0.63m - 2.6m / 22.2m                                                                   \n",
      "5\t70k\t0.03\t\t0.04\t\t0.475\t\t0.902\t\t0.64m - 3.3m / 22.1m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.433\t\t0.885\t\t0.65m - 3.9m / 22.4m                                                                   \n",
      "7\t98k\t0.03\t\t0.04\t\t0.443\t\t0.891\t\t0.62m - 4.5m / 22.7m                                                                   \n",
      "8\t112k\t0.03\t\t0.04\t\t0.430\t\t0.884\t\t0.64m - 5.2m / 22.0m                                                                  \n",
      "VAL f1\t0.5073215238484255 - (0.5073215238484255)                                                                       \n",
      "VAL loss\t0.02837394284485045                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02837394284485045\n",
      "        | \\     )|_\tf1: 0.5073215238484255\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\53 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 57.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         57                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03879427485744938                |\n",
      "|  noam_learning_rate_warmup   |                        8169                       |\n",
      "|  noam_learning_rate_factor   |                 1.4482206723164346                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.5083537036016336                |\n",
      "|     pointwise_layer_size     |                        266                        |\n",
      "|      last_layer_dropout      |                 0.6370210167558114                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 58%|███████████████████████▊                 | 87/150 [13:31:48<11:34:13, 661.17s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521c192b5e4749e69483d20a356225f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.084\t\t0.768\t\t0.38m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.089\t\t0.775\t\t0.38m - 0.8m / 13.2m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.084\t\t0.760\t\t0.38m - 1.2m / 13.2m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.083\t\t0.763\t\t0.37m - 1.5m / 13.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.090\t\t0.779\t\t0.38m - 1.9m / 13.0m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.094\t\t0.785\t\t0.38m - 2.3m / 13.3m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.090\t\t0.780\t\t0.37m - 2.7m / 13.3m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.090\t\t0.789\t\t0.38m - 3.1m / 13.1m                                                                  \n",
      "9\t127k\t0.00\t\t0.02\t\t0.095\t\t0.791\t\t0.37m - 3.5m / 13.3m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.094\t\t0.797\t\t0.38m - 3.9m / 13.2m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.099\t\t0.798\t\t0.37m - 4.3m / 13.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.02\t\t0.108\t\t0.815\t\t0.37m - 4.7m / 13.3m                                                                 \n",
      "13\t183k\t0.00\t\t0.02\t\t0.098\t\t0.808\t\t0.38m - 5.1m / 13.2m                                                                 \n",
      "14\t197k\t0.00\t\t0.02\t\t0.118\t\t0.829\t\t0.38m - 5.5m / 13.4m                                                                 \n",
      "15\t211k\t0.00\t\t0.02\t\t0.115\t\t0.832\t\t0.36m - 5.8m / 13.5m                                                                 \n",
      "16\t225k\t0.00\t\t0.02\t\t0.116\t\t0.829\t\t0.37m - 6.2m / 13.1m                                                                 \n",
      "17\t239k\t0.00\t\t0.02\t\t0.123\t\t0.837\t\t0.36m - 6.6m / 13.3m                                                                 \n",
      "18\t253k\t0.00\t\t0.01\t\t0.129\t\t0.844\t\t0.39m - 7.0m / 13.2m                                                                 \n",
      "19\t268k\t0.00\t\t0.02\t\t0.112\t\t0.823\t\t0.38m - 7.4m / 13.6m                                                                 \n",
      "20\t282k\t0.00\t\t0.02\t\t0.127\t\t0.843\t\t0.38m - 7.8m / 13.5m                                                                 \n",
      "21\t296k\t0.00\t\t0.02\t\t0.125\t\t0.844\t\t0.38m - 8.2m / 13.5m                                                                 \n",
      "22\t310k\t0.00\t\t0.02\t\t0.127\t\t0.843\t\t0.37m - 8.6m / 13.6m                                                                 \n",
      "23\t324k\t0.00\t\t0.01\t\t0.127\t\t0.843\t\t0.38m - 9.0m / 13.5m                                                                 \n",
      "VAL f1\t0.12866768181647978 - (0.12866768181647978)                                                                     \n",
      "VAL loss\t0.014525603417913372                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.014525603417913372\n",
      "        | \\     )|_\tf1: 0.12866768181647978\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\54 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 15.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         15                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.011816177179661928               |\n",
      "|  noam_learning_rate_warmup   |                        7804                       |\n",
      "|  noam_learning_rate_factor   |                 2.441985628183576                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.4554944181808295                |\n",
      "|     pointwise_layer_size     |                         49                        |\n",
      "|      last_layer_dropout      |                0.36070888386500644                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 59%|████████████████████████                 | 88/150 [13:41:19<10:55:13, 634.08s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5633d2dca0f4e77a30e05041c18e393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.10\t\t0.07\t\t0.244\t\t0.759\t\t1.79m - 1.8m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.05\t\t0.414\t\t0.861\t\t1.82m - 3.6m / 62.6m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.508\t\t0.901\t\t1.76m - 5.4m / 63.6m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.422\t\t0.872\t\t1.77m - 7.2m / 61.7m                                                                   \n",
      "5\t70k\t0.03\t\t0.05\t\t0.428\t\t0.867\t\t1.89m - 9.1m / 62.1m                                                                   \n",
      "6\t84k\t0.04\t\t0.05\t\t0.442\t\t0.874\t\t1.86m - 11.0m / 65.8m                                                                  \n",
      "7\t98k\t0.04\t\t0.06\t\t0.442\t\t0.877\t\t1.76m - 12.7m / 64.8m                                                                  \n",
      "8\t112k\t0.05\t\t0.06\t\t0.398\t\t0.859\t\t1.77m - 14.5m / 62.1m                                                                 \n",
      "VAL f1\t0.5076315037706023 - (0.5076315037706023)                                                                       \n",
      "VAL loss\t0.04000480127407841                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04000480127407841\n",
      "        | \\     )|_\tf1: 0.5076315037706023\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\55 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 23.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         23                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.00248919706126079                |\n",
      "|  noam_learning_rate_warmup   |                        4227                       |\n",
      "|  noam_learning_rate_factor   |                  0.49685083617259                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.16343185384158732                |\n",
      "|     pointwise_layer_size     |                        163                        |\n",
      "|      last_layer_dropout      |                0.16586470485595656                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 59%|████████████████████████▎                | 89/150 [13:57:01<12:18:36, 726.49s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c89cf775a845e2a634183a2c2f21f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.05\t\t0.300\t\t0.847\t\t0.73m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.387\t\t0.893\t\t0.75m - 1.5m / 25.7m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.460\t\t0.919\t\t0.74m - 2.3m / 26.1m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.420\t\t0.906\t\t0.74m - 3.0m / 25.9m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.407\t\t0.905\t\t0.75m - 3.8m / 26.0m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.371\t\t0.891\t\t0.74m - 4.5m / 26.4m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.450\t\t0.918\t\t0.75m - 5.3m / 26.1m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.453\t\t0.920\t\t0.75m - 6.1m / 26.2m                                                                  \n",
      "VAL f1\t0.45991598682585433 - (0.45991598682585433)                                                                     \n",
      "VAL loss\t0.017092033384615343                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.017092033384615343\n",
      "        | \\     )|_\tf1: 0.45991598682585433\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\56 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 14.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         14                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.0437940009802894                |\n",
      "|  noam_learning_rate_warmup   |                        3633                       |\n",
      "|  noam_learning_rate_factor   |                 2.846904406426119                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.3991376964160789                |\n",
      "|     pointwise_layer_size     |                         93                        |\n",
      "|      last_layer_dropout      |                0.21455499806664033                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 60%|████████████████████████▌                | 90/150 [14:03:41<10:28:35, 628.60s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78ab44834ee433b93dd4eb3a775e82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.04\t\t0.447\t\t0.874\t\t1.13m - 1.1m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.05\t\t0.481\t\t0.891\t\t1.18m - 2.3m / 39.7m                                                                   \n",
      "3\t42k\t0.05\t\t0.08\t\t0.407\t\t0.853\t\t1.11m - 3.5m / 41.4m                                                                   \n",
      "4\t56k\t0.07\t\t0.07\t\t0.217\t\t0.749\t\t1.08m - 4.6m / 39.0m                                                                   \n",
      "5\t70k\t0.07\t\t0.08\t\t0.358\t\t0.833\t\t1.09m - 5.7m / 38.0m                                                                   \n",
      "6\t84k\t0.07\t\t0.07\t\t0.381\t\t0.843\t\t1.08m - 6.8m / 38.4m                                                                   \n",
      "7\t98k\t0.06\t\t0.07\t\t0.363\t\t0.830\t\t1.09m - 7.9m / 38.2m                                                                   \n",
      "VAL f1\t0.4811716721928253 - (0.4811716721928253)                                                                       \n",
      "VAL loss\t0.04210171443915565                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04210171443915565\n",
      "        | \\     )|_\tf1: 0.4811716721928253\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\57 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 54.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         54                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.02802740356378225                |\n",
      "|  noam_learning_rate_warmup   |                        7514                       |\n",
      "|  noam_learning_rate_factor   |                 3.851456165200205                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.05581548683831557                |\n",
      "|     pointwise_layer_size     |                        117                        |\n",
      "|      last_layer_dropout      |                0.28690108212589055                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 61%|█████████████████████████▍                | 91/150 [14:12:22<9:46:18, 596.25s/it, best loss: 0.007256374223039066]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447fee0589ec4abcb3e1c8be2d21755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.01\t\t0.153\t\t0.848\t\t0.38m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.201\t\t0.889\t\t0.38m - 0.8m / 13.3m                                                                   \n",
      "3\t42k\t0.00\t\t0.01\t\t0.222\t\t0.901\t\t0.36m - 1.2m / 13.3m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.194\t\t0.887\t\t0.38m - 1.6m / 12.7m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.204\t\t0.894\t\t0.39m - 2.0m / 13.3m                                                                   \n",
      "6\t85k\t0.00\t\t0.01\t\t0.217\t\t0.900\t\t0.37m - 2.3m / 13.7m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.217\t\t0.901\t\t0.37m - 2.7m / 13.2m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.208\t\t0.896\t\t0.37m - 3.1m / 13.2m                                                                  \n",
      "VAL f1\t0.22152803372668853 - (0.22152803372668853)                                                                     \n",
      "VAL loss\t0.007194733719890525                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.007194733719890525\n",
      "        | \\     )|_\tf1: 0.22152803372668853\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\58 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 45.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         45                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.011387235979707243               |\n",
      "|  noam_learning_rate_warmup   |                        6991                       |\n",
      "|  noam_learning_rate_factor   |                 3.874384128066393                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.004501899611920557               |\n",
      "|     pointwise_layer_size     |                        189                        |\n",
      "|      last_layer_dropout      |                0.33326733263108316                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 61%|█████████████████████████▊                | 92/150 [14:16:02<7:47:16, 483.38s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2c01d7f01244c3aa3a1a79e62be3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.164\t\t0.832\t\t0.73m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.195\t\t0.863\t\t0.74m - 1.5m / 25.6m                                                                   \n",
      "3\t42k\t0.00\t\t0.01\t\t0.186\t\t0.858\t\t0.72m - 2.2m / 26.1m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.243\t\t0.894\t\t0.73m - 3.0m / 25.4m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.249\t\t0.898\t\t0.73m - 3.7m / 25.7m                                                                   \n",
      "6\t85k\t0.00\t\t0.01\t\t0.291\t\t0.913\t\t0.73m - 4.5m / 25.6m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.249\t\t0.895\t\t0.78m - 5.3m / 25.8m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.296\t\t0.918\t\t0.78m - 6.1m / 27.1m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.275\t\t0.910\t\t0.75m - 6.9m / 27.2m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.207\t\t0.876\t\t0.72m - 7.6m / 26.4m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.197\t\t0.867\t\t0.71m - 8.3m / 25.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.268\t\t0.908\t\t0.71m - 9.0m / 25.4m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.207\t\t0.884\t\t0.70m - 9.8m / 25.4m                                                                 \n",
      "VAL f1\t0.29596550490291285 - (0.29596550490291285)                                                                     \n",
      "VAL loss\t0.008538318609129894                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.008538318609129894\n",
      "        | \\     )|_\tf1: 0.29596550490291285\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\59 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 35.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         35                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0003027564740582469               |\n",
      "|  noam_learning_rate_warmup   |                        2697                       |\n",
      "|  noam_learning_rate_factor   |                 3.624503918985611                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.4791223879567852                |\n",
      "|     pointwise_layer_size     |                        342                        |\n",
      "|      last_layer_dropout      |                0.057728610967172855               |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 62%|██████████████████████████                | 93/150 [14:26:22<8:18:07, 524.35s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1b01e6e2fa45378661ca6081b8d04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.252\t\t0.879\t\t0.35m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.02\t\t0.275\t\t0.893\t\t0.35m - 0.7m / 12.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.174\t\t0.835\t\t0.35m - 1.1m / 12.3m                                                                   \n",
      "4\t56k\t0.01\t\t0.03\t\t0.154\t\t0.806\t\t0.36m - 1.5m / 12.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.03\t\t0.168\t\t0.826\t\t0.36m - 1.8m / 12.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.180\t\t0.832\t\t0.35m - 2.2m / 12.6m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.172\t\t0.832\t\t0.35m - 2.6m / 12.3m                                                                   \n",
      "VAL f1\t0.27513112287593555 - (0.27513112287593555)                                                                     \n",
      "VAL loss\t0.01844908297147756                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01844908297147756\n",
      "        | \\     )|_\tf1: 0.27513112287593555\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\60 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 29.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         29                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.08608840120074937                |\n",
      "|  noam_learning_rate_warmup   |                        4531                       |\n",
      "|  noam_learning_rate_factor   |                 2.1582342570180315                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.022231555023905527               |\n",
      "|     pointwise_layer_size     |                        203                        |\n",
      "|      last_layer_dropout      |                0.10502272541070799                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 63%|██████████████████████████▎               | 94/150 [14:29:21<6:32:48, 420.87s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7113725b2eb24c53bcc01dc6ee19191e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.305\t\t0.887\t\t1.02m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.279\t\t0.875\t\t0.98m - 2.0m / 35.9m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.374\t\t0.915\t\t0.92m - 3.0m / 34.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.339\t\t0.903\t\t0.92m - 3.9m / 32.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.253\t\t0.861\t\t0.94m - 4.9m / 32.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.335\t\t0.898\t\t0.91m - 5.8m / 33.0m                                                                   \n",
      "7\t98k\t0.01\t\t0.01\t\t0.314\t\t0.892\t\t0.92m - 6.7m / 32.2m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.317\t\t0.894\t\t0.93m - 7.7m / 32.5m                                                                  \n",
      "VAL f1\t0.37367259653880275 - (0.37367259653880275)                                                                     \n",
      "VAL loss\t0.012197696224712165                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012197696224712165\n",
      "        | \\     )|_\tf1: 0.37367259653880275\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\61 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 50.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         50                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005580681224373418               |\n",
      "|  noam_learning_rate_warmup   |                        5078                       |\n",
      "|  noam_learning_rate_factor   |                 1.123451136850691                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.608303303319786                 |\n",
      "|     pointwise_layer_size     |                        111                        |\n",
      "|      last_layer_dropout      |                 0.4022149142242942                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 63%|██████████████████████████▌               | 95/150 [14:37:40<6:47:16, 444.30s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c0a3b2ba194bc0867b3747801fa22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.099\t\t0.773\t\t0.53m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.099\t\t0.773\t\t0.54m - 1.1m / 18.4m                                                                   \n",
      "3\t42k\t0.03\t\t0.02\t\t0.073\t\t0.736\t\t0.52m - 1.6m / 18.8m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.091\t\t0.759\t\t0.52m - 2.1m / 18.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.03\t\t0.097\t\t0.769\t\t0.52m - 2.7m / 18.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.118\t\t0.806\t\t0.52m - 3.2m / 18.2m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.109\t\t0.794\t\t0.51m - 3.8m / 18.3m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.121\t\t0.813\t\t0.50m - 4.3m / 18.0m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.137\t\t0.835\t\t0.52m - 4.8m / 17.8m                                                                  \n",
      "10\t140k\t0.01\t\t0.01\t\t0.145\t\t0.846\t\t0.51m - 5.3m / 18.2m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.163\t\t0.863\t\t0.51m - 5.9m / 18.1m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.163\t\t0.863\t\t0.50m - 6.4m / 18.1m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.153\t\t0.853\t\t0.52m - 6.9m / 17.9m                                                                 \n",
      "14\t197k\t0.01\t\t0.01\t\t0.171\t\t0.869\t\t0.53m - 7.5m / 18.4m                                                                 \n",
      "15\t211k\t0.01\t\t0.01\t\t0.161\t\t0.861\t\t0.50m - 8.1m / 18.8m                                                                 \n",
      "16\t225k\t0.01\t\t0.01\t\t0.145\t\t0.847\t\t0.49m - 8.6m / 18.1m                                                                 \n",
      "17\t239k\t0.01\t\t0.01\t\t0.164\t\t0.865\t\t0.49m - 9.1m / 18.0m                                                                 \n",
      "18\t253k\t0.01\t\t0.01\t\t0.162\t\t0.865\t\t0.50m - 9.6m / 18.0m                                                                 \n",
      "19\t267k\t0.01\t\t0.01\t\t0.174\t\t0.872\t\t0.50m - 10.1m / 18.1m                                                                \n",
      "20\t281k\t0.00\t\t0.01\t\t0.155\t\t0.853\t\t0.50m - 10.6m / 18.1m                                                                \n",
      "21\t295k\t0.00\t\t0.01\t\t0.167\t\t0.867\t\t0.50m - 11.2m / 18.2m                                                                \n",
      "22\t309k\t0.00\t\t0.01\t\t0.171\t\t0.870\t\t0.50m - 11.7m / 18.2m                                                                \n",
      "23\t323k\t0.00\t\t0.01\t\t0.172\t\t0.872\t\t0.52m - 12.2m / 18.2m                                                                \n",
      "24\t337k\t0.00\t\t0.01\t\t0.161\t\t0.861\t\t0.53m - 12.7m / 18.5m                                                                \n",
      "VAL f1\t0.17365933122886687 - (0.17365933122886687)                                                                     \n",
      "VAL loss\t0.009309657596624814                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009309657596624814\n",
      "        | \\     )|_\tf1: 0.17365933122886687\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\62 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 27.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         27                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.13843014069791282                |\n",
      "|  noam_learning_rate_warmup   |                        2913                       |\n",
      "|  noam_learning_rate_factor   |                 0.6977959829026809                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.05197473394581387                |\n",
      "|     pointwise_layer_size     |                         39                        |\n",
      "|      last_layer_dropout      |                 0.545706481638872                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 64%|██████████████████████████▉               | 96/150 [14:51:04<8:16:57, 552.17s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e8ea17aa7b4c5c961c8a62ee98771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.319\t\t0.885\t\t0.72m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.02\t\t0.396\t\t0.912\t\t0.69m - 1.4m / 25.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.364\t\t0.901\t\t0.68m - 2.1m / 24.2m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.414\t\t0.917\t\t0.66m - 2.8m / 23.9m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.414\t\t0.918\t\t0.68m - 3.5m / 23.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.436\t\t0.925\t\t0.67m - 4.2m / 23.9m                                                                   \n",
      "7\t98k\t0.01\t\t0.01\t\t0.429\t\t0.922\t\t0.66m - 4.9m / 23.8m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.396\t\t0.913\t\t0.67m - 5.5m / 23.4m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.412\t\t0.917\t\t0.66m - 6.2m / 23.6m                                                                  \n",
      "10\t141k\t0.00\t\t0.02\t\t0.437\t\t0.926\t\t0.66m - 6.9m / 23.4m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.457\t\t0.929\t\t0.67m - 7.6m / 23.4m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.435\t\t0.924\t\t0.65m - 8.2m / 23.6m                                                                 \n",
      "13\t183k\t0.00\t\t0.02\t\t0.448\t\t0.928\t\t0.66m - 8.9m / 23.3m                                                                 \n",
      "14\t197k\t0.00\t\t0.02\t\t0.459\t\t0.932\t\t0.65m - 9.6m / 23.4m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.448\t\t0.928\t\t0.65m - 10.3m / 23.2m                                                                \n",
      "16\t225k\t0.00\t\t0.02\t\t0.452\t\t0.930\t\t0.65m - 10.9m / 23.3m                                                                \n",
      "17\t239k\t0.00\t\t0.02\t\t0.444\t\t0.928\t\t0.66m - 11.6m / 23.3m                                                                \n",
      "18\t253k\t0.00\t\t0.01\t\t0.425\t\t0.921\t\t0.65m - 12.2m / 23.4m                                                                \n",
      "19\t267k\t0.00\t\t0.02\t\t0.449\t\t0.928\t\t0.65m - 12.9m / 23.4m                                                                \n",
      "VAL f1\t0.4592392282162724 - (0.4592392282162724)                                                                       \n",
      "VAL loss\t0.012671276519611965                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012671276519611965\n",
      "        | \\     )|_\tf1: 0.4592392282162724\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\63 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 12.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         12                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.029136700183639036               |\n",
      "|  noam_learning_rate_warmup   |                        3786                       |\n",
      "|  noam_learning_rate_factor   |                 2.940549807107376                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7086109622850308                |\n",
      "|     pointwise_layer_size     |                        258                        |\n",
      "|      last_layer_dropout      |                 0.2603439971815984                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 65%|███████████████████████████▏              | 97/150 [15:04:36<9:16:38, 630.16s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64638ffbf0934e85b325b29254cec333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.13\t\t0.14\t\t0.336\t\t0.766\t\t1.75m - 1.8m / 0.0m                                                                    \n",
      "2\t28k\t0.10\t\t0.13\t\t0.348\t\t0.803\t\t1.68m - 3.5m / 61.4m                                                                   \n",
      "3\t42k\t0.09\t\t0.16\t\t0.336\t\t0.818\t\t1.60m - 5.1m / 58.9m                                                                   \n",
      "4\t56k\t0.09\t\t0.11\t\t0.267\t\t0.723\t\t1.61m - 6.7m / 56.4m                                                                   \n",
      "5\t70k\t0.09\t\t0.14\t\t0.361\t\t0.808\t\t1.61m - 8.3m / 56.6m                                                                   \n",
      "6\t84k\t0.09\t\t0.18\t\t0.387\t\t0.820\t\t1.67m - 10.0m / 56.6m                                                                  \n",
      "7\t98k\t0.09\t\t0.13\t\t0.413\t\t0.836\t\t1.60m - 11.7m / 58.5m                                                                  \n",
      "8\t112k\t0.08\t\t0.18\t\t0.400\t\t0.830\t\t1.60m - 13.3m / 56.6m                                                                 \n",
      "9\t126k\t0.08\t\t0.12\t\t0.343\t\t0.791\t\t1.62m - 14.9m / 56.5m                                                                 \n",
      "10\t141k\t0.09\t\t0.13\t\t0.386\t\t0.813\t\t1.72m - 16.6m / 56.9m                                                                \n",
      "11\t155k\t0.09\t\t0.14\t\t0.027\t\t0.082\t\t1.64m - 18.3m / 59.6m                                                                \n",
      "12\t169k\t0.09\t\t0.15\t\t0.025\t\t0.072\t\t1.62m - 19.9m / 57.6m                                                                \n",
      "VAL f1\t0.41285259141072483 - (0.41285259141072483)                                                                     \n",
      "VAL loss\t0.10936154100727771                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.10936154100727771\n",
      "        | \\     )|_\tf1: 0.41285259141072483\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\64 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 36.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         36                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.001158841028911872               |\n",
      "|  noam_learning_rate_warmup   |                        8202                       |\n",
      "|  noam_learning_rate_factor   |                 0.9498551816182208                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.06592604295248697                |\n",
      "|     pointwise_layer_size     |                        123                        |\n",
      "|      last_layer_dropout      |                0.08712387813965057                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 65%|██████████████████████████▊              | 98/150 [15:25:35<11:49:25, 818.56s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b982e44f9fae4ef69692ac1cbda90c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.176\t\t0.818\t\t0.68m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.248\t\t0.874\t\t0.68m - 1.4m / 23.8m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.300\t\t0.900\t\t0.66m - 2.1m / 24.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.339\t\t0.915\t\t0.67m - 2.8m / 23.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.311\t\t0.904\t\t0.66m - 3.5m / 23.7m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.325\t\t0.912\t\t0.66m - 4.2m / 23.4m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.335\t\t0.915\t\t0.66m - 4.8m / 23.3m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.338\t\t0.915\t\t0.67m - 5.5m / 23.5m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.302\t\t0.902\t\t0.66m - 6.2m / 23.5m                                                                  \n",
      "VAL f1\t0.3387815558027873 - (0.3387815558027873)                                                                       \n",
      "VAL loss\t0.011684386045214297                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011684386045214297\n",
      "        | \\     )|_\tf1: 0.3387815558027873\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\65 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 10.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         10                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.007814457876057276               |\n",
      "|  noam_learning_rate_warmup   |                        8892                       |\n",
      "|  noam_learning_rate_factor   |                 3.259211137154845                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6761424750620821                |\n",
      "|     pointwise_layer_size     |                        181                        |\n",
      "|      last_layer_dropout      |                 0.2411435255323026                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 66%|███████████████████████████▋              | 99/150 [15:32:27<9:52:17, 696.82s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7759b06d00d64d898ed9e5efb7f2abad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.17\t\t0.16\t\t0.389\t\t0.773\t\t1.91m - 1.9m / 0.0m                                                                    \n",
      "2\t28k\t0.12\t\t0.11\t\t0.411\t\t0.822\t\t2.02m - 4.0m / 66.9m                                                                   \n",
      "3\t42k\t0.10\t\t0.15\t\t0.354\t\t0.775\t\t1.84m - 5.8m / 70.7m                                                                   \n",
      "4\t56k\t0.11\t\t0.15\t\t0.321\t\t0.758\t\t1.85m - 7.7m / 64.6m                                                                   \n",
      "5\t70k\t0.11\t\t0.20\t\t0.047\t\t0.416\t\t1.83m - 9.5m / 64.9m                                                                   \n",
      "6\t84k\t0.11\t\t0.16\t\t0.416\t\t0.797\t\t1.84m - 11.4m / 64.6m                                                                  \n",
      "7\t98k\t0.11\t\t0.19\t\t0.394\t\t0.814\t\t1.84m - 13.2m / 64.6m                                                                  \n",
      "8\t112k\t0.11\t\t0.16\t\t0.235\t\t0.761\t\t1.88m - 15.1m / 64.8m                                                                 \n",
      "9\t126k\t0.11\t\t0.17\t\t0.312\t\t0.785\t\t1.86m - 17.0m / 66.0m                                                                 \n",
      "10\t140k\t0.11\t\t0.17\t\t0.273\t\t0.757\t\t1.96m - 19.0m / 65.4m                                                                \n",
      "11\t155k\t0.11\t\t0.19\t\t0.385\t\t0.789\t\t1.85m - 20.8m / 68.0m                                                                \n",
      "VAL f1\t0.41590120454224466 - (0.41590120454224466)                                                                     \n",
      "VAL loss\t0.10623691783960049                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.10623691783960049\n",
      "        | \\     )|_\tf1: 0.41590120454224466\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\66 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 29.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         29                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0022727621868552593               |\n",
      "|  noam_learning_rate_warmup   |                        4638                       |\n",
      "|  noam_learning_rate_factor   |                 1.7552697355630669                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7568308088510781                |\n",
      "|     pointwise_layer_size     |                         86                        |\n",
      "|      last_layer_dropout      |                0.34111312296978524                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 67%|██████████████████████████▋             | 100/150 [15:54:30<12:17:14, 884.68s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77da841fb9ed462d866e1ab16c3e6e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.07\t\t0.189\t\t0.807\t\t0.41m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.06\t\t0.192\t\t0.807\t\t0.41m - 0.8m / 14.3m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.217\t\t0.827\t\t0.41m - 1.3m / 14.2m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.233\t\t0.842\t\t0.41m - 1.7m / 14.3m                                                                   \n",
      "5\t70k\t0.02\t\t0.04\t\t0.246\t\t0.853\t\t0.41m - 2.1m / 14.4m                                                                   \n",
      "6\t84k\t0.02\t\t0.04\t\t0.255\t\t0.857\t\t0.41m - 2.5m / 14.3m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.303\t\t0.888\t\t0.40m - 2.9m / 14.3m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.297\t\t0.880\t\t0.40m - 3.4m / 14.1m                                                                  \n",
      "9\t127k\t0.02\t\t0.03\t\t0.310\t\t0.891\t\t0.40m - 3.8m / 14.2m                                                                  \n",
      "10\t141k\t0.02\t\t0.03\t\t0.291\t\t0.883\t\t0.41m - 4.2m / 14.3m                                                                 \n",
      "11\t155k\t0.02\t\t0.03\t\t0.297\t\t0.882\t\t0.41m - 4.6m / 14.3m                                                                 \n",
      "12\t169k\t0.02\t\t0.03\t\t0.294\t\t0.881\t\t0.39m - 5.0m / 14.4m                                                                 \n",
      "13\t183k\t0.02\t\t0.03\t\t0.277\t\t0.874\t\t0.40m - 5.4m / 14.1m                                                                 \n",
      "14\t197k\t0.02\t\t0.03\t\t0.305\t\t0.887\t\t0.40m - 5.8m / 14.2m                                                                 \n",
      "VAL f1\t0.3097191955519045 - (0.3097191955519045)                                                                       \n",
      "VAL loss\t0.03031513086717086                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03031513086717086\n",
      "        | \\     )|_\tf1: 0.3097191955519045\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\67 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 41.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         41                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.013685126821475197               |\n",
      "|  noam_learning_rate_warmup   |                        6670                       |\n",
      "|  noam_learning_rate_factor   |                0.22699265813144856                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.3685901274884201                |\n",
      "|     pointwise_layer_size     |                        312                        |\n",
      "|      last_layer_dropout      |                 0.3253654091453977                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 67%|███████████████████████████▌             | 101/150 [16:00:53<9:59:23, 733.94s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d0c3d8a4046aeb6502d5de0411821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.148\t\t0.810\t\t0.66m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.148\t\t0.810\t\t0.67m - 1.4m / 23.2m                                                                   \n",
      "3\t42k\t0.04\t\t0.03\t\t0.143\t\t0.801\t\t0.68m - 2.0m / 23.5m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.125\t\t0.788\t\t0.67m - 2.7m / 23.7m                                                                   \n",
      "5\t70k\t0.03\t\t0.02\t\t0.167\t\t0.829\t\t0.67m - 3.4m / 23.4m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.179\t\t0.839\t\t0.73m - 4.1m / 23.4m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.196\t\t0.852\t\t0.70m - 4.9m / 25.2m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.218\t\t0.867\t\t0.71m - 5.6m / 24.5m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.203\t\t0.859\t\t0.67m - 6.3m / 24.9m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.213\t\t0.865\t\t0.65m - 7.0m / 23.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.241\t\t0.884\t\t0.65m - 7.7m / 23.3m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.234\t\t0.877\t\t0.65m - 8.3m / 23.3m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.242\t\t0.884\t\t0.64m - 9.0m / 23.3m                                                                 \n",
      "14\t197k\t0.00\t\t0.02\t\t0.234\t\t0.879\t\t0.66m - 9.7m / 23.1m                                                                 \n",
      "15\t211k\t0.00\t\t0.02\t\t0.248\t\t0.888\t\t0.65m - 10.3m / 23.5m                                                                \n",
      "16\t225k\t0.00\t\t0.02\t\t0.239\t\t0.884\t\t0.64m - 11.0m / 23.4m                                                                \n",
      "17\t239k\t0.00\t\t0.03\t\t0.218\t\t0.874\t\t0.65m - 11.7m / 23.2m                                                                \n",
      "18\t253k\t0.00\t\t0.02\t\t0.232\t\t0.881\t\t0.64m - 12.3m / 23.4m                                                                \n",
      "19\t267k\t0.00\t\t0.02\t\t0.226\t\t0.882\t\t0.64m - 13.0m / 23.3m                                                                \n",
      "20\t281k\t0.00\t\t0.02\t\t0.238\t\t0.885\t\t0.65m - 13.6m / 23.3m                                                                \n",
      "VAL f1\t0.24781331855067795 - (0.24781331855067795)                                                                     \n",
      "VAL loss\t0.019693943673017914                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.019693943673017914\n",
      "        | \\     )|_\tf1: 0.24781331855067795\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\68 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 24.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         24                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.002385120615569131               |\n",
      "|  noam_learning_rate_warmup   |                        6456                       |\n",
      "|  noam_learning_rate_factor   |                 3.949128607150874                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.007938193700719865               |\n",
      "|     pointwise_layer_size     |                         58                        |\n",
      "|      last_layer_dropout      |                 0.3143122914439982                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 68%|███████████████████████████▏            | 102/150 [16:15:07<10:16:03, 770.07s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce3a73976f04850af6f38d937861193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.400\t\t0.902\t\t0.72m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.02\t\t0.450\t\t0.920\t\t0.73m - 1.5m / 25.3m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.377\t\t0.902\t\t0.75m - 2.2m / 25.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.353\t\t0.890\t\t0.73m - 3.0m / 26.1m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.407\t\t0.908\t\t0.72m - 3.7m / 25.6m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.404\t\t0.907\t\t0.73m - 4.5m / 25.4m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.356\t\t0.889\t\t0.75m - 5.2m / 25.7m                                                                   \n",
      "VAL f1\t0.4495804258366203 - (0.4495804258366203)                                                                       \n",
      "VAL loss\t0.016515897516179462                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.016515897516179462\n",
      "        | \\     )|_\tf1: 0.4495804258366203\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\69 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 36.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         36                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.07183319507296287                |\n",
      "|  noam_learning_rate_warmup   |                        2056                       |\n",
      "|  noam_learning_rate_factor   |                 2.230605821319232                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.14369044869037761                |\n",
      "|     pointwise_layer_size     |                        141                        |\n",
      "|      last_layer_dropout      |                 0.7371948759890189                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 69%|████████████████████████████▏            | 103/150 [16:21:04<8:26:05, 646.08s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8cacdf84714c119cf197cea67c5c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.01\t\t0.235\t\t0.866\t\t0.35m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.295\t\t0.899\t\t0.35m - 0.7m / 12.2m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.312\t\t0.905\t\t0.34m - 1.1m / 12.3m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.288\t\t0.895\t\t0.36m - 1.5m / 12.0m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.271\t\t0.889\t\t0.33m - 1.8m / 12.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.225\t\t0.868\t\t0.34m - 2.2m / 11.7m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.175\t\t0.845\t\t0.34m - 2.5m / 11.9m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.237\t\t0.866\t\t0.33m - 2.8m / 11.9m                                                                  \n",
      "VAL f1\t0.3123610720792619 - (0.3123610720792619)                                                                       \n",
      "VAL loss\t0.011302552961770523                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011302552961770523\n",
      "        | \\     )|_\tf1: 0.3123610720792619\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\70 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 28.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         28                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0021976332510761734               |\n",
      "|  noam_learning_rate_warmup   |                        2655                       |\n",
      "|  noam_learning_rate_factor   |                 2.8110703581253462                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.4426754951610858                |\n",
      "|     pointwise_layer_size     |                         38                        |\n",
      "|      last_layer_dropout      |                0.24945661111110892                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 69%|████████████████████████████▍            | 104/150 [16:24:25<6:33:08, 512.79s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0408cbde94e54e2eb277f1da9aa5e140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.251\t\t0.854\t\t1.05m - 1.1m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.233\t\t0.857\t\t1.06m - 2.1m / 36.9m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.151\t\t0.778\t\t1.06m - 3.2m / 37.2m                                                                   \n",
      "4\t56k\t0.04\t\t0.05\t\t0.105\t\t0.756\t\t1.06m - 4.3m / 37.1m                                                                   \n",
      "5\t70k\t0.05\t\t0.05\t\t0.174\t\t0.803\t\t1.03m - 5.3m / 37.0m                                                                   \n",
      "6\t84k\t0.05\t\t0.06\t\t0.194\t\t0.807\t\t1.05m - 6.4m / 36.4m                                                                   \n",
      "VAL f1\t0.25107596531206017 - (0.25107596531206017)                                                                     \n",
      "VAL loss\t0.02487191578807703                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02487191578807703\n",
      "        | \\     )|_\tf1: 0.25107596531206017\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\71 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00025732145791727183              |\n",
      "|  noam_learning_rate_warmup   |                        1500                       |\n",
      "|  noam_learning_rate_factor   |                 2.080874624003051                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7199917469533745                |\n",
      "|     pointwise_layer_size     |                        171                        |\n",
      "|      last_layer_dropout      |                 0.3038637669791007                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 70%|████████████████████████████▋            | 105/150 [16:31:34<6:05:42, 487.61s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac69cff48d4145f9b10c5a0c9c690260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.122\t\t0.800\t\t0.42m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.118\t\t0.790\t\t0.43m - 0.9m / 14.8m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.128\t\t0.797\t\t0.43m - 1.3m / 15.0m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.120\t\t0.796\t\t0.42m - 1.8m / 15.1m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.039\t\t0.660\t\t0.42m - 2.2m / 15.0m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.022\t\t0.576\t\t0.42m - 2.6m / 14.8m                                                                   \n",
      "7\t98k\t0.02\t\t0.02\t\t0.055\t\t0.726\t\t0.45m - 3.1m / 14.7m                                                                   \n",
      "8\t113k\t0.02\t\t0.02\t\t0.114\t\t0.801\t\t0.45m - 3.6m / 15.8m                                                                  \n",
      "VAL f1\t0.12831731745507627 - (0.12831731745507627)                                                                     \n",
      "VAL loss\t0.022006214037197158                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.022006214037197158\n",
      "        | \\     )|_\tf1: 0.12831731745507627\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\72 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.16613820369919396                |\n",
      "|  noam_learning_rate_warmup   |                        8179                       |\n",
      "|  noam_learning_rate_factor   |                  3.93461652805847                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.07150908385823432                |\n",
      "|     pointwise_layer_size     |                        279                        |\n",
      "|      last_layer_dropout      |                 0.6962935283621184                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 71%|████████████████████████████▉            | 106/150 [16:35:36<5:03:33, 413.94s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94e01276d794bf4ad6d8876459abfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.03\t\t0.422\t\t0.880\t\t1.44m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.482\t\t0.905\t\t1.38m - 2.8m / 50.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.379\t\t0.861\t\t1.28m - 4.1m / 48.4m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.480\t\t0.904\t\t1.27m - 5.4m / 45.3m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.510\t\t0.914\t\t1.28m - 6.7m / 44.8m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.497\t\t0.908\t\t1.33m - 8.1m / 45.1m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.490\t\t0.909\t\t1.35m - 9.4m / 46.8m                                                                   \n",
      "8\t112k\t0.02\t\t0.05\t\t0.437\t\t0.885\t\t1.37m - 10.8m / 47.1m                                                                 \n",
      "9\t126k\t0.02\t\t0.03\t\t0.433\t\t0.883\t\t1.37m - 12.2m / 47.7m                                                                 \n",
      "10\t140k\t0.02\t\t0.03\t\t0.463\t\t0.897\t\t1.39m - 13.6m / 47.7m                                                                \n",
      "VAL f1\t0.5102868172991283 - (0.5102868172991283)                                                                       \n",
      "VAL loss\t0.026876761318942278                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.026876761318942278\n",
      "        | \\     )|_\tf1: 0.5102868172991283\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\73 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 11.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         11                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00019176327598817818              |\n",
      "|  noam_learning_rate_warmup   |                        6711                       |\n",
      "|  noam_learning_rate_factor   |                 0.5293353858942539                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6647182353726339                |\n",
      "|     pointwise_layer_size     |                        123                        |\n",
      "|      last_layer_dropout      |                 0.5141541326344407                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 71%|█████████████████████████████▏           | 107/150 [16:50:12<6:35:48, 552.28s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88e0c7d77ec45eaa8f93d611e894535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.17\t\t0.16\t\t0.405\t\t0.824\t\t1.41m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.13\t\t0.11\t\t0.371\t\t0.817\t\t1.34m - 2.8m / 49.4m                                                                   \n",
      "3\t42k\t0.10\t\t0.09\t\t0.393\t\t0.821\t\t1.32m - 4.1m / 46.9m                                                                   \n",
      "4\t56k\t0.07\t\t0.09\t\t0.422\t\t0.828\t\t1.31m - 5.4m / 46.2m                                                                   \n",
      "5\t70k\t0.06\t\t0.08\t\t0.462\t\t0.849\t\t1.26m - 6.7m / 46.1m                                                                   \n",
      "6\t84k\t0.05\t\t0.07\t\t0.542\t\t0.888\t\t1.29m - 8.0m / 44.6m                                                                   \n",
      "7\t98k\t0.04\t\t0.06\t\t0.570\t\t0.900\t\t1.24m - 9.3m / 45.4m                                                                   \n",
      "8\t112k\t0.04\t\t0.06\t\t0.575\t\t0.903\t\t1.27m - 10.6m / 44.1m                                                                 \n",
      "9\t126k\t0.04\t\t0.06\t\t0.612\t\t0.915\t\t1.22m - 11.8m / 44.8m                                                                 \n",
      "10\t140k\t0.03\t\t0.06\t\t0.564\t\t0.898\t\t1.25m - 13.1m / 43.7m                                                                \n",
      "11\t155k\t0.03\t\t0.05\t\t0.596\t\t0.912\t\t1.29m - 14.4m / 44.4m                                                                \n",
      "12\t169k\t0.03\t\t0.07\t\t0.594\t\t0.910\t\t1.33m - 15.7m / 45.5m                                                                \n",
      "13\t183k\t0.03\t\t0.07\t\t0.614\t\t0.918\t\t1.29m - 17.1m / 46.3m                                                                \n",
      "14\t197k\t0.03\t\t0.06\t\t0.600\t\t0.912\t\t1.25m - 18.3m / 45.5m                                                                \n",
      "15\t211k\t0.03\t\t0.07\t\t0.610\t\t0.915\t\t1.23m - 19.6m / 44.7m                                                                \n",
      "16\t225k\t0.03\t\t0.07\t\t0.619\t\t0.918\t\t1.25m - 20.8m / 44.1m                                                                \n",
      "17\t239k\t0.03\t\t0.07\t\t0.620\t\t0.919\t\t1.28m - 22.1m / 44.6m                                                                \n",
      "18\t253k\t0.03\t\t0.07\t\t0.591\t\t0.909\t\t1.23m - 23.4m / 45.3m                                                                \n",
      "19\t267k\t0.03\t\t0.06\t\t0.624\t\t0.919\t\t1.26m - 24.7m / 44.4m                                                                \n",
      "20\t281k\t0.03\t\t0.07\t\t0.623\t\t0.920\t\t1.27m - 25.9m / 44.7m                                                                \n",
      "21\t295k\t0.03\t\t0.07\t\t0.609\t\t0.915\t\t1.27m - 27.2m / 44.9m                                                                \n",
      "22\t309k\t0.03\t\t0.07\t\t0.632\t\t0.922\t\t1.29m - 28.5m / 45.0m                                                                \n",
      "23\t323k\t0.03\t\t0.07\t\t0.639\t\t0.925\t\t1.26m - 29.8m / 45.3m                                                                \n",
      "24\t337k\t0.03\t\t0.07\t\t0.623\t\t0.919\t\t1.29m - 31.1m / 45.0m                                                                \n",
      "25\t351k\t0.03\t\t0.07\t\t0.625\t\t0.921\t\t1.29m - 32.4m / 45.3m                                                                \n",
      "26\t365k\t0.03\t\t0.07\t\t0.619\t\t0.918\t\t1.26m - 33.7m / 45.3m                                                                \n",
      "27\t379k\t0.03\t\t0.08\t\t0.616\t\t0.917\t\t1.26m - 34.9m / 45.0m                                                                \n",
      "28\t393k\t0.03\t\t0.07\t\t0.628\t\t0.921\t\t1.27m - 36.2m / 45.0m                                                                \n",
      "VAL f1\t0.6390522335138381 - (0.6390522335138381)                                                                       \n",
      "VAL loss\t0.05474799635005577                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.05474799635005577\n",
      "        | \\     )|_\tf1: 0.6390522335138381\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\74 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 54.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         54                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0015366519547490558               |\n",
      "|  noam_learning_rate_warmup   |                        8823                       |\n",
      "|  noam_learning_rate_factor   |                 1.4533351145591045                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.05786716720744574                |\n",
      "|     pointwise_layer_size     |                        201                        |\n",
      "|      last_layer_dropout      |                 0.143337289452953                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 72%|████████████████████████████           | 108/150 [17:27:33<12:21:22, 1059.11s/it, best loss: 0.007194733719890525]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002d09dab99443319593dd335e585ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.114\t\t0.802\t\t0.62m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.01\t\t0.134\t\t0.827\t\t0.62m - 1.3m / 21.6m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.179\t\t0.875\t\t0.62m - 1.9m / 21.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.202\t\t0.889\t\t0.62m - 2.5m / 21.8m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.217\t\t0.898\t\t0.62m - 3.2m / 21.8m                                                                   \n",
      "6\t85k\t0.00\t\t0.01\t\t0.213\t\t0.899\t\t0.62m - 3.8m / 21.9m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.215\t\t0.898\t\t0.62m - 4.4m / 21.8m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.188\t\t0.883\t\t0.62m - 5.1m / 21.9m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.221\t\t0.899\t\t0.61m - 5.7m / 21.8m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.194\t\t0.885\t\t0.61m - 6.3m / 21.7m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.216\t\t0.898\t\t0.61m - 6.9m / 21.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.214\t\t0.896\t\t0.61m - 7.6m / 21.6m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.242\t\t0.912\t\t0.61m - 8.2m / 21.6m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.254\t\t0.916\t\t0.66m - 8.9m / 21.6m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.255\t\t0.916\t\t0.64m - 9.5m / 22.8m                                                                 \n",
      "16\t226k\t0.00\t\t0.01\t\t0.254\t\t0.916\t\t0.66m - 10.2m / 22.4m                                                                \n",
      "17\t240k\t0.00\t\t0.01\t\t0.252\t\t0.915\t\t0.61m - 10.8m / 22.7m                                                                \n",
      "18\t254k\t0.00\t\t0.01\t\t0.223\t\t0.902\t\t0.62m - 11.5m / 21.9m                                                                \n",
      "19\t268k\t0.00\t\t0.01\t\t0.219\t\t0.900\t\t0.62m - 12.1m / 22.0m                                                                \n",
      "20\t282k\t0.00\t\t0.01\t\t0.244\t\t0.910\t\t0.62m - 12.7m / 22.0m                                                                \n",
      "VAL f1\t0.2552525785944801 - (0.2552525785944801)                                                                       \n",
      "VAL loss\t0.005932488496815102                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.005932488496815102\n",
      "        | \\     )|_\tf1: 0.2552525785944801\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\75 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 50.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         50                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0048243139480141405               |\n",
      "|  noam_learning_rate_warmup   |                        1100                       |\n",
      "|  noam_learning_rate_factor   |                 0.8763866467369634                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7268062192313922                |\n",
      "|     pointwise_layer_size     |                        149                        |\n",
      "|      last_layer_dropout      |                 0.5187442536152203                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 73%|█████████████████████████████           | 109/150 [17:40:50<11:09:52, 980.30s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2fb9fd16104445893f58d3867245a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.099\t\t0.773\t\t0.39m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.106\t\t0.788\t\t0.40m - 0.8m / 13.8m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.069\t\t0.762\t\t0.40m - 1.2m / 13.9m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.089\t\t0.761\t\t0.39m - 1.6m / 13.9m                                                                   \n",
      "5\t70k\t0.01\t\t0.03\t\t0.095\t\t0.775\t\t0.39m - 2.1m / 13.9m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.108\t\t0.800\t\t0.40m - 2.5m / 13.8m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.111\t\t0.806\t\t0.40m - 2.9m / 14.0m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.108\t\t0.800\t\t0.39m - 3.3m / 14.0m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.114\t\t0.813\t\t0.39m - 3.7m / 13.9m                                                                  \n",
      "10\t140k\t0.01\t\t0.03\t\t0.119\t\t0.821\t\t0.39m - 4.1m / 13.8m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.111\t\t0.805\t\t0.39m - 4.5m / 13.8m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.110\t\t0.806\t\t0.39m - 4.9m / 13.9m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.114\t\t0.811\t\t0.38m - 5.3m / 13.9m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.119\t\t0.818\t\t0.39m - 5.7m / 13.8m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.120\t\t0.822\t\t0.38m - 6.1m / 13.9m                                                                 \n",
      "16\t225k\t0.01\t\t0.02\t\t0.106\t\t0.799\t\t0.38m - 6.5m / 13.7m                                                                 \n",
      "17\t239k\t0.01\t\t0.02\t\t0.118\t\t0.819\t\t0.39m - 6.9m / 13.7m                                                                 \n",
      "18\t253k\t0.01\t\t0.03\t\t0.122\t\t0.823\t\t0.38m - 7.3m / 13.8m                                                                 \n",
      "19\t267k\t0.01\t\t0.02\t\t0.100\t\t0.790\t\t0.38m - 7.7m / 13.8m                                                                 \n",
      "20\t281k\t0.01\t\t0.02\t\t0.107\t\t0.801\t\t0.38m - 8.1m / 13.8m                                                                 \n",
      "21\t295k\t0.01\t\t0.02\t\t0.101\t\t0.794\t\t0.39m - 8.5m / 13.8m                                                                 \n",
      "22\t309k\t0.01\t\t0.02\t\t0.094\t\t0.784\t\t0.41m - 8.9m / 13.9m                                                                 \n",
      "23\t323k\t0.01\t\t0.02\t\t0.107\t\t0.801\t\t0.42m - 9.3m / 14.3m                                                                 \n",
      "VAL f1\t0.12188911109448862 - (0.12188911109448862)                                                                     \n",
      "VAL loss\t0.02015926698537973                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02015926698537973\n",
      "        | \\     )|_\tf1: 0.12188911109448862\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\76 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 63.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         63                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.575983133976649                 |\n",
      "|  noam_learning_rate_warmup   |                        8509                       |\n",
      "|  noam_learning_rate_factor   |                 2.7695008292768373                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6206367375850937                |\n",
      "|     pointwise_layer_size     |                        170                        |\n",
      "|      last_layer_dropout      |                 0.7078892723490487                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 73%|██████████████████████████████           | 110/150 [17:50:37<9:34:51, 862.30s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbaf9e9e3cf54eb8892197e9b0ec8ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.089\t\t0.783\t\t0.47m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.089\t\t0.783\t\t0.47m - 1.0m / 16.6m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.077\t\t0.763\t\t0.45m - 1.4m / 16.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.093\t\t0.801\t\t0.44m - 1.9m / 15.8m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.089\t\t0.784\t\t0.44m - 2.3m / 15.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.106\t\t0.808\t\t0.44m - 2.8m / 15.6m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.096\t\t0.793\t\t0.44m - 3.2m / 15.7m                                                                   \n",
      "8\t112k\t0.01\t\t0.01\t\t0.128\t\t0.841\t\t0.44m - 3.7m / 15.5m                                                                  \n",
      "9\t126k\t0.01\t\t0.01\t\t0.131\t\t0.846\t\t0.44m - 4.1m / 15.6m                                                                  \n",
      "10\t140k\t0.01\t\t0.01\t\t0.134\t\t0.848\t\t0.44m - 4.6m / 15.6m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.130\t\t0.844\t\t0.44m - 5.1m / 15.6m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.150\t\t0.863\t\t0.44m - 5.5m / 15.6m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.149\t\t0.862\t\t0.43m - 6.0m / 15.5m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.150\t\t0.866\t\t0.44m - 6.4m / 15.5m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.152\t\t0.870\t\t0.44m - 6.9m / 15.6m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.155\t\t0.870\t\t0.43m - 7.3m / 15.7m                                                                 \n",
      "17\t239k\t0.00\t\t0.01\t\t0.151\t\t0.866\t\t0.43m - 7.8m / 15.6m                                                                 \n",
      "18\t253k\t0.00\t\t0.01\t\t0.159\t\t0.874\t\t0.44m - 8.2m / 15.6m                                                                 \n",
      "19\t267k\t0.00\t\t0.01\t\t0.153\t\t0.872\t\t0.43m - 8.7m / 15.7m                                                                 \n",
      "20\t281k\t0.00\t\t0.01\t\t0.137\t\t0.865\t\t0.44m - 9.1m / 15.6m                                                                 \n",
      "21\t295k\t0.00\t\t0.01\t\t0.147\t\t0.861\t\t0.43m - 9.6m / 15.7m                                                                 \n",
      "22\t309k\t0.00\t\t0.01\t\t0.153\t\t0.866\t\t0.43m - 10.0m / 15.6m                                                                \n",
      "23\t323k\t0.00\t\t0.01\t\t0.159\t\t0.873\t\t0.44m - 10.5m / 15.7m                                                                \n",
      "VAL f1\t0.15908040213996807 - (0.15908040213996807)                                                                     \n",
      "VAL loss\t0.009551910787135118                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009551910787135118\n",
      "        | \\     )|_\tf1: 0.15908040213996807\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\77 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 46.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         46                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0012415225888674796               |\n",
      "|  noam_learning_rate_warmup   |                        1610                       |\n",
      "|  noam_learning_rate_factor   |                 0.2226036411126336                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.048810567401394694               |\n",
      "|     pointwise_layer_size     |                         76                        |\n",
      "|      last_layer_dropout      |                 0.5937476284030335                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 74%|██████████████████████████████▎          | 111/150 [18:01:33<8:40:19, 800.50s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839c76685ee6407cb4c0827888f80e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.130\t\t0.800\t\t0.59m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.175\t\t0.847\t\t0.59m - 1.2m / 20.7m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.211\t\t0.875\t\t0.60m - 1.8m / 20.8m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.208\t\t0.872\t\t0.60m - 2.4m / 21.0m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.250\t\t0.900\t\t0.62m - 3.1m / 21.0m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.242\t\t0.894\t\t0.63m - 3.7m / 21.7m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.238\t\t0.891\t\t0.62m - 4.4m / 22.2m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.236\t\t0.892\t\t0.58m - 5.0m / 21.9m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.261\t\t0.903\t\t0.58m - 5.5m / 20.5m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.230\t\t0.887\t\t0.57m - 6.1m / 20.5m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.254\t\t0.899\t\t0.57m - 6.7m / 20.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.243\t\t0.893\t\t0.58m - 7.3m / 20.4m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.264\t\t0.906\t\t0.58m - 7.9m / 20.6m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.264\t\t0.904\t\t0.57m - 8.5m / 20.7m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.245\t\t0.895\t\t0.57m - 9.1m / 20.5m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.248\t\t0.898\t\t0.57m - 9.7m / 20.5m                                                                 \n",
      "17\t239k\t0.00\t\t0.01\t\t0.245\t\t0.895\t\t0.57m - 10.3m / 20.4m                                                                \n",
      "18\t253k\t0.00\t\t0.01\t\t0.255\t\t0.901\t\t0.57m - 10.8m / 20.5m                                                                \n",
      "19\t267k\t0.00\t\t0.01\t\t0.248\t\t0.899\t\t0.57m - 11.4m / 20.5m                                                                \n",
      "VAL f1\t0.2640780446384189 - (0.2640780446384189)                                                                       \n",
      "VAL loss\t0.008608532590427724                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.008608532590427724\n",
      "        | \\     )|_\tf1: 0.2640780446384189\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\78 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 40.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         40                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.06912782497353431                |\n",
      "|  noam_learning_rate_warmup   |                        1483                       |\n",
      "|  noam_learning_rate_factor   |                 3.6482340364408468                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.0797619241735081                |\n",
      "|     pointwise_layer_size     |                        154                        |\n",
      "|      last_layer_dropout      |                 0.7243463399631213                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 75%|██████████████████████████████▌          | 112/150 [18:13:30<8:11:08, 775.48s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f21172842945f898d136c093f26093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.02\t\t0.01\t\t0.300\t\t0.909\t\t0.32m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.217\t\t0.878\t\t0.32m - 0.7m / 11.3m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.202\t\t0.877\t\t0.32m - 1.0m / 11.4m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.197\t\t0.870\t\t0.32m - 1.3m / 11.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.199\t\t0.865\t\t0.33m - 1.7m / 11.4m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.221\t\t0.868\t\t0.33m - 2.0m / 11.5m                                                                   \n",
      "VAL f1\t0.2995573513871599 - (0.2995573513871599)                                                                       \n",
      "VAL loss\t0.010547797358594835                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.010547797358594835\n",
      "        | \\     )|_\tf1: 0.2995573513871599\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\79 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 44.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         44                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0004402593803022487               |\n",
      "|  noam_learning_rate_warmup   |                        7429                       |\n",
      "|  noam_learning_rate_factor   |                 3.201362072480977                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7433386933677042                |\n",
      "|     pointwise_layer_size     |                        250                        |\n",
      "|      last_layer_dropout      |                 0.461843660709923                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 75%|██████████████████████████████▉          | 113/150 [18:15:55<6:01:39, 586.48s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7189c3b4c6e440dacc59bc1b732adad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.123\t\t0.789\t\t0.28m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.123\t\t0.789\t\t0.29m - 0.6m / 10.0m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.134\t\t0.809\t\t0.28m - 0.9m / 10.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.04\t\t0.117\t\t0.778\t\t0.29m - 1.2m / 10.0m                                                                   \n",
      "5\t70k\t0.02\t\t0.04\t\t0.133\t\t0.803\t\t0.29m - 1.5m / 10.1m                                                                   \n",
      "6\t84k\t0.01\t\t0.04\t\t0.152\t\t0.826\t\t0.29m - 1.8m / 10.3m                                                                   \n",
      "7\t99k\t0.01\t\t0.04\t\t0.155\t\t0.831\t\t0.29m - 2.1m / 10.2m                                                                   \n",
      "8\t113k\t0.01\t\t0.03\t\t0.163\t\t0.837\t\t0.29m - 2.4m / 10.2m                                                                  \n",
      "9\t127k\t0.01\t\t0.05\t\t0.166\t\t0.838\t\t0.28m - 2.7m / 10.2m                                                                  \n",
      "10\t141k\t0.01\t\t0.04\t\t0.167\t\t0.841\t\t0.29m - 3.0m / 10.1m                                                                 \n",
      "11\t155k\t0.01\t\t0.04\t\t0.180\t\t0.852\t\t0.29m - 3.3m / 10.4m                                                                 \n",
      "12\t169k\t0.01\t\t0.03\t\t0.189\t\t0.860\t\t0.30m - 3.7m / 10.3m                                                                 \n",
      "13\t183k\t0.01\t\t0.03\t\t0.187\t\t0.856\t\t0.30m - 4.0m / 10.6m                                                                 \n",
      "14\t197k\t0.01\t\t0.04\t\t0.186\t\t0.856\t\t0.29m - 4.3m / 10.6m                                                                 \n",
      "15\t211k\t0.01\t\t0.03\t\t0.149\t\t0.819\t\t0.30m - 4.6m / 10.5m                                                                 \n",
      "16\t225k\t0.01\t\t0.03\t\t0.183\t\t0.858\t\t0.31m - 4.9m / 10.5m                                                                 \n",
      "17\t239k\t0.01\t\t0.03\t\t0.177\t\t0.854\t\t0.31m - 5.2m / 10.8m                                                                 \n",
      "VAL f1\t0.1890797798554386 - (0.1890797798554386)                                                                       \n",
      "VAL loss\t0.026844151940480496                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.026844151940480496\n",
      "        | \\     )|_\tf1: 0.1890797798554386\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\80 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 26.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         26                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005381849643311094               |\n",
      "|  noam_learning_rate_warmup   |                        8221                       |\n",
      "|  noam_learning_rate_factor   |                 3.5025941444948088                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.22647432805556253                |\n",
      "|     pointwise_layer_size     |                        210                        |\n",
      "|      last_layer_dropout      |                 0.7416095898920769                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 76%|███████████████████████████████▏         | 114/150 [18:21:36<5:07:34, 512.63s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1482c46644a4422ba07b60b2d2d16d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.275\t\t0.867\t\t0.45m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.292\t\t0.874\t\t0.46m - 0.9m / 15.9m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.332\t\t0.897\t\t0.46m - 1.4m / 16.1m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.303\t\t0.883\t\t0.45m - 1.9m / 16.2m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.331\t\t0.895\t\t0.45m - 2.3m / 15.7m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.326\t\t0.893\t\t0.44m - 2.8m / 15.7m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.344\t\t0.901\t\t0.45m - 3.2m / 15.5m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.342\t\t0.900\t\t0.43m - 3.7m / 15.8m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.381\t\t0.914\t\t0.43m - 4.1m / 15.3m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.350\t\t0.902\t\t0.44m - 4.6m / 15.2m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.263\t\t0.856\t\t0.44m - 5.0m / 15.6m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.292\t\t0.874\t\t0.44m - 5.5m / 15.6m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.284\t\t0.869\t\t0.44m - 5.9m / 15.6m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.281\t\t0.863\t\t0.44m - 6.4m / 15.6m                                                                 \n",
      "VAL f1\t0.3812520560227909 - (0.3812520560227909)                                                                       \n",
      "VAL loss\t0.013738986354768992                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013738986354768992\n",
      "        | \\     )|_\tf1: 0.3812520560227909\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\81 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 11.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         11                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.02481919780424103                |\n",
      "|  noam_learning_rate_warmup   |                        7105                       |\n",
      "|  noam_learning_rate_factor   |                 1.066635246159494                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.3922778279486779                |\n",
      "|     pointwise_layer_size     |                         82                        |\n",
      "|      last_layer_dropout      |                 0.7062680948072053                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 77%|███████████████████████████████▍         | 115/150 [18:28:38<4:43:09, 485.41s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11634f4d8384260b71d21cd55abb7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.14\t\t0.09\t\t0.420\t\t0.841\t\t2.32m - 2.3m / 0.0m                                                                    \n",
      "2\t28k\t0.07\t\t0.07\t\t0.509\t\t0.872\t\t2.28m - 4.6m / 81.1m                                                                   \n",
      "3\t42k\t0.05\t\t0.07\t\t0.444\t\t0.843\t\t2.31m - 6.9m / 79.8m                                                                   \n",
      "4\t56k\t0.04\t\t0.06\t\t0.567\t\t0.896\t\t2.21m - 9.2m / 80.8m                                                                   \n",
      "5\t70k\t0.04\t\t0.05\t\t0.591\t\t0.904\t\t2.25m - 11.4m / 77.7m                                                                  \n",
      "6\t84k\t0.04\t\t0.07\t\t0.470\t\t0.866\t\t2.13m - 13.6m / 78.8m                                                                  \n",
      "7\t98k\t0.04\t\t0.05\t\t0.561\t\t0.899\t\t2.14m - 15.7m / 75.4m                                                                  \n",
      "8\t112k\t0.04\t\t0.06\t\t0.501\t\t0.869\t\t2.21m - 18.0m / 75.7m                                                                 \n",
      "9\t126k\t0.04\t\t0.05\t\t0.600\t\t0.909\t\t2.20m - 20.2m / 77.8m                                                                 \n",
      "10\t140k\t0.04\t\t0.05\t\t0.553\t\t0.890\t\t2.35m - 22.5m / 77.4m                                                                \n",
      "11\t155k\t0.04\t\t0.05\t\t0.583\t\t0.901\t\t2.23m - 24.8m / 81.4m                                                                \n",
      "12\t169k\t0.03\t\t0.05\t\t0.565\t\t0.896\t\t2.27m - 27.1m / 78.2m                                                                \n",
      "13\t183k\t0.03\t\t0.04\t\t0.573\t\t0.902\t\t2.22m - 29.3m / 79.2m                                                                \n",
      "14\t197k\t0.03\t\t0.05\t\t0.576\t\t0.902\t\t2.21m - 31.5m / 78.1m                                                                \n",
      "VAL f1\t0.5999177233082126 - (0.5999177233082126)                                                                       \n",
      "VAL loss\t0.044166282156576156                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.044166282156576156\n",
      "        | \\     )|_\tf1: 0.5999177233082126\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\82 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.09505690700131114                |\n",
      "|  noam_learning_rate_warmup   |                        8906                       |\n",
      "|  noam_learning_rate_factor   |                 0.4049850889006156                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.010986088278348927               |\n",
      "|     pointwise_layer_size     |                        335                        |\n",
      "|      last_layer_dropout      |                 0.5795301884180173                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 77%|███████████████████████████████▋         | 116/150 [19:01:38<8:49:15, 934.00s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d514febd58014efaadc78cc61c7b3436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.09\t\t0.06\t\t0.358\t\t0.842\t\t1.04m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.05\t\t0.349\t\t0.833\t\t1.01m - 2.1m / 36.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.492\t\t0.902\t\t1.07m - 3.1m / 35.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.469\t\t0.899\t\t1.08m - 4.3m / 37.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.03\t\t0.465\t\t0.896\t\t1.01m - 5.3m / 37.7m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.469\t\t0.897\t\t0.99m - 6.3m / 35.5m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.533\t\t0.919\t\t1.01m - 7.3m / 34.9m                                                                   \n",
      "8\t112k\t0.01\t\t0.03\t\t0.501\t\t0.910\t\t1.00m - 8.3m / 35.5m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.532\t\t0.920\t\t1.01m - 9.3m / 35.3m                                                                  \n",
      "10\t140k\t0.01\t\t0.03\t\t0.491\t\t0.905\t\t1.01m - 10.4m / 35.6m                                                                \n",
      "11\t155k\t0.01\t\t0.03\t\t0.551\t\t0.924\t\t1.01m - 11.4m / 35.6m                                                                \n",
      "12\t169k\t0.01\t\t0.03\t\t0.497\t\t0.908\t\t0.98m - 12.4m / 35.6m                                                                \n",
      "13\t183k\t0.01\t\t0.03\t\t0.529\t\t0.919\t\t0.99m - 13.4m / 35.0m                                                                \n",
      "14\t197k\t0.01\t\t0.03\t\t0.521\t\t0.914\t\t0.99m - 14.4m / 35.2m                                                                \n",
      "15\t211k\t0.00\t\t0.03\t\t0.516\t\t0.914\t\t0.99m - 15.4m / 35.1m                                                                \n",
      "16\t225k\t0.00\t\t0.03\t\t0.517\t\t0.913\t\t0.99m - 16.4m / 35.3m                                                                \n",
      "VAL f1\t0.5508783115939965 - (0.5508783115939965)                                                                       \n",
      "VAL loss\t0.022495315415618083                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.022495315415618083\n",
      "        | \\     )|_\tf1: 0.5508783115939965\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\83 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 11.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         11                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0038438216256070734               |\n",
      "|  noam_learning_rate_warmup   |                        8459                       |\n",
      "|  noam_learning_rate_factor   |                 1.1025022872568957                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.0987973684477061                |\n",
      "|     pointwise_layer_size     |                        200                        |\n",
      "|      last_layer_dropout      |                 0.6923865907858916                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 78%|███████████████████████████████▉         | 117/150 [19:18:54<8:50:32, 964.62s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d101373ef28c410c89ef4fd677bb36ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.05\t\t0.542\t\t0.889\t\t1.95m - 2.0m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.610\t\t0.915\t\t1.93m - 3.9m / 68.4m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.607\t\t0.914\t\t1.80m - 5.8m / 67.8m                                                                   \n",
      "4\t56k\t0.02\t\t0.04\t\t0.579\t\t0.905\t\t1.80m - 7.6m / 63.6m                                                                   \n",
      "5\t70k\t0.02\t\t0.04\t\t0.565\t\t0.900\t\t1.80m - 9.4m / 63.6m                                                                   \n",
      "6\t84k\t0.02\t\t0.04\t\t0.589\t\t0.909\t\t1.80m - 11.2m / 63.5m                                                                  \n",
      "7\t98k\t0.02\t\t0.05\t\t0.630\t\t0.922\t\t1.81m - 13.1m / 63.5m                                                                  \n",
      "8\t112k\t0.02\t\t0.04\t\t0.549\t\t0.903\t\t1.83m - 14.9m / 63.7m                                                                 \n",
      "9\t126k\t0.02\t\t0.04\t\t0.619\t\t0.918\t\t1.91m - 16.8m / 64.3m                                                                 \n",
      "10\t140k\t0.02\t\t0.04\t\t0.585\t\t0.905\t\t1.86m - 18.7m / 66.4m                                                                \n",
      "11\t155k\t0.02\t\t0.04\t\t0.627\t\t0.918\t\t1.83m - 20.6m / 65.3m                                                                \n",
      "12\t169k\t0.02\t\t0.04\t\t0.624\t\t0.919\t\t1.82m - 22.4m / 64.6m                                                                \n",
      "VAL f1\t0.6295342595097979 - (0.6295342595097979)                                                                       \n",
      "VAL loss\t0.03311453708094981                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.03311453708094981\n",
      "        | \\     )|_\tf1: 0.6295342595097979\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\84 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 11.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         11                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03913887868776048                |\n",
      "|  noam_learning_rate_warmup   |                        6446                       |\n",
      "|  noam_learning_rate_factor   |                0.07073052023944502                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.37303443482626686                |\n",
      "|     pointwise_layer_size     |                        172                        |\n",
      "|      last_layer_dropout      |                 0.4344570984331436                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 79%|███████████████████████████████▍        | 118/150 [19:42:39<9:48:00, 1102.51s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a96532f947d4cb8b8caec283b08f0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.16\t\t0.14\t\t0.405\t\t0.824\t\t1.38m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.13\t\t0.10\t\t0.394\t\t0.822\t\t1.33m - 2.7m / 48.3m                                                                   \n",
      "3\t42k\t0.11\t\t0.08\t\t0.436\t\t0.842\t\t1.34m - 4.1m / 46.6m                                                                   \n",
      "4\t56k\t0.08\t\t0.08\t\t0.420\t\t0.829\t\t1.33m - 5.4m / 47.1m                                                                   \n",
      "5\t70k\t0.06\t\t0.07\t\t0.482\t\t0.861\t\t1.36m - 6.8m / 46.6m                                                                   \n",
      "6\t84k\t0.05\t\t0.06\t\t0.501\t\t0.872\t\t1.39m - 8.2m / 47.5m                                                                   \n",
      "7\t98k\t0.04\t\t0.06\t\t0.521\t\t0.882\t\t1.34m - 9.6m / 48.5m                                                                   \n",
      "8\t112k\t0.04\t\t0.06\t\t0.490\t\t0.867\t\t1.35m - 10.9m / 47.2m                                                                 \n",
      "9\t126k\t0.04\t\t0.05\t\t0.582\t\t0.905\t\t1.33m - 12.3m / 47.4m                                                                 \n",
      "10\t140k\t0.03\t\t0.06\t\t0.484\t\t0.864\t\t1.32m - 13.7m / 47.0m                                                                \n",
      "11\t155k\t0.03\t\t0.05\t\t0.561\t\t0.897\t\t1.31m - 15.0m / 46.8m                                                                \n",
      "12\t169k\t0.03\t\t0.05\t\t0.568\t\t0.900\t\t1.32m - 16.4m / 46.5m                                                                \n",
      "13\t183k\t0.03\t\t0.05\t\t0.561\t\t0.896\t\t1.33m - 17.7m / 46.8m                                                                \n",
      "14\t197k\t0.03\t\t0.05\t\t0.542\t\t0.890\t\t1.32m - 19.0m / 47.0m                                                                \n",
      "VAL f1\t0.5823548496696108 - (0.5823548496696108)                                                                       \n",
      "VAL loss\t0.04650327643203373                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04650327643203373\n",
      "        | \\     )|_\tf1: 0.5823548496696108\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\85 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 46.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         46                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               5.5088016754441935e-05              |\n",
      "|  noam_learning_rate_warmup   |                        7602                       |\n",
      "|  noam_learning_rate_factor   |                 1.782897552854469                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.35658146183672684                |\n",
      "|     pointwise_layer_size     |                        234                        |\n",
      "|      last_layer_dropout      |                 0.219511058325506                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 79%|███████████████████████████████▋        | 119/150 [20:02:46<9:45:55, 1134.04s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d728ea742e249c48e7e6c51c5b66d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.131\t\t0.800\t\t0.29m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.148\t\t0.826\t\t0.30m - 0.6m / 10.3m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.177\t\t0.856\t\t0.30m - 0.9m / 10.7m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.180\t\t0.859\t\t0.31m - 1.3m / 10.4m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.193\t\t0.867\t\t0.31m - 1.6m / 10.8m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.184\t\t0.864\t\t0.32m - 1.9m / 10.9m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.202\t\t0.875\t\t0.30m - 2.3m / 11.1m                                                                   \n",
      "8\t113k\t0.01\t\t0.01\t\t0.199\t\t0.872\t\t0.30m - 2.6m / 10.7m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.210\t\t0.880\t\t0.31m - 2.9m / 10.7m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.231\t\t0.891\t\t0.31m - 3.3m / 10.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.188\t\t0.864\t\t0.30m - 3.6m / 11.1m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.203\t\t0.873\t\t0.29m - 3.9m / 10.8m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.222\t\t0.883\t\t0.29m - 4.2m / 10.6m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.223\t\t0.884\t\t0.28m - 4.5m / 10.6m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.207\t\t0.875\t\t0.29m - 4.8m / 10.5m                                                                 \n",
      "VAL f1\t0.23089395467735688 - (0.23089395467735688)                                                                     \n",
      "VAL loss\t0.008604704852364795                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.008604704852364795\n",
      "        | \\     )|_\tf1: 0.23089395467735688\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\86 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03983469326620705                |\n",
      "|  noam_learning_rate_warmup   |                        7938                       |\n",
      "|  noam_learning_rate_factor   |                 3.348790100371731                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.29785863863113554                |\n",
      "|     pointwise_layer_size     |                        168                        |\n",
      "|      last_layer_dropout      |                 0.5663261689056943                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 80%|████████████████████████████████▊        | 120/150 [20:08:08<7:25:09, 890.30s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65ef8888e1a4ee3b69b3e2b4ba77776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.04\t\t0.347\t\t0.840\t\t1.36m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.04\t\t0.343\t\t0.844\t\t1.36m - 2.7m / 47.5m                                                                   \n",
      "3\t42k\t0.02\t\t0.04\t\t0.372\t\t0.863\t\t1.34m - 4.1m / 47.7m                                                                   \n",
      "4\t56k\t0.02\t\t0.04\t\t0.325\t\t0.834\t\t1.31m - 5.4m / 47.1m                                                                   \n",
      "5\t70k\t0.03\t\t0.06\t\t0.316\t\t0.830\t\t1.31m - 6.7m / 46.1m                                                                   \n",
      "6\t84k\t0.04\t\t0.07\t\t0.227\t\t0.751\t\t1.30m - 8.1m / 46.1m                                                                   \n",
      "7\t98k\t0.06\t\t0.08\t\t0.142\t\t0.618\t\t1.30m - 9.4m / 45.8m                                                                   \n",
      "8\t112k\t0.07\t\t0.07\t\t0.181\t\t0.672\t\t1.31m - 10.7m / 45.8m                                                                 \n",
      "VAL f1\t0.37169170929185047 - (0.37169170929185047)                                                                     \n",
      "VAL loss\t0.0360612597695424                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0360612597695424\n",
      "        | \\     )|_\tf1: 0.37169170929185047\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\87 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 50.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         50                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04672814946456588                |\n",
      "|  noam_learning_rate_warmup   |                        3905                       |\n",
      "|  noam_learning_rate_factor   |                 0.7218607514635321                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5297995335144373                |\n",
      "|     pointwise_layer_size     |                        329                        |\n",
      "|      last_layer_dropout      |                 0.2150131112900331                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 81%|█████████████████████████████████        | 121/150 [20:19:47<6:42:32, 832.86s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989325d76e5f46e7a6fca64f6b33dbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.099\t\t0.773\t\t0.45m - 0.4m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.114\t\t0.799\t\t0.45m - 0.9m / 15.6m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.117\t\t0.809\t\t0.45m - 1.4m / 15.9m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.116\t\t0.801\t\t0.46m - 1.9m / 15.7m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.120\t\t0.807\t\t0.43m - 2.3m / 16.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.117\t\t0.808\t\t0.42m - 2.8m / 15.2m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.132\t\t0.828\t\t0.43m - 3.2m / 14.8m                                                                   \n",
      "8\t112k\t0.00\t\t0.02\t\t0.130\t\t0.829\t\t0.42m - 3.6m / 15.2m                                                                  \n",
      "9\t126k\t0.00\t\t0.02\t\t0.136\t\t0.837\t\t0.43m - 4.1m / 15.0m                                                                  \n",
      "10\t140k\t0.00\t\t0.02\t\t0.111\t\t0.803\t\t0.44m - 4.6m / 15.2m                                                                 \n",
      "11\t155k\t0.00\t\t0.02\t\t0.142\t\t0.842\t\t0.43m - 5.0m / 15.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.02\t\t0.150\t\t0.850\t\t0.41m - 5.5m / 15.3m                                                                 \n",
      "13\t183k\t0.00\t\t0.02\t\t0.134\t\t0.834\t\t0.41m - 5.9m / 14.9m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.142\t\t0.844\t\t0.41m - 6.3m / 14.9m                                                                 \n",
      "15\t211k\t0.00\t\t0.02\t\t0.143\t\t0.848\t\t0.41m - 6.7m / 14.9m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.148\t\t0.851\t\t0.41m - 7.1m / 15.0m                                                                 \n",
      "17\t239k\t0.00\t\t0.01\t\t0.140\t\t0.844\t\t0.41m - 7.6m / 14.9m                                                                 \n",
      "VAL f1\t0.14965509928133316 - (0.14965509928133316)                                                                     \n",
      "VAL loss\t0.01327599617652595                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01327599617652595\n",
      "        | \\     )|_\tf1: 0.14965509928133316\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\88 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 33.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         33                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.008439438129388986               |\n",
      "|  noam_learning_rate_warmup   |                        6366                       |\n",
      "|  noam_learning_rate_factor   |                 1.674189512842192                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7992247933554941                |\n",
      "|     pointwise_layer_size     |                        170                        |\n",
      "|      last_layer_dropout      |                 0.6147682230164682                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 81%|█████████████████████████████████▎       | 122/150 [20:27:58<5:40:48, 730.29s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6cfb747d8d47fb85ed9f82b13d0875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.07\t\t0.178\t\t0.809\t\t0.55m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.06\t\t0.178\t\t0.809\t\t0.56m - 1.1m / 19.3m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.178\t\t0.809\t\t0.57m - 1.7m / 19.6m                                                                   \n",
      "4\t56k\t0.04\t\t0.06\t\t0.192\t\t0.817\t\t0.56m - 2.3m / 19.9m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.172\t\t0.801\t\t0.55m - 2.9m / 19.7m                                                                   \n",
      "6\t84k\t0.03\t\t0.04\t\t0.169\t\t0.794\t\t0.55m - 3.4m / 19.4m                                                                   \n",
      "7\t98k\t0.03\t\t0.05\t\t0.169\t\t0.792\t\t0.55m - 4.0m / 19.3m                                                                   \n",
      "8\t112k\t0.03\t\t0.05\t\t0.154\t\t0.776\t\t0.55m - 4.5m / 19.4m                                                                  \n",
      "9\t127k\t0.02\t\t0.05\t\t0.176\t\t0.801\t\t0.55m - 5.1m / 19.4m                                                                  \n",
      "VAL f1\t0.19173685129208184 - (0.19173685129208184)                                                                     \n",
      "VAL loss\t0.04165375323918824                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04165375323918824\n",
      "        | \\     )|_\tf1: 0.19173685129208184\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\89 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 13.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         13                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.003447509943699213               |\n",
      "|  noam_learning_rate_warmup   |                        5683                       |\n",
      "|  noam_learning_rate_factor   |                 2.8053367314975293                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.7206516855572559                |\n",
      "|     pointwise_layer_size     |                        147                        |\n",
      "|      last_layer_dropout      |                 0.7101444823257613                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 82%|█████████████████████████████████▌       | 123/150 [20:33:34<4:35:30, 612.24s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d175b6f2fa4255bc847b10e4ea5d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.13\t\t0.14\t\t0.332\t\t0.804\t\t1.66m - 1.7m / 0.0m                                                                    \n",
      "2\t28k\t0.10\t\t0.12\t\t0.361\t\t0.818\t\t1.62m - 3.3m / 58.0m                                                                   \n",
      "3\t42k\t0.09\t\t0.10\t\t0.391\t\t0.837\t\t1.49m - 4.8m / 56.8m                                                                   \n",
      "4\t56k\t0.08\t\t0.14\t\t0.396\t\t0.839\t\t1.50m - 6.3m / 52.5m                                                                   \n",
      "5\t70k\t0.08\t\t0.13\t\t0.381\t\t0.827\t\t1.46m - 7.8m / 53.0m                                                                   \n",
      "6\t84k\t0.08\t\t0.14\t\t0.382\t\t0.825\t\t1.46m - 9.3m / 51.7m                                                                   \n",
      "7\t98k\t0.08\t\t0.12\t\t0.320\t\t0.793\t\t1.45m - 10.7m / 51.5m                                                                  \n",
      "8\t112k\t0.08\t\t0.17\t\t0.375\t\t0.828\t\t1.45m - 12.2m / 51.4m                                                                 \n",
      "9\t126k\t0.08\t\t0.11\t\t0.352\t\t0.815\t\t1.48m - 13.7m / 51.4m                                                                 \n",
      "VAL f1\t0.3960999863921929 - (0.3960999863921929)                                                                       \n",
      "VAL loss\t0.09696468512828534                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.09696468512828534\n",
      "        | \\     )|_\tf1: 0.3960999863921929\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\90 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 48.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         48                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.03724367563699976                |\n",
      "|  noam_learning_rate_warmup   |                        2809                       |\n",
      "|  noam_learning_rate_factor   |                 3.6589253845062806                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2549258222875989                |\n",
      "|     pointwise_layer_size     |                        302                        |\n",
      "|      last_layer_dropout      |                 0.232368262208672                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 83%|█████████████████████████████████▉       | 124/150 [20:48:22<5:01:08, 694.95s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818d68daccd74c12bc3f21cd9415415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.02\t\t0.180\t\t0.861\t\t0.76m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.200\t\t0.869\t\t0.80m - 1.7m / 26.8m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.205\t\t0.880\t\t0.79m - 2.5m / 28.2m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.166\t\t0.849\t\t0.79m - 3.3m / 27.8m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.137\t\t0.818\t\t0.74m - 4.0m / 27.7m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.079\t\t0.729\t\t0.73m - 4.8m / 26.2m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.062\t\t0.623\t\t0.73m - 5.5m / 26.0m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.095\t\t0.750\t\t0.75m - 6.3m / 26.0m                                                                  \n",
      "VAL f1\t0.20491313763851773 - (0.20491313763851773)                                                                     \n",
      "VAL loss\t0.0104681015486587                                                                                            \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.0104681015486587\n",
      "        | \\     )|_\tf1: 0.20491313763851773\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\91 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 31.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         31                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.19209743923524045                |\n",
      "|  noam_learning_rate_warmup   |                        5344                       |\n",
      "|  noam_learning_rate_factor   |                 2.455199804441853                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.33306945487811385                |\n",
      "|     pointwise_layer_size     |                         60                        |\n",
      "|      last_layer_dropout      |                 0.581849406259994                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 83%|██████████████████████████████████▏      | 125/150 [20:55:24<4:15:16, 612.66s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25036028e0c8411693ed864134b634b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.145\t\t0.778\t\t1.00m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.131\t\t0.752\t\t0.97m - 2.0m / 35.1m                                                                   \n",
      "3\t42k\t0.01\t\t0.02\t\t0.159\t\t0.803\t\t0.96m - 3.0m / 34.1m                                                                   \n",
      "4\t56k\t0.01\t\t0.03\t\t0.131\t\t0.758\t\t0.94m - 4.0m / 33.8m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.253\t\t0.872\t\t0.96m - 4.9m / 33.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.183\t\t0.821\t\t0.95m - 5.9m / 33.6m                                                                   \n",
      "7\t98k\t0.01\t\t0.03\t\t0.158\t\t0.789\t\t0.95m - 6.9m / 33.5m                                                                   \n",
      "8\t112k\t0.02\t\t0.03\t\t0.167\t\t0.810\t\t0.95m - 7.8m / 33.6m                                                                  \n",
      "9\t126k\t0.02\t\t0.04\t\t0.208\t\t0.840\t\t0.98m - 8.8m / 33.4m                                                                  \n",
      "10\t140k\t0.03\t\t0.04\t\t0.047\t\t0.616\t\t1.02m - 9.8m / 34.2m                                                                 \n",
      "VAL f1\t0.2527440346786001 - (0.2527440346786001)                                                                       \n",
      "VAL loss\t0.016306943612347732                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.016306943612347732\n",
      "        | \\     )|_\tf1: 0.2527440346786001\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\92 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00037095019304674747              |\n",
      "|  noam_learning_rate_warmup   |                        7991                       |\n",
      "|  noam_learning_rate_factor   |                 0.6407899017787531                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.48292524557335553                |\n",
      "|     pointwise_layer_size     |                        191                        |\n",
      "|      last_layer_dropout      |                 0.3113258529602318                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 84%|██████████████████████████████████▍      | 126/150 [21:06:10<4:09:14, 623.10s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47da178093b44b119ab780282ea54a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.04\t\t0.122\t\t0.800\t\t0.27m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.122\t\t0.800\t\t0.28m - 0.6m / 9.6m                                                                    \n",
      "3\t42k\t0.03\t\t0.02\t\t0.161\t\t0.843\t\t0.28m - 0.9m / 9.8m                                                                    \n",
      "4\t56k\t0.02\t\t0.02\t\t0.164\t\t0.851\t\t0.27m - 1.2m / 9.9m                                                                    \n",
      "5\t70k\t0.02\t\t0.02\t\t0.178\t\t0.864\t\t0.28m - 1.5m / 9.6m                                                                    \n",
      "6\t84k\t0.01\t\t0.02\t\t0.176\t\t0.863\t\t0.27m - 1.7m / 9.9m                                                                    \n",
      "7\t98k\t0.01\t\t0.02\t\t0.202\t\t0.882\t\t0.28m - 2.0m / 9.7m                                                                    \n",
      "8\t113k\t0.01\t\t0.02\t\t0.203\t\t0.880\t\t0.27m - 2.3m / 9.9m                                                                   \n",
      "9\t127k\t0.01\t\t0.01\t\t0.208\t\t0.883\t\t0.27m - 2.6m / 9.8m                                                                   \n",
      "10\t141k\t0.01\t\t0.01\t\t0.214\t\t0.886\t\t0.28m - 2.9m / 9.7m                                                                  \n",
      "11\t155k\t0.01\t\t0.01\t\t0.218\t\t0.888\t\t0.27m - 3.2m / 10.0m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.228\t\t0.894\t\t0.28m - 3.5m / 9.6m                                                                  \n",
      "13\t183k\t0.00\t\t0.01\t\t0.239\t\t0.899\t\t0.27m - 3.8m / 10.0m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.234\t\t0.898\t\t0.28m - 4.1m / 9.7m                                                                  \n",
      "15\t211k\t0.00\t\t0.01\t\t0.216\t\t0.891\t\t0.28m - 4.4m / 9.9m                                                                  \n",
      "16\t225k\t0.00\t\t0.01\t\t0.220\t\t0.892\t\t0.28m - 4.7m / 9.9m                                                                  \n",
      "17\t239k\t0.00\t\t0.01\t\t0.220\t\t0.892\t\t0.28m - 5.0m / 10.1m                                                                 \n",
      "18\t253k\t0.00\t\t0.01\t\t0.241\t\t0.901\t\t0.28m - 5.2m / 9.9m                                                                  \n",
      "19\t267k\t0.00\t\t0.01\t\t0.209\t\t0.885\t\t0.28m - 5.5m / 10.0m                                                                 \n",
      "20\t281k\t0.00\t\t0.01\t\t0.232\t\t0.897\t\t0.27m - 5.8m / 10.0m                                                                 \n",
      "21\t295k\t0.00\t\t0.01\t\t0.231\t\t0.897\t\t0.27m - 6.1m / 9.9m                                                                  \n",
      "22\t309k\t0.00\t\t0.01\t\t0.218\t\t0.890\t\t0.27m - 6.4m / 9.9m                                                                  \n",
      "23\t323k\t0.00\t\t0.01\t\t0.248\t\t0.903\t\t0.27m - 6.7m / 9.9m                                                                  \n",
      "24\t338k\t0.00\t\t0.01\t\t0.235\t\t0.896\t\t0.28m - 7.0m / 9.9m                                                                  \n",
      "25\t352k\t0.00\t\t0.01\t\t0.218\t\t0.890\t\t0.28m - 7.3m / 10.0m                                                                 \n",
      "26\t366k\t0.00\t\t0.01\t\t0.231\t\t0.895\t\t0.28m - 7.5m / 10.0m                                                                 \n",
      "27\t380k\t0.00\t\t0.01\t\t0.243\t\t0.901\t\t0.28m - 7.8m / 10.1m                                                                 \n",
      "28\t394k\t0.00\t\t0.01\t\t0.208\t\t0.887\t\t0.28m - 8.1m / 10.1m                                                                 \n",
      "VAL f1\t0.24762021780378116 - (0.24762021780378116)                                                                     \n",
      "VAL loss\t0.010017928626800216                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.010017928626800216\n",
      "        | \\     )|_\tf1: 0.24762021780378116\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\93 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0004489372405028469               |\n",
      "|  noam_learning_rate_warmup   |                        8993                       |\n",
      "|  noam_learning_rate_factor   |                 1.266048681560082                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.010528820483666747               |\n",
      "|     pointwise_layer_size     |                        186                        |\n",
      "|      last_layer_dropout      |                 0.7374750343969017                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 85%|██████████████████████████████████▋      | 127/150 [21:14:45<3:46:22, 590.53s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f013ada3e34d86b5341395d72e9ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.128\t\t0.786\t\t0.64m - 0.6m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.01\t\t0.215\t\t0.869\t\t0.64m - 1.3m / 22.6m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.237\t\t0.884\t\t0.63m - 2.0m / 22.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.243\t\t0.883\t\t0.64m - 2.6m / 22.2m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.275\t\t0.900\t\t0.63m - 3.3m / 22.6m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.268\t\t0.898\t\t0.63m - 3.9m / 22.2m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.271\t\t0.899\t\t0.63m - 4.6m / 22.3m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.279\t\t0.905\t\t0.68m - 5.3m / 22.3m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.261\t\t0.894\t\t0.67m - 6.0m / 23.6m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.258\t\t0.893\t\t0.62m - 6.6m / 23.4m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.260\t\t0.897\t\t0.62m - 7.2m / 22.1m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.285\t\t0.906\t\t0.62m - 7.9m / 22.1m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.264\t\t0.899\t\t0.62m - 8.5m / 22.2m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.259\t\t0.897\t\t0.62m - 9.1m / 22.1m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.264\t\t0.898\t\t0.62m - 9.8m / 22.2m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.271\t\t0.902\t\t0.61m - 10.4m / 22.2m                                                                \n",
      "17\t239k\t0.00\t\t0.01\t\t0.237\t\t0.883\t\t0.64m - 11.0m / 22.1m                                                                \n",
      "VAL f1\t0.285274037678765 - (0.285274037678765)                                                                         \n",
      "VAL loss\t0.009111451244408052                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009111451244408052\n",
      "        | \\     )|_\tf1: 0.285274037678765\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\94 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 58.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         58                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.012408102677702123               |\n",
      "|  noam_learning_rate_warmup   |                        8358                       |\n",
      "|  noam_learning_rate_factor   |                 0.5021276280176691                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5145951331256304                |\n",
      "|     pointwise_layer_size     |                        312                        |\n",
      "|      last_layer_dropout      |                 0.3699798223635363                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 85%|██████████████████████████████████▉      | 128/150 [21:26:21<3:48:05, 622.09s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea46d6f1304d47b689b13a0bae8a1bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.090\t\t0.780\t\t0.24m - 0.2m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.090\t\t0.780\t\t0.24m - 0.5m / 8.3m                                                                    \n",
      "3\t42k\t0.03\t\t0.02\t\t0.092\t\t0.785\t\t0.24m - 0.7m / 8.4m                                                                    \n",
      "4\t56k\t0.02\t\t0.02\t\t0.111\t\t0.816\t\t0.23m - 1.0m / 8.4m                                                                    \n",
      "5\t70k\t0.02\t\t0.01\t\t0.119\t\t0.831\t\t0.23m - 1.3m / 8.3m                                                                    \n",
      "6\t85k\t0.02\t\t0.01\t\t0.126\t\t0.842\t\t0.23m - 1.5m / 8.2m                                                                    \n",
      "7\t99k\t0.01\t\t0.01\t\t0.125\t\t0.840\t\t0.24m - 1.8m / 8.3m                                                                    \n",
      "8\t113k\t0.01\t\t0.01\t\t0.136\t\t0.853\t\t0.23m - 2.0m / 8.4m                                                                   \n",
      "9\t127k\t0.01\t\t0.02\t\t0.142\t\t0.861\t\t0.23m - 2.3m / 8.3m                                                                   \n",
      "10\t141k\t0.01\t\t0.01\t\t0.142\t\t0.860\t\t0.23m - 2.5m / 8.3m                                                                  \n",
      "11\t155k\t0.01\t\t0.01\t\t0.142\t\t0.859\t\t0.23m - 2.8m / 8.4m                                                                  \n",
      "12\t169k\t0.01\t\t0.01\t\t0.148\t\t0.865\t\t0.23m - 3.0m / 8.3m                                                                  \n",
      "13\t183k\t0.01\t\t0.01\t\t0.142\t\t0.860\t\t0.23m - 3.3m / 8.4m                                                                  \n",
      "14\t197k\t0.01\t\t0.01\t\t0.147\t\t0.865\t\t0.23m - 3.5m / 8.4m                                                                  \n",
      "15\t211k\t0.01\t\t0.01\t\t0.149\t\t0.866\t\t0.23m - 3.7m / 8.4m                                                                  \n",
      "16\t226k\t0.00\t\t0.01\t\t0.163\t\t0.880\t\t0.23m - 4.0m / 8.4m                                                                  \n",
      "17\t240k\t0.00\t\t0.01\t\t0.161\t\t0.878\t\t0.23m - 4.3m / 8.4m                                                                  \n",
      "18\t254k\t0.00\t\t0.01\t\t0.154\t\t0.872\t\t0.23m - 4.5m / 8.5m                                                                  \n",
      "19\t268k\t0.00\t\t0.01\t\t0.156\t\t0.875\t\t0.23m - 4.8m / 8.5m                                                                  \n",
      "20\t282k\t0.00\t\t0.01\t\t0.152\t\t0.871\t\t0.23m - 5.0m / 8.5m                                                                  \n",
      "21\t296k\t0.00\t\t0.01\t\t0.158\t\t0.879\t\t0.23m - 5.3m / 8.5m                                                                  \n",
      "VAL f1\t0.162962931018261 - (0.162962931018261)                                                                         \n",
      "VAL loss\t0.009551243343842945                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009551243343842945\n",
      "        | \\     )|_\tf1: 0.162962931018261\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\95 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 38.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         38                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.003498916633672975               |\n",
      "|  noam_learning_rate_warmup   |                        7705                       |\n",
      "|  noam_learning_rate_factor   |                 3.557950435532404                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.15760584421671187                |\n",
      "|     pointwise_layer_size     |                        209                        |\n",
      "|      last_layer_dropout      |                 0.5885450999139703                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 86%|███████████████████████████████████▎     | 129/150 [21:32:00<3:08:03, 537.33s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675b5e191df9473f9edae544ed032ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.180\t\t0.828\t\t0.66m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.139\t\t0.792\t\t0.67m - 1.3m / 23.1m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.200\t\t0.858\t\t0.67m - 2.0m / 23.5m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.175\t\t0.837\t\t0.70m - 2.7m / 23.4m                                                                   \n",
      "5\t70k\t0.00\t\t0.02\t\t0.180\t\t0.839\t\t0.71m - 3.5m / 24.6m                                                                   \n",
      "6\t84k\t0.00\t\t0.02\t\t0.187\t\t0.849\t\t0.69m - 4.2m / 24.9m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.241\t\t0.880\t\t0.66m - 4.9m / 24.1m                                                                   \n",
      "8\t112k\t0.00\t\t0.02\t\t0.185\t\t0.851\t\t0.65m - 5.5m / 23.2m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.283\t\t0.895\t\t0.65m - 6.2m / 23.1m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.228\t\t0.872\t\t0.64m - 6.8m / 23.2m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.196\t\t0.852\t\t0.64m - 7.5m / 22.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.180\t\t0.841\t\t0.64m - 8.2m / 22.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.178\t\t0.839\t\t0.64m - 8.8m / 23.0m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.203\t\t0.859\t\t0.65m - 9.5m / 22.8m                                                                 \n",
      "VAL f1\t0.2831425512809455 - (0.2831425512809455)                                                                       \n",
      "VAL loss\t0.013197811920027112                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.013197811920027112\n",
      "        | \\     )|_\tf1: 0.2831425512809455\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\96 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 28.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         28                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.00013375855610559185              |\n",
      "|  noam_learning_rate_warmup   |                        7378                       |\n",
      "|  noam_learning_rate_factor   |                 2.820057537026812                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.46334909112051187                |\n",
      "|     pointwise_layer_size     |                        203                        |\n",
      "|      last_layer_dropout      |                0.23936339491864767                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 87%|███████████████████████████████████▌     | 130/150 [21:42:00<3:05:19, 555.99s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150ac93343974a88b56b45215a0e774c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.03\t\t0.220\t\t0.827\t\t0.67m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.233\t\t0.843\t\t0.67m - 1.4m / 23.5m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.207\t\t0.828\t\t0.66m - 2.0m / 23.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.04\t\t0.242\t\t0.852\t\t0.66m - 2.7m / 23.1m                                                                   \n",
      "5\t70k\t0.01\t\t0.04\t\t0.210\t\t0.827\t\t0.66m - 3.4m / 23.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.251\t\t0.859\t\t0.65m - 4.1m / 23.3m                                                                   \n",
      "7\t98k\t0.01\t\t0.03\t\t0.241\t\t0.852\t\t0.65m - 4.7m / 23.0m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.310\t\t0.888\t\t0.63m - 5.4m / 22.9m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.308\t\t0.884\t\t0.63m - 6.0m / 22.5m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.286\t\t0.870\t\t0.64m - 6.7m / 22.5m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.224\t\t0.852\t\t0.68m - 7.4m / 22.7m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.273\t\t0.870\t\t0.68m - 8.1m / 23.8m                                                                 \n",
      "13\t183k\t0.01\t\t0.03\t\t0.314\t\t0.887\t\t0.70m - 8.8m / 23.8m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.308\t\t0.881\t\t0.68m - 9.5m / 24.2m                                                                 \n",
      "15\t211k\t0.01\t\t0.02\t\t0.326\t\t0.892\t\t0.63m - 10.1m / 23.9m                                                                \n",
      "16\t225k\t0.01\t\t0.02\t\t0.292\t\t0.874\t\t0.63m - 10.8m / 22.9m                                                                \n",
      "17\t239k\t0.01\t\t0.02\t\t0.306\t\t0.885\t\t0.63m - 11.4m / 22.8m                                                                \n",
      "18\t253k\t0.01\t\t0.02\t\t0.271\t\t0.865\t\t0.63m - 12.1m / 22.8m                                                                \n",
      "19\t267k\t0.01\t\t0.02\t\t0.269\t\t0.862\t\t0.63m - 12.7m / 22.8m                                                                \n",
      "20\t281k\t0.01\t\t0.04\t\t0.292\t\t0.876\t\t0.63m - 13.4m / 22.8m                                                                \n",
      "VAL f1\t0.3260788250817392 - (0.3260788250817392)                                                                       \n",
      "VAL loss\t0.01888722751996911                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01888722751996911\n",
      "        | \\     )|_\tf1: 0.3260788250817392\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\97 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 35.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         35                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0001846143287469088               |\n",
      "|  noam_learning_rate_warmup   |                        4988                       |\n",
      "|  noam_learning_rate_factor   |                 3.869451658707882                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.7560861075752585                |\n",
      "|     pointwise_layer_size     |                        260                        |\n",
      "|      last_layer_dropout      |                0.27411367727315483                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 87%|███████████████████████████████████▊     | 131/150 [21:56:06<3:23:35, 642.94s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d288c4f47c42443e880eeade2e6ba5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.05\t\t0.155\t\t0.798\t\t0.79m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.05\t\t0.155\t\t0.798\t\t0.78m - 1.6m / 27.9m                                                                   \n",
      "3\t42k\t0.04\t\t0.05\t\t0.129\t\t0.730\t\t0.76m - 2.4m / 27.3m                                                                   \n",
      "4\t56k\t0.04\t\t0.05\t\t0.105\t\t0.743\t\t0.77m - 3.2m / 26.9m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.111\t\t0.749\t\t0.77m - 4.0m / 27.0m                                                                   \n",
      "6\t84k\t0.04\t\t0.04\t\t0.101\t\t0.749\t\t0.76m - 4.8m / 27.1m                                                                   \n",
      "VAL f1\t0.15492418383919282 - (0.15492418383919282)                                                                     \n",
      "VAL loss\t0.04175147136784919                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.04175147136784919\n",
      "        | \\     )|_\tf1: 0.15492418383919282\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\98 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 41.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         41                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.004019415829081182               |\n",
      "|  noam_learning_rate_warmup   |                        7271                       |\n",
      "|  noam_learning_rate_factor   |                 3.6466859171128987                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.19339383149094636                |\n",
      "|     pointwise_layer_size     |                        237                        |\n",
      "|      last_layer_dropout      |                0.29249273045291607                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 88%|████████████████████████████████████     | 132/150 [22:01:35<2:44:37, 548.75s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3619dd532fcd470289c9c786363e735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.02\t\t0.195\t\t0.849\t\t0.33m - 0.3m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.263\t\t0.897\t\t0.33m - 0.7m / 11.4m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.264\t\t0.896\t\t0.32m - 1.0m / 11.6m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.238\t\t0.885\t\t0.32m - 1.4m / 11.2m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.292\t\t0.908\t\t0.33m - 1.7m / 11.4m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.260\t\t0.897\t\t0.31m - 2.0m / 11.5m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.262\t\t0.899\t\t0.31m - 2.3m / 11.1m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.258\t\t0.896\t\t0.33m - 2.7m / 11.2m                                                                  \n",
      "9\t127k\t0.00\t\t0.02\t\t0.230\t\t0.887\t\t0.33m - 3.0m / 11.6m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.282\t\t0.909\t\t0.34m - 3.4m / 11.6m                                                                 \n",
      "VAL f1\t0.29166110585872956 - (0.29166110585872956)                                                                     \n",
      "VAL loss\t0.009881682269752206                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009881682269752206\n",
      "        | \\     )|_\tf1: 0.29166110585872956\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\99 \n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 63.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         63                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0006680555429078888               |\n",
      "|  noam_learning_rate_warmup   |                        3937                       |\n",
      "|  noam_learning_rate_factor   |                 3.4284416074112003                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.6901657677801842                |\n",
      "|     pointwise_layer_size     |                        309                        |\n",
      "|      last_layer_dropout      |                0.23371173971255585                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 89%|████████████████████████████████████▎    | 133/150 [22:05:31<2:08:58, 455.18s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685a66f8112442a689382fffdbc1b40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.089\t\t0.783\t\t0.50m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.089\t\t0.783\t\t0.49m - 1.0m / 17.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.091\t\t0.793\t\t0.47m - 1.5m / 17.1m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.105\t\t0.810\t\t0.47m - 2.0m / 16.5m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.114\t\t0.823\t\t0.46m - 2.5m / 16.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.124\t\t0.836\t\t0.46m - 3.0m / 16.3m                                                                   \n",
      "7\t98k\t0.01\t\t0.01\t\t0.126\t\t0.840\t\t0.46m - 3.4m / 16.3m                                                                   \n",
      "8\t112k\t0.01\t\t0.01\t\t0.125\t\t0.837\t\t0.45m - 3.9m / 16.3m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.139\t\t0.855\t\t0.45m - 4.4m / 16.0m                                                                  \n",
      "10\t140k\t0.01\t\t0.02\t\t0.130\t\t0.842\t\t0.45m - 4.8m / 16.1m                                                                 \n",
      "11\t155k\t0.01\t\t0.03\t\t0.127\t\t0.845\t\t0.45m - 5.3m / 16.1m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.125\t\t0.838\t\t0.45m - 5.8m / 16.1m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.120\t\t0.833\t\t0.45m - 6.2m / 16.2m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.126\t\t0.839\t\t0.45m - 6.7m / 16.2m                                                                 \n",
      "VAL f1\t0.13889922424030182 - (0.13889922424030182)                                                                     \n",
      "VAL loss\t0.012600670372345172                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.012600670372345172\n",
      "        | \\     )|_\tf1: 0.13889922424030182\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\100\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 13.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         13                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.001182826406448047               |\n",
      "|  noam_learning_rate_warmup   |                        1220                       |\n",
      "|  noam_learning_rate_factor   |                 0.6439950777316883                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         1                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2023154336185815                |\n",
      "|     pointwise_layer_size     |                        231                        |\n",
      "|      last_layer_dropout      |                 0.7111087452044424                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 89%|████████████████████████████████████▋    | 134/150 [22:12:44<1:59:32, 448.25s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9a8c2bbc414a2591669bf8d2b7afe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.04\t\t0.461\t\t0.875\t\t0.76m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.04\t\t0.514\t\t0.896\t\t0.78m - 1.6m / 26.6m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.486\t\t0.888\t\t0.73m - 2.3m / 27.2m                                                                   \n",
      "4\t56k\t0.03\t\t0.03\t\t0.558\t\t0.912\t\t0.73m - 3.0m / 25.6m                                                                   \n",
      "5\t70k\t0.03\t\t0.03\t\t0.538\t\t0.907\t\t0.77m - 3.8m / 25.6m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.590\t\t0.922\t\t0.77m - 4.6m / 26.9m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.559\t\t0.916\t\t0.72m - 5.3m / 26.9m                                                                   \n",
      "8\t112k\t0.02\t\t0.03\t\t0.586\t\t0.922\t\t0.72m - 6.1m / 25.6m                                                                  \n",
      "9\t126k\t0.02\t\t0.03\t\t0.591\t\t0.924\t\t0.74m - 6.8m / 25.5m                                                                  \n",
      "10\t141k\t0.02\t\t0.03\t\t0.548\t\t0.910\t\t0.80m - 7.6m / 26.0m                                                                 \n",
      "11\t155k\t0.02\t\t0.03\t\t0.569\t\t0.916\t\t0.78m - 8.4m / 27.6m                                                                 \n",
      "12\t169k\t0.02\t\t0.03\t\t0.502\t\t0.892\t\t0.81m - 9.3m / 27.2m                                                                 \n",
      "13\t183k\t0.02\t\t0.03\t\t0.610\t\t0.929\t\t0.77m - 10.0m / 27.8m                                                                \n",
      "14\t197k\t0.02\t\t0.03\t\t0.602\t\t0.927\t\t0.72m - 10.8m / 26.9m                                                                \n",
      "15\t211k\t0.02\t\t0.03\t\t0.592\t\t0.922\t\t0.71m - 11.5m / 25.8m                                                                \n",
      "16\t225k\t0.02\t\t0.03\t\t0.574\t\t0.921\t\t0.72m - 12.2m / 25.8m                                                                \n",
      "17\t239k\t0.02\t\t0.03\t\t0.581\t\t0.921\t\t0.73m - 13.0m / 25.9m                                                                \n",
      "18\t253k\t0.02\t\t0.03\t\t0.569\t\t0.917\t\t0.71m - 13.7m / 26.1m                                                                \n",
      "VAL f1\t0.6096937323267833 - (0.6096937323267833)                                                                       \n",
      "VAL loss\t0.026577465168845193                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.026577465168845193\n",
      "        | \\     )|_\tf1: 0.6096937323267833\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\101\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 25.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         25                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.02213770098471568                |\n",
      "|  noam_learning_rate_warmup   |                        6507                       |\n",
      "|  noam_learning_rate_factor   |                 1.6624661761453818                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5381397993391865                |\n",
      "|     pointwise_layer_size     |                        155                        |\n",
      "|      last_layer_dropout      |                 0.4329619510761318                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 90%|████████████████████████████████████▉    | 135/150 [22:27:10<2:23:27, 573.82s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1761019d87954c2ea37307bc3829c349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.07\t\t0.212\t\t0.805\t\t1.04m - 1.0m / 0.0m                                                                    \n",
      "2\t28k\t0.05\t\t0.05\t\t0.240\t\t0.835\t\t1.00m - 2.1m / 36.3m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.264\t\t0.847\t\t0.99m - 3.1m / 35.1m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.282\t\t0.862\t\t0.97m - 4.1m / 34.7m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.309\t\t0.877\t\t0.97m - 5.0m / 34.2m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.331\t\t0.889\t\t0.95m - 6.0m / 34.3m                                                                   \n",
      "7\t98k\t0.01\t\t0.03\t\t0.337\t\t0.891\t\t0.97m - 7.0m / 33.6m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.321\t\t0.885\t\t1.00m - 8.0m / 34.1m                                                                  \n",
      "9\t126k\t0.01\t\t0.02\t\t0.351\t\t0.896\t\t1.05m - 9.1m / 35.1m                                                                  \n",
      "10\t140k\t0.01\t\t0.03\t\t0.323\t\t0.883\t\t0.95m - 10.1m / 36.3m                                                                \n",
      "11\t155k\t0.02\t\t0.03\t\t0.337\t\t0.889\t\t0.96m - 11.0m / 33.9m                                                                \n",
      "12\t169k\t0.02\t\t0.03\t\t0.322\t\t0.884\t\t0.96m - 12.0m / 34.0m                                                                \n",
      "13\t183k\t0.02\t\t0.03\t\t0.281\t\t0.860\t\t0.95m - 13.0m / 34.1m                                                                \n",
      "14\t197k\t0.02\t\t0.03\t\t0.230\t\t0.861\t\t0.95m - 13.9m / 33.8m                                                                \n",
      "VAL f1\t0.3514857101219681 - (0.3514857101219681)                                                                       \n",
      "VAL loss\t0.022935788019345357                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.022935788019345357\n",
      "        | \\     )|_\tf1: 0.3514857101219681\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\102\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 49.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         49                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.001446403596490327               |\n",
      "|  noam_learning_rate_warmup   |                        8716                       |\n",
      "|  noam_learning_rate_factor   |                 1.0935898055230193                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5173552730995271                |\n",
      "|     pointwise_layer_size     |                        219                        |\n",
      "|      last_layer_dropout      |                0.21296124461443294                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [22:41:57<2:35:45, 667.55s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ddaf2443be49248ec9fb84add4f6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.04\t\t0.122\t\t0.800\t\t0.70m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.122\t\t0.800\t\t0.68m - 1.4m / 24.4m                                                                   \n",
      "3\t42k\t0.03\t\t0.03\t\t0.096\t\t0.768\t\t0.68m - 2.1m / 23.7m                                                                   \n",
      "4\t56k\t0.03\t\t0.02\t\t0.095\t\t0.763\t\t0.68m - 2.8m / 23.9m                                                                   \n",
      "5\t70k\t0.02\t\t0.02\t\t0.102\t\t0.766\t\t0.67m - 3.5m / 24.0m                                                                   \n",
      "6\t84k\t0.02\t\t0.02\t\t0.148\t\t0.830\t\t0.67m - 4.1m / 23.5m                                                                   \n",
      "7\t98k\t0.01\t\t0.02\t\t0.180\t\t0.861\t\t0.67m - 4.8m / 23.6m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.179\t\t0.862\t\t0.66m - 5.5m / 23.7m                                                                  \n",
      "9\t127k\t0.01\t\t0.01\t\t0.167\t\t0.851\t\t0.67m - 6.2m / 23.4m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.193\t\t0.872\t\t0.68m - 6.9m / 23.7m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.213\t\t0.885\t\t0.69m - 7.6m / 23.9m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.202\t\t0.881\t\t0.70m - 8.3m / 24.2m                                                                 \n",
      "13\t183k\t0.01\t\t0.01\t\t0.207\t\t0.883\t\t0.69m - 9.0m / 24.3m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.219\t\t0.889\t\t0.68m - 9.7m / 24.3m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.208\t\t0.884\t\t0.65m - 10.4m / 24.0m                                                                \n",
      "16\t225k\t0.00\t\t0.01\t\t0.197\t\t0.878\t\t0.64m - 11.0m / 23.3m                                                                \n",
      "17\t239k\t0.00\t\t0.02\t\t0.213\t\t0.888\t\t0.65m - 11.7m / 23.2m                                                                \n",
      "18\t253k\t0.00\t\t0.01\t\t0.221\t\t0.890\t\t0.64m - 12.3m / 23.4m                                                                \n",
      "19\t267k\t0.00\t\t0.01\t\t0.223\t\t0.893\t\t0.65m - 13.0m / 23.3m                                                                \n",
      "20\t281k\t0.00\t\t0.01\t\t0.217\t\t0.889\t\t0.64m - 13.7m / 23.5m                                                                \n",
      "21\t295k\t0.00\t\t0.02\t\t0.232\t\t0.898\t\t0.64m - 14.3m / 23.3m                                                                \n",
      "22\t309k\t0.00\t\t0.01\t\t0.231\t\t0.898\t\t0.65m - 15.0m / 23.3m                                                                \n",
      "23\t323k\t0.00\t\t0.01\t\t0.220\t\t0.893\t\t0.65m - 15.7m / 23.4m                                                                \n",
      "24\t338k\t0.00\t\t0.01\t\t0.218\t\t0.890\t\t0.67m - 16.3m / 23.4m                                                                \n",
      "25\t352k\t0.00\t\t0.01\t\t0.220\t\t0.891\t\t0.66m - 17.0m / 23.7m                                                                \n",
      "26\t366k\t0.00\t\t0.01\t\t0.216\t\t0.891\t\t0.65m - 17.7m / 23.6m                                                                \n",
      "VAL f1\t0.23227994860781193 - (0.23227994860781193)                                                                     \n",
      "VAL loss\t0.011525501255677889                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011525501255677889\n",
      "        | \\     )|_\tf1: 0.23227994860781193\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\103\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 55.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         55                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.01840327365355571                |\n",
      "|  noam_learning_rate_warmup   |                        5031                       |\n",
      "|  noam_learning_rate_factor   |                 2.390062617767605                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.6374300179000101                |\n",
      "|     pointwise_layer_size     |                        144                        |\n",
      "|      last_layer_dropout      |                0.15975560498723385                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------------+\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [23:00:19<2:52:52, 797.87s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868ac71c223047f693101d9b25e491a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.100\t\t0.792\t\t0.49m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.03\t\t0.105\t\t0.803\t\t0.49m - 1.0m / 17.2m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.093\t\t0.792\t\t0.48m - 1.5m / 17.3m                                                                   \n",
      "4\t56k\t0.02\t\t0.02\t\t0.099\t\t0.785\t\t0.48m - 2.0m / 16.9m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.118\t\t0.816\t\t0.49m - 2.5m / 16.8m                                                                   \n",
      "6\t84k\t0.01\t\t0.02\t\t0.138\t\t0.840\t\t0.49m - 3.0m / 17.3m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.155\t\t0.856\t\t0.48m - 3.5m / 17.1m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.151\t\t0.855\t\t0.48m - 4.0m / 16.9m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.149\t\t0.854\t\t0.53m - 4.5m / 17.0m                                                                  \n",
      "10\t141k\t0.01\t\t0.02\t\t0.145\t\t0.852\t\t0.52m - 5.1m / 18.3m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.145\t\t0.856\t\t0.50m - 5.6m / 18.0m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.100\t\t0.833\t\t0.49m - 6.1m / 17.7m                                                                 \n",
      "VAL f1\t0.15481478739316515 - (0.15481478739316515)                                                                     \n",
      "VAL loss\t0.015142615076267359                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.015142615076267359\n",
      "        | \\     )|_\tf1: 0.15481478739316515\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\104\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 39.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         39                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |               0.0025518318394771996               |\n",
      "|  noam_learning_rate_warmup   |                        8569                       |\n",
      "|  noam_learning_rate_factor   |                0.48160002031246085                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.5768195263121847                |\n",
      "|     pointwise_layer_size     |                        100                        |\n",
      "|      last_layer_dropout      |                 0.4297082541052169                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [23:07:02<2:15:53, 679.43s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f77eeff6ca4f70a7ac3235483dc2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.06\t\t0.156\t\t0.810\t\t0.92m - 0.9m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.88m - 1.8m / 32.4m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.156\t\t0.810\t\t0.84m - 2.7m / 30.9m                                                                   \n",
      "4\t56k\t0.04\t\t0.04\t\t0.145\t\t0.799\t\t0.82m - 3.5m / 29.6m                                                                   \n",
      "5\t70k\t0.04\t\t0.04\t\t0.102\t\t0.746\t\t0.81m - 4.3m / 29.0m                                                                   \n",
      "6\t84k\t0.03\t\t0.03\t\t0.107\t\t0.766\t\t0.81m - 5.2m / 28.7m                                                                   \n",
      "7\t99k\t0.03\t\t0.03\t\t0.104\t\t0.754\t\t0.83m - 6.0m / 28.7m                                                                   \n",
      "8\t113k\t0.02\t\t0.03\t\t0.109\t\t0.763\t\t0.81m - 6.8m / 29.2m                                                                  \n",
      "VAL f1\t0.15632942848995837 - (0.15632942848995837)                                                                     \n",
      "VAL loss\t0.026112980381000035                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.026112980381000035\n",
      "        | \\     )|_\tf1: 0.15632942848995837\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\105\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 28.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         28                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.13514120927190645                |\n",
      "|  noam_learning_rate_warmup   |                        8341                       |\n",
      "|  noam_learning_rate_factor   |                 3.0055681994883714                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.5264502114450866                |\n",
      "|     pointwise_layer_size     |                         70                        |\n",
      "|      last_layer_dropout      |                 0.3525439920295422                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [23:14:31<1:51:53, 610.29s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2291056112481b9a3a8b15719cf823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.06\t\t0.05\t\t0.194\t\t0.807\t\t0.66m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.03\t\t0.268\t\t0.867\t\t0.66m - 1.3m / 23.0m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.280\t\t0.869\t\t0.66m - 2.0m / 23.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.03\t\t0.324\t\t0.894\t\t0.66m - 2.7m / 23.0m                                                                   \n",
      "5\t70k\t0.01\t\t0.02\t\t0.333\t\t0.899\t\t0.65m - 3.3m / 23.1m                                                                   \n",
      "6\t84k\t0.01\t\t0.03\t\t0.312\t\t0.890\t\t0.64m - 4.0m / 22.8m                                                                   \n",
      "7\t98k\t0.01\t\t0.03\t\t0.291\t\t0.879\t\t0.65m - 4.7m / 22.6m                                                                   \n",
      "8\t112k\t0.01\t\t0.02\t\t0.332\t\t0.901\t\t0.64m - 5.3m / 22.7m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.320\t\t0.893\t\t0.65m - 6.0m / 22.6m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.338\t\t0.899\t\t0.65m - 6.6m / 22.9m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.334\t\t0.900\t\t0.63m - 7.3m / 22.8m                                                                 \n",
      "12\t169k\t0.01\t\t0.02\t\t0.309\t\t0.888\t\t0.66m - 7.9m / 22.3m                                                                 \n",
      "13\t183k\t0.01\t\t0.02\t\t0.275\t\t0.870\t\t0.67m - 8.6m / 23.1m                                                                 \n",
      "14\t197k\t0.01\t\t0.02\t\t0.300\t\t0.883\t\t0.68m - 9.3m / 23.4m                                                                 \n",
      "15\t211k\t0.02\t\t0.03\t\t0.315\t\t0.887\t\t0.67m - 10.0m / 23.5m                                                                \n",
      "VAL f1\t0.3376884611251117 - (0.3376884611251117)                                                                       \n",
      "VAL loss\t0.019331641002843597                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.019331641002843597\n",
      "        | \\     )|_\tf1: 0.3376884611251117\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\106\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 18.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         18                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.08702280453469051                |\n",
      "|  noam_learning_rate_warmup   |                        8567                       |\n",
      "|  noam_learning_rate_factor   |                 1.8825402909029805                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.001                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                 0.3304568184608687                |\n",
      "|     pointwise_layer_size     |                        283                        |\n",
      "|      last_layer_dropout      |                0.16239725073081168                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [23:25:09<1:43:07, 618.80s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3368d2e23d764ef381e4df2163c40337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.08\t\t0.06\t\t0.333\t\t0.847\t\t1.31m - 1.3m / 0.0m                                                                    \n",
      "2\t28k\t0.04\t\t0.04\t\t0.380\t\t0.865\t\t1.23m - 2.6m / 45.9m                                                                   \n",
      "3\t42k\t0.03\t\t0.04\t\t0.460\t\t0.901\t\t1.23m - 3.9m / 43.1m                                                                   \n",
      "4\t56k\t0.02\t\t0.03\t\t0.469\t\t0.905\t\t1.22m - 5.1m / 43.4m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.433\t\t0.891\t\t1.19m - 6.3m / 42.8m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.473\t\t0.906\t\t1.20m - 7.5m / 42.0m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.468\t\t0.904\t\t1.19m - 8.7m / 42.3m                                                                   \n",
      "8\t112k\t0.02\t\t0.02\t\t0.459\t\t0.903\t\t1.20m - 9.9m / 42.0m                                                                  \n",
      "9\t127k\t0.02\t\t0.03\t\t0.509\t\t0.918\t\t1.19m - 11.2m / 42.4m                                                                 \n",
      "10\t141k\t0.02\t\t0.03\t\t0.508\t\t0.917\t\t1.22m - 12.4m / 42.1m                                                                \n",
      "11\t155k\t0.02\t\t0.03\t\t0.404\t\t0.877\t\t1.27m - 13.7m / 42.9m                                                                \n",
      "12\t169k\t0.02\t\t0.03\t\t0.492\t\t0.914\t\t1.17m - 14.9m / 44.2m                                                                \n",
      "13\t183k\t0.02\t\t0.03\t\t0.447\t\t0.899\t\t1.17m - 16.0m / 41.9m                                                                \n",
      "14\t197k\t0.02\t\t0.05\t\t0.411\t\t0.884\t\t1.16m - 17.2m / 41.7m                                                                \n",
      "VAL f1\t0.5085787901650528 - (0.5085787901650528)                                                                       \n",
      "VAL loss\t0.02306964269457894                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02306964269457894\n",
      "        | \\     )|_\tf1: 0.5085787901650528\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\107\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 47.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         47                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.01293621936765006                |\n",
      "|  noam_learning_rate_warmup   |                        7955                       |\n",
      "|  noam_learning_rate_factor   |                 1.588454758025039                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2845428766402131                |\n",
      "|     pointwise_layer_size     |                         70                        |\n",
      "|      last_layer_dropout      |                 0.143379517226757                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [23:43:23<1:54:11, 761.32s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481820170e77431389c504b98f160688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.125\t\t0.806\t\t0.75m - 0.7m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.147\t\t0.832\t\t0.74m - 1.5m / 26.2m                                                                   \n",
      "3\t42k\t0.02\t\t0.01\t\t0.161\t\t0.844\t\t0.72m - 2.2m / 25.8m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.208\t\t0.881\t\t0.72m - 3.0m / 25.3m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.178\t\t0.858\t\t0.71m - 3.7m / 25.5m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.199\t\t0.875\t\t0.70m - 4.4m / 25.0m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.184\t\t0.868\t\t0.72m - 5.2m / 24.9m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.201\t\t0.877\t\t0.72m - 5.9m / 25.3m                                                                  \n",
      "9\t126k\t0.00\t\t0.01\t\t0.193\t\t0.876\t\t0.70m - 6.6m / 25.3m                                                                  \n",
      "VAL f1\t0.20779085438833936 - (0.20779085438833936)                                                                     \n",
      "VAL loss\t0.01110400662369641                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.01110400662369641\n",
      "        | \\     )|_\tf1: 0.20779085438833936\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\108\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 16.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         16                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.017872627206346765               |\n",
      "|  noam_learning_rate_warmup   |                        8480                       |\n",
      "|  noam_learning_rate_factor   |                 2.4553942340222568                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-07                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.644173591053796                 |\n",
      "|     pointwise_layer_size     |                        343                        |\n",
      "|      last_layer_dropout      |                 0.696665113542271                 |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [23:50:42<1:28:35, 664.48s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50adbd4988274586806bbff68fda0c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.11\t\t0.13\t\t0.316\t\t0.819\t\t1.45m - 1.4m / 0.0m                                                                    \n",
      "2\t28k\t0.08\t\t0.07\t\t0.281\t\t0.801\t\t1.48m - 3.0m / 50.6m                                                                   \n",
      "3\t42k\t0.05\t\t0.07\t\t0.325\t\t0.825\t\t1.40m - 4.4m / 51.9m                                                                   \n",
      "4\t56k\t0.04\t\t0.06\t\t0.372\t\t0.854\t\t1.36m - 5.7m / 49.2m                                                                   \n",
      "5\t70k\t0.04\t\t0.09\t\t0.342\t\t0.831\t\t1.37m - 7.1m / 47.9m                                                                   \n",
      "6\t84k\t0.04\t\t0.06\t\t0.361\t\t0.850\t\t1.39m - 8.5m / 48.2m                                                                   \n",
      "7\t98k\t0.04\t\t0.06\t\t0.426\t\t0.882\t\t1.42m - 10.0m / 48.9m                                                                  \n",
      "8\t112k\t0.04\t\t0.06\t\t0.382\t\t0.860\t\t1.33m - 11.3m / 49.9m                                                                 \n",
      "9\t126k\t0.05\t\t0.07\t\t0.340\t\t0.852\t\t1.33m - 12.7m / 47.3m                                                                 \n",
      "10\t140k\t0.05\t\t0.07\t\t0.292\t\t0.817\t\t1.38m - 14.1m / 47.3m                                                                \n",
      "11\t155k\t0.06\t\t0.08\t\t0.224\t\t0.820\t\t1.47m - 15.5m / 48.5m                                                                \n",
      "12\t169k\t0.06\t\t0.08\t\t0.294\t\t0.805\t\t1.36m - 16.9m / 50.8m                                                                \n",
      "VAL f1\t0.4258622948956907 - (0.4258622948956907)                                                                       \n",
      "VAL loss\t0.056779932850451374                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.056779932850451374\n",
      "        | \\     )|_\tf1: 0.4258622948956907\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\109\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 26.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         26                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.02506615019443493                |\n",
      "|  noam_learning_rate_warmup   |                        8786                       |\n",
      "|  noam_learning_rate_factor   |                 1.3916337200784146                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                 0.5638770228501891                |\n",
      "|     pointwise_layer_size     |                         95                        |\n",
      "|      last_layer_dropout      |                 0.5393293125287627                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 95%|███████████████████████████████████████  | 143/150 [24:08:39<1:31:58, 788.37s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07a74f1092043d8b5bc4450c9cf960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.07\t\t0.07\t\t0.202\t\t0.804\t\t0.89m - 0.9m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.04\t\t0.159\t\t0.770\t\t0.90m - 1.8m / 31.3m                                                                   \n",
      "3\t42k\t0.04\t\t0.04\t\t0.185\t\t0.801\t\t0.90m - 2.7m / 31.4m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.211\t\t0.817\t\t0.89m - 3.6m / 31.5m                                                                   \n",
      "5\t70k\t0.02\t\t0.03\t\t0.250\t\t0.849\t\t0.89m - 4.5m / 31.2m                                                                   \n",
      "6\t84k\t0.02\t\t0.03\t\t0.278\t\t0.866\t\t0.89m - 5.4m / 31.3m                                                                   \n",
      "7\t98k\t0.02\t\t0.03\t\t0.294\t\t0.876\t\t0.88m - 6.3m / 31.1m                                                                   \n",
      "8\t113k\t0.01\t\t0.02\t\t0.317\t\t0.889\t\t0.87m - 7.2m / 31.0m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.306\t\t0.884\t\t0.88m - 8.1m / 30.7m                                                                  \n",
      "10\t141k\t0.01\t\t0.03\t\t0.266\t\t0.866\t\t0.87m - 9.0m / 31.0m                                                                 \n",
      "11\t155k\t0.01\t\t0.02\t\t0.305\t\t0.884\t\t0.88m - 9.9m / 30.8m                                                                 \n",
      "12\t169k\t0.01\t\t0.03\t\t0.289\t\t0.873\t\t0.88m - 10.8m / 31.0m                                                                \n",
      "13\t183k\t0.01\t\t0.03\t\t0.328\t\t0.895\t\t0.94m - 11.7m / 31.1m                                                                \n",
      "14\t197k\t0.01\t\t0.03\t\t0.286\t\t0.871\t\t0.93m - 12.7m / 32.4m                                                                \n",
      "15\t211k\t0.01\t\t0.03\t\t0.329\t\t0.894\t\t0.92m - 13.6m / 32.3m                                                                \n",
      "16\t225k\t0.01\t\t0.03\t\t0.275\t\t0.867\t\t0.90m - 14.5m / 32.0m                                                                \n",
      "17\t239k\t0.01\t\t0.03\t\t0.272\t\t0.860\t\t0.87m - 15.4m / 31.6m                                                                \n",
      "18\t253k\t0.01\t\t0.04\t\t0.297\t\t0.882\t\t0.86m - 16.3m / 31.1m                                                                \n",
      "19\t267k\t0.01\t\t0.04\t\t0.217\t\t0.863\t\t0.86m - 17.2m / 30.9m                                                                \n",
      "20\t281k\t0.01\t\t0.04\t\t0.268\t\t0.858\t\t0.86m - 18.0m / 31.0m                                                                \n",
      "VAL f1\t0.3287012706474703 - (0.3287012706474703)                                                                       \n",
      "VAL loss\t0.02037413892766031                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.02037413892766031\n",
      "        | \\     )|_\tf1: 0.3287012706474703\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\110\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 24.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         24                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.15738315018323526                |\n",
      "|  noam_learning_rate_warmup   |                        4029                       |\n",
      "|  noam_learning_rate_factor   |                  3.29638197902919                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.2426781916007852                |\n",
      "|     pointwise_layer_size     |                         73                        |\n",
      "|      last_layer_dropout      |                0.41934326325217514                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [24:27:23<1:28:54, 889.14s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a68892bdc3488696553362080d8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.05\t\t0.03\t\t0.373\t\t0.897\t\t1.24m - 1.2m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.03\t\t0.370\t\t0.895\t\t1.26m - 2.5m / 43.4m                                                                   \n",
      "3\t42k\t0.02\t\t0.03\t\t0.291\t\t0.854\t\t1.30m - 3.8m / 44.1m                                                                   \n",
      "4\t56k\t0.03\t\t0.04\t\t0.228\t\t0.816\t\t1.25m - 5.1m / 45.3m                                                                   \n",
      "5\t70k\t0.04\t\t0.06\t\t0.197\t\t0.785\t\t1.26m - 6.4m / 43.9m                                                                   \n",
      "6\t84k\t0.06\t\t0.06\t\t0.144\t\t0.792\t\t1.26m - 7.6m / 44.2m                                                                   \n",
      "VAL f1\t0.37340667590677823 - (0.37340667590677823)                                                                     \n",
      "VAL loss\t0.029554871765225577                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.029554871765225577\n",
      "        | \\     )|_\tf1: 0.37340667590677823\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\111\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 54.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         54                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                 0.2005035697646398                |\n",
      "|  noam_learning_rate_warmup   |                        4305                       |\n",
      "|  noam_learning_rate_factor   |                 3.6849470900449144                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-06                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.6405175647819424                |\n",
      "|     pointwise_layer_size     |                        246                        |\n",
      "|      last_layer_dropout      |                 0.6547271575604239                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [24:35:50<1:04:32, 774.49s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6849ec3f8d1444b9de5b78f43dea43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.03\t\t0.113\t\t0.802\t\t0.55m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.03\t\t0.02\t\t0.065\t\t0.735\t\t0.54m - 1.1m / 19.2m                                                                   \n",
      "3\t42k\t0.02\t\t0.02\t\t0.131\t\t0.823\t\t0.57m - 1.7m / 19.0m                                                                   \n",
      "4\t56k\t0.01\t\t0.02\t\t0.099\t\t0.794\t\t0.57m - 2.3m / 20.0m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.153\t\t0.852\t\t0.58m - 2.9m / 19.9m                                                                   \n",
      "6\t85k\t0.01\t\t0.01\t\t0.182\t\t0.877\t\t0.52m - 3.4m / 20.2m                                                                   \n",
      "7\t99k\t0.01\t\t0.01\t\t0.189\t\t0.882\t\t0.53m - 4.0m / 18.5m                                                                   \n",
      "8\t113k\t0.01\t\t0.01\t\t0.154\t\t0.859\t\t0.52m - 4.5m / 18.7m                                                                  \n",
      "9\t127k\t0.01\t\t0.02\t\t0.159\t\t0.863\t\t0.52m - 5.0m / 18.5m                                                                  \n",
      "10\t141k\t0.01\t\t0.01\t\t0.164\t\t0.864\t\t0.51m - 5.6m / 18.6m                                                                 \n",
      "11\t155k\t0.01\t\t0.01\t\t0.158\t\t0.858\t\t0.51m - 6.1m / 18.3m                                                                 \n",
      "12\t169k\t0.01\t\t0.01\t\t0.170\t\t0.867\t\t0.51m - 6.6m / 18.3m                                                                 \n",
      "VAL f1\t0.18866637916181125 - (0.18866637916181125)                                                                     \n",
      "VAL loss\t0.011026029350065289                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.011026029350065289\n",
      "        | \\     )|_\tf1: 0.18866637916181125\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\112\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 61.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         61                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.28409406379466434                |\n",
      "|  noam_learning_rate_warmup   |                        7600                       |\n",
      "|  noam_learning_rate_factor   |                 2.960769746095886                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-08                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         3                         |\n",
      "|           n_heads            |                         1                         |\n",
      "|             d_k              |                        300                        |\n",
      "|             d_v              |                        300                        |\n",
      "|         dropout_rate         |                0.03650547992580329                |\n",
      "|     pointwise_layer_size     |                        199                        |\n",
      "|      last_layer_dropout      |                 0.7353543981011152                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                      fasttext                     |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 97%|█████████████████████████████████████████▊ | 146/150 [24:43:04<44:49, 672.28s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb5857ab6044ffdb64c6aae0d494414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.02\t\t0.02\t\t0.122\t\t0.832\t\t0.46m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.178\t\t0.885\t\t0.47m - 0.9m / 16.0m                                                                   \n",
      "3\t42k\t0.00\t\t0.01\t\t0.145\t\t0.857\t\t0.45m - 1.4m / 16.3m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.193\t\t0.893\t\t0.45m - 1.9m / 15.7m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.200\t\t0.897\t\t0.46m - 2.3m / 15.9m                                                                   \n",
      "6\t85k\t0.00\t\t0.01\t\t0.192\t\t0.892\t\t0.45m - 2.8m / 16.1m                                                                   \n",
      "7\t99k\t0.00\t\t0.01\t\t0.202\t\t0.899\t\t0.45m - 3.3m / 15.8m                                                                   \n",
      "8\t113k\t0.00\t\t0.01\t\t0.190\t\t0.891\t\t0.45m - 3.7m / 15.8m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.179\t\t0.883\t\t0.44m - 4.2m / 15.9m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.213\t\t0.906\t\t0.44m - 4.6m / 15.6m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.189\t\t0.892\t\t0.44m - 5.1m / 15.7m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.207\t\t0.903\t\t0.44m - 5.6m / 15.6m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.215\t\t0.906\t\t0.44m - 6.0m / 15.7m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.216\t\t0.908\t\t0.44m - 6.5m / 15.6m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.206\t\t0.901\t\t0.44m - 6.9m / 15.7m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.163\t\t0.872\t\t0.43m - 7.4m / 15.7m                                                                 \n",
      "17\t240k\t0.00\t\t0.01\t\t0.197\t\t0.894\t\t0.44m - 7.8m / 15.6m                                                                 \n",
      "18\t254k\t0.00\t\t0.01\t\t0.190\t\t0.890\t\t0.48m - 8.3m / 15.7m                                                                 \n",
      "19\t268k\t0.00\t\t0.01\t\t0.154\t\t0.868\t\t0.47m - 8.8m / 16.5m                                                                 \n",
      "VAL f1\t0.21643997209715488 - (0.21643997209715488)                                                                     \n",
      "VAL loss\t0.00621879355033094                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.00621879355033094\n",
      "        | \\     )|_\tf1: 0.21643997209715488\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\113\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 10.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         10                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.012333242942578477               |\n",
      "|  noam_learning_rate_warmup   |                        6488                       |\n",
      "|  noam_learning_rate_factor   |                 1.9898232273569187                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       0.0001                      |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                0.45535730892883397                |\n",
      "|     pointwise_layer_size     |                         62                        |\n",
      "|      last_layer_dropout      |                 0.2823476646973852                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 98%|██████████████████████████████████████████▏| 147/150 [24:52:29<31:59, 639.95s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c048db42eb64b029d5002a1222cadee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.13\t\t0.09\t\t0.543\t\t0.879\t\t1.49m - 1.5m / 0.0m                                                                    \n",
      "2\t28k\t0.06\t\t0.09\t\t0.465\t\t0.851\t\t1.43m - 2.9m / 52.0m                                                                   \n",
      "3\t42k\t0.05\t\t0.07\t\t0.538\t\t0.880\t\t1.41m - 4.4m / 50.2m                                                                   \n",
      "4\t56k\t0.06\t\t0.06\t\t0.522\t\t0.875\t\t1.42m - 5.8m / 49.7m                                                                   \n",
      "5\t70k\t0.07\t\t0.07\t\t0.515\t\t0.872\t\t1.42m - 7.2m / 49.8m                                                                   \n",
      "6\t84k\t0.08\t\t0.07\t\t0.486\t\t0.858\t\t1.44m - 8.7m / 49.8m                                                                   \n",
      "VAL f1\t0.5429158089937979 - (0.5429158089937979)                                                                       \n",
      "VAL loss\t0.06318303090792436                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.06318303090792436\n",
      "        | \\     )|_\tf1: 0.5429158089937979\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\114\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 43.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         43                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.04675483701954983                |\n",
      "|  noam_learning_rate_warmup   |                        8585                       |\n",
      "|  noam_learning_rate_factor   |                 2.7859326644051734                |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         2                         |\n",
      "|           n_heads            |                         2                         |\n",
      "|             d_k              |                        150                        |\n",
      "|             d_v              |                        150                        |\n",
      "|         dropout_rate         |                0.19516523189945512                |\n",
      "|     pointwise_layer_size     |                        209                        |\n",
      "|      last_layer_dropout      |                0.14825706486108123                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 99%|██████████████████████████████████████████▍| 148/150 [25:02:12<20:45, 622.93s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f472f40717545369788f7f519127278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.04\t\t0.03\t\t0.141\t\t0.811\t\t0.47m - 0.5m / 0.0m                                                                    \n",
      "2\t28k\t0.02\t\t0.02\t\t0.221\t\t0.875\t\t0.47m - 1.0m / 16.5m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.237\t\t0.885\t\t0.47m - 1.5m / 16.6m                                                                   \n",
      "4\t56k\t0.01\t\t0.01\t\t0.263\t\t0.900\t\t0.48m - 1.9m / 16.5m                                                                   \n",
      "5\t70k\t0.00\t\t0.01\t\t0.229\t\t0.881\t\t0.47m - 2.4m / 16.8m                                                                   \n",
      "6\t84k\t0.00\t\t0.01\t\t0.256\t\t0.895\t\t0.50m - 2.9m / 16.4m                                                                   \n",
      "7\t98k\t0.00\t\t0.01\t\t0.268\t\t0.900\t\t0.48m - 3.4m / 17.4m                                                                   \n",
      "8\t112k\t0.00\t\t0.01\t\t0.264\t\t0.899\t\t0.49m - 4.0m / 16.9m                                                                  \n",
      "9\t127k\t0.00\t\t0.01\t\t0.253\t\t0.893\t\t0.48m - 4.5m / 17.3m                                                                  \n",
      "10\t141k\t0.00\t\t0.01\t\t0.273\t\t0.903\t\t0.46m - 4.9m / 16.9m                                                                 \n",
      "11\t155k\t0.00\t\t0.01\t\t0.258\t\t0.895\t\t0.45m - 5.4m / 16.5m                                                                 \n",
      "12\t169k\t0.00\t\t0.01\t\t0.259\t\t0.895\t\t0.45m - 5.9m / 16.2m                                                                 \n",
      "13\t183k\t0.00\t\t0.01\t\t0.249\t\t0.893\t\t0.45m - 6.3m / 16.2m                                                                 \n",
      "14\t197k\t0.00\t\t0.01\t\t0.262\t\t0.899\t\t0.45m - 6.8m / 16.3m                                                                 \n",
      "15\t211k\t0.00\t\t0.01\t\t0.274\t\t0.902\t\t0.45m - 7.3m / 16.3m                                                                 \n",
      "16\t225k\t0.00\t\t0.01\t\t0.279\t\t0.903\t\t0.44m - 7.7m / 16.3m                                                                 \n",
      "17\t239k\t0.00\t\t0.01\t\t0.257\t\t0.896\t\t0.45m - 8.2m / 16.2m                                                                 \n",
      "18\t253k\t0.00\t\t0.01\t\t0.268\t\t0.900\t\t0.45m - 8.6m / 16.4m                                                                 \n",
      "19\t267k\t0.00\t\t0.01\t\t0.257\t\t0.894\t\t0.44m - 9.1m / 16.3m                                                                 \n",
      "20\t281k\t0.00\t\t0.01\t\t0.251\t\t0.894\t\t0.45m - 9.6m / 16.2m                                                                 \n",
      "21\t295k\t0.00\t\t0.01\t\t0.256\t\t0.895\t\t0.45m - 10.0m / 16.3m                                                                \n",
      "VAL f1\t0.27853022856569737 - (0.27853022856569737)                                                                     \n",
      "VAL loss\t0.009566887582776523                                                                                          \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.009566887582776523\n",
      "        | \\     )|_\tf1: 0.27853022856569737\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "Log path is                                                                                                            \n",
      "C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\CoNLL-2003HyperoptTPE\\20190429\\115\n",
      "                                                                                                                       \n",
      "\n",
      "#########################################################################\n",
      "+----------------------------------------------------------------------------------+                                   \n",
      "|                                 Hyperparameters                                  |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|          Parameter           |                       Value                       |\n",
      "+------------------------------+---------------------------------------------------+\n",
      "|            kwargs            | {'batch_size': 46.0, 'learning_rate_sche[...]rue} |\n",
      "|          model_size          |                        300                        |\n",
      "|        early_stopping        |                         5                         |\n",
      "|           use_cuda           |                        True                       |\n",
      "|             task             |                        ner                        |\n",
      "|          batch_size          |                         46                        |\n",
      "| learning_rate_scheduler_type |             LearningSchedulerType.Noam            |\n",
      "|      output_layer_type       |                        None                       |\n",
      "|        optimizer_type        |                 OptimizerType.Adam                |\n",
      "|        learning_rate         |                0.005389837712406708               |\n",
      "|  noam_learning_rate_warmup   |                        2624                       |\n",
      "|  noam_learning_rate_factor   |                 2.233962717870328                 |\n",
      "|          adam_beta1          |                        0.9                        |\n",
      "|          adam_beta2          |                        0.98                       |\n",
      "|           adam_eps           |                       1e-08                       |\n",
      "|      adam_weight_decay       |                       1e-05                       |\n",
      "|         adam_amsgrad         |                       False                       |\n",
      "|           use_bias           |                        True                       |\n",
      "|         n_enc_blocks         |                         4                         |\n",
      "|           n_heads            |                         3                         |\n",
      "|             d_k              |                        100                        |\n",
      "|             d_v              |                        100                        |\n",
      "|         dropout_rate         |                 0.150329812494165                 |\n",
      "|     pointwise_layer_size     |                        270                        |\n",
      "|      last_layer_dropout      |                 0.7100547160871096                |\n",
      "|   log_every_xth_iteration    |                         -1                        |\n",
      "|          num_epochs          |                         35                        |\n",
      "|        embedding_type        |                       glove                       |\n",
      "|        embedding_name        |                         6B                        |\n",
      "|        embedding_dim         |                        300                        |\n",
      "|       clip_comments_to       |                        200                        |\n",
      "|      finetune_embedding      |                        True                       |\n",
      "|           language           |                         en                        |\n",
      "|        use_stop_words        |                        True                       |\n",
      "|         use_stemming         |                       False                       |\n",
      "|        harmonize_bahn        |                       False                       |\n",
      "|      use_spell_checkers      |                       False                       |\n",
      "|      replace_url_tokens      |                        True                       |\n",
      "|       use_text_cleaner       |                       False                       |\n",
      "|     contraction_removal      |                       False                       |\n",
      "|    organic_text_cleaning     |                       False                       |\n",
      "|       token_removal_1        |                       False                       |\n",
      "|       token_removal_2        |                       False                       |\n",
      "|       token_removal_3        |                       False                       |\n",
      "|             seed             |                         42                        |\n",
      "+------------------------------+---------------------------------------------------+\n",
      " 99%|██████████████████████████████████████████▋| 149/150 [25:12:42<10:25, 625.03s/it, best loss: 0.006738710305531937]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03b8c19d17c4520b280e8a30dbc284d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time                                                             \n",
      "1\t14k\t0.03\t\t0.01\t\t0.166\t\t0.842\t\t0.76m - 0.8m / 0.0m                                                                    \n",
      "2\t28k\t0.01\t\t0.01\t\t0.201\t\t0.869\t\t0.76m - 1.5m / 26.6m                                                                   \n",
      "3\t42k\t0.01\t\t0.01\t\t0.227\t\t0.888\t\t0.75m - 2.3m / 26.5m                                                                   \n",
      "4\t56k\t0.00\t\t0.01\t\t0.243\t\t0.895\t\t0.76m - 3.1m / 26.5m                                                                   \n",
      "5\t70k\t0.01\t\t0.01\t\t0.202\t\t0.874\t\t0.75m - 3.9m / 26.7m                                                                   \n",
      "6\t84k\t0.01\t\t0.01\t\t0.196\t\t0.873\t\t0.76m - 4.6m / 26.3m                                                                   \n",
      "7\t99k\t0.01\t\t0.02\t\t0.063\t\t0.734\t\t0.74m - 5.4m / 26.6m                                                                   \n",
      "8\t113k\t0.02\t\t0.02\t\t0.104\t\t0.762\t\t0.75m - 6.1m / 26.1m                                                                  \n",
      "9\t127k\t0.03\t\t0.03\t\t0.125\t\t0.793\t\t0.75m - 6.9m / 26.5m                                                                  \n",
      "VAL f1\t0.24296027002325798 - (0.24296027002325798)                                                                     \n",
      "VAL loss\t0.00954419874517157                                                                                           \n",
      "       .---.                                                                                                           \n",
      "          /     \\\n",
      "          \\.@-@./\n",
      "          /`\\_/`\\\n",
      "         //  _  \\\\\tLoss: 0.00954419874517157\n",
      "        | \\     )|_\tf1: 0.24296027002325798\n",
      "       /`\\_`>  <_/ \\\n",
      "       \\__/'---'\\__/\n",
      "\n",
      "100%|███████████████████████████████████████████| 150/150 [25:20:10<00:00, 572.12s/it, best loss: 0.006738710305531937]\n",
      "{'adam_learning_rate': 0.0015366519547490558, 'adam_weight_decay': -3.0, 'batch_size': 54.0, 'dropout_rate': 0.05786716720744574, 'embedding_type': 1, 'last_layer_dropout': 0.143337289452953, 'noam_learning_rate_factor': 1.4533351145591045, 'noam_learning_rate_warmup': 8823.0, 'num_encoder_blocks': 4.0, 'num_heads': 0, 'pointwise_layer_size': 201.0}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info('Current commit: ' + utils.get_current_git_commit())\n",
    "    print('Current commit: ' + utils.get_current_git_commit())\n",
    "except Exception as err:\n",
    "    logger.exception('Could not print current commit')\n",
    "\n",
    "trials = Trials()\n",
    "try:\n",
    "\n",
    "    best = fmin(objective,\n",
    "        space=search_space,\n",
    "        algo=rand.suggest,\n",
    "        max_evals=runs,\n",
    "        trials=trials)\n",
    "\n",
    "    print(best)\n",
    "except Exception as err:\n",
    "    logger.exception('Could not complete optimization')\n",
    "    print('Could not complete optimization. The log file provides more details.')\n",
    "    traceback.print_tb(err.__traceback__)\n",
    "\n",
    "\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'logs', f'hp_run_{main_experiment_name}.pkl')\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(trials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
