{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "from data.data_loader import Dataset\n",
    "from data.germeval2017 import germeval2017_dataset\n",
    "\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.run_configuration import get_default_params, randomize_params\n",
    "from misc import utils\n",
    "\n",
    "from optimizer import get_default_optimizer\n",
    "from criterion import NllLoss, LossCombiner\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.softmax_output import SoftmaxOutputLayerWithCommentWiseClass\n",
    "from models.transformer_tagger import TransformerTagger\n",
    "from models.jointAspectTagger import JointAspectTagger\n",
    "from models.transformer.train import Trainer\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/germeval2017',\n",
    "    data_train='train_v1.4.tsv',    \n",
    "    data_validation='dev_v1.4.tsv',\n",
    "    data_test='test_TIMESTAMP1.tsv',\n",
    "    early_stopping='highest_5_F1'\n",
    ")\n",
    "def load(hp, logger):\n",
    "    dataset = Dataset(\n",
    "        'germeval',\n",
    "        logger,\n",
    "        hp,\n",
    "        source_index=0,\n",
    "        target_vocab_index=2,\n",
    "        data_path=PREFERENCES.data_root,\n",
    "        train_file=PREFERENCES.data_train,\n",
    "        valid_file=PREFERENCES.data_validation,\n",
    "        test_file=PREFERENCES.data_test,\n",
    "        file_format='.tsv',\n",
    "        init_token=None,\n",
    "        eos_token=None\n",
    "    )\n",
    "    dataset.load_data(germeval2017_dataset, verbose=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(dataset, hp, experiment_name):\n",
    "    loss = LossCombiner(4, dataset.class_weights, NllLoss)\n",
    "    transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                     hyperparameters=hp)\n",
    "    model = JointAspectTagger(transformer, hp, 4, 20, dataset.target_names)\n",
    "    optimizer = get_default_optimizer(model, hp)\n",
    "    trainer = Trainer(\n",
    "                        model,\n",
    "                        loss,\n",
    "                        optimizer,\n",
    "                        hp,\n",
    "                        dataset,\n",
    "                        experiment_name,\n",
    "                        enable_tensorboard=False,\n",
    "                        verbose=True)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'Conv2dLayerTest'\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  C:\\Users\\felix\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\logs\\Conv2dLayerTest\\20190223\\2\n"
     ]
    }
   ],
   "source": [
    "# get general logger just for search\n",
    "experiment_name = utils.create_loggers(experiment_name=experiment_name)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.get_current_git_commit()\n",
    "logger.info('Current commit: ' + utils.get_current_git_commit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|          Hyperparameters           |\n",
      "+-------------------------+----------+\n",
      "|        Parameter        |  Value   |\n",
      "+-------------------------+----------+\n",
      "|        batch_size       |    12    |\n",
      "|        model_size       |   300    |\n",
      "|    learning_rate_type   |   noam   |\n",
      "|      learning_rate      |    0     |\n",
      "|   learning_rate_warmup  |   4800   |\n",
      "|   learning_rate_factor  |    2     |\n",
      "|     optim_adam_beta1    |   0.9    |\n",
      "|     optim_adam_beta2    |   0.98   |\n",
      "|      early_stopping     |    5     |\n",
      "|         use_cuda        |   True   |\n",
      "|       n_enc_blocks      |    3     |\n",
      "|         n_heads         |    6     |\n",
      "|           d_k           |    50    |\n",
      "|           d_v           |    50    |\n",
      "|       dropout_rate      |   0.1    |\n",
      "|   pointwise_layer_size  |   2048   |\n",
      "|    output_layer_type    |   conv   |\n",
      "| output_conv_num_filters |   300    |\n",
      "| output_conv_kernel_size |    5     |\n",
      "|    output_conv_stride   |    1     |\n",
      "|   output_conv_padding   |    0     |\n",
      "| log_every_xth_iteration |    -1    |\n",
      "|        num_epochs       |    15    |\n",
      "|      embedding_type     | fasttext |\n",
      "|      embedding_name     |    6B    |\n",
      "|      embedding_dim      |   300    |\n",
      "|     clip_comments_to    |   100    |\n",
      "|         language        |    de    |\n",
      "|      use_stop_words     |   True   |\n",
      "|           seed          |    42    |\n",
      "+-------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "hp = get_default_params(use_cuda)\n",
    "hp.num_epochs = 15\n",
    "\n",
    "logger.info(hp)\n",
    "print(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|  GERM EVAL 2017 DATASET |\n",
      "+---------------+---------+\n",
      "|     Split     |   Size  |\n",
      "+---------------+---------+\n",
      "|     train     |  17043  |\n",
      "|   validation  |   2049  |\n",
      "|      test     |   2095  |\n",
      "+---------------+---------+\n",
      "+--------------------------------------+\n",
      "|           Vocabulary Stats           |\n",
      "+------------------------------+-------+\n",
      "|          Vocabulary          |  Size |\n",
      "+------------------------------+-------+\n",
      "|           comments           | 67041 |\n",
      "|      general_sentiments      |   3   |\n",
      "|      aspect_sentiments       |   4   |\n",
      "|           padding            | 23197 |\n",
      "|   Komfort_und_Ausstattung    |   4   |\n",
      "|          Atmosphäre          |   4   |\n",
      "|          Toiletten           |   4   |\n",
      "|            Design            |   4   |\n",
      "|         Connectivity         |   4   |\n",
      "|        Informationen         |   4   |\n",
      "|      DB_App_und_Website      |   4   |\n",
      "|            Image             |   4   |\n",
      "|          Sicherheit          |   4   |\n",
      "|   Gastronomisches_Angebot    |   4   |\n",
      "|           Zugfahrt           |   4   |\n",
      "| Sonstige_Unregelmässigkeiten |   4   |\n",
      "|      Reisen_mit_Kindern      |   4   |\n",
      "|           QR-Code            |   3   |\n",
      "|          Ticketkauf          |   4   |\n",
      "| Service_und_Kundenbetreuung  |   4   |\n",
      "| Auslastung_und_Platzangebot  |   4   |\n",
      "|          Allgemein           |   4   |\n",
      "|       Barrierefreiheit       |   4   |\n",
      "|            Gepäck            |   4   |\n",
      "+------------------------------+-------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                     Komfort_und_Ausstattung                     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20989  |  99.06546467173266  | 0.009345353282673385 |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| negative |   117   |  0.5522254212488791 |  0.9944777457875112  |\n",
      "| neutral  |    33   | 0.15575588804455562 |  0.9984424411195545  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Atmosphäre                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  19854  | 93.70840609807901  | 0.06291593901920989 |\n",
      "| negative |   1035  | 4.8850710341246995 |  0.951149289658753  |\n",
      "| positive |   133   | 0.6277434275735121 |  0.9937225657242649 |\n",
      "| neutral  |   165   | 0.7787794402227781 |  0.9922122055977722 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                           Toiletten                            |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |    Class Weight    |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|   n/a    |  21131  |  99.73568697786378   | 0.0026431302213622 |\n",
      "| negative |    41   | 0.19351489120687212  | 0.9980648510879313 |\n",
      "| neutral  |    13   | 0.06135838013876433  | 0.9993864161986123 |\n",
      "| positive |    2    | 0.009439750790579128 | 0.9999056024920943 |\n",
      "|   Sum    |  21187  |                      |        1.0         |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Design                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21148  |   99.8159248595837   | 0.0018407514041629547 |\n",
      "| negative |    18   | 0.08495775711521215  |   0.9991504224288479  |\n",
      "| positive |    19   | 0.08967763251050172  |   0.999103223674895   |\n",
      "| neutral  |    2    | 0.009439750790579128 |   0.9999056024920943  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                           Connectivity                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20871  |   98.5085193750885  | 0.014914806249115009 |\n",
      "| positive |    69   |  0.3256714022749799 |  0.9967432859772501  |\n",
      "| negative |   197   |  0.9298154528720441 |  0.9907018454712796  |\n",
      "| neutral  |    50   | 0.23599376976447822 |  0.9976400623023552  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                          Informationen                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20765  |   98.0082125831878  | 0.019917874168121963 |\n",
      "| positive |    51   |  0.2407136451597678 |  0.9975928635484024  |\n",
      "| negative |   285   |  1.345164487657526  |  0.9865483551234248  |\n",
      "| neutral  |    86   | 0.40590928399490256 |  0.995940907160051   |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                        DB_App_und_Website                       |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20951  |  98.88610940671167  | 0.011138905932883358 |\n",
      "| positive |    41   | 0.19351489120687212 |  0.9980648510879313  |\n",
      "| negative |   134   |  0.6324633029688016 |  0.993675366970312   |\n",
      "| neutral  |    61   |  0.2879123991126634 |  0.9971208760088733  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                              Image                              |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  21129  |   99.7262472270732  | 0.002737527729267941 |\n",
      "| negative |    34   | 0.16047576343984518 |  0.9983952423656015  |\n",
      "| positive |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "| neutral  |    14   |  0.0660782555340539 |  0.9993392174446595  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                            Sicherheit                           |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight    |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|   n/a    |  20611  |   97.2813517723132   | 0.02718648227686793 |\n",
      "| negative |   542   |  2.558172464246944   |  0.9744182753575306 |\n",
      "| positive |    22   | 0.10383725869637041  |  0.9989616274130363 |\n",
      "| neutral  |    12   | 0.056638504743474774 |  0.9994336149525652 |\n",
      "|   Sum    |  21187  |                      |         1.0         |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                     Gastronomisches_Angebot                      |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |      Class Weight     |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|   n/a    |  21136  |  99.75928635484024  | 0.0024071364515976246 |\n",
      "| negative |    32   | 0.15103601264926605 |   0.9984896398735074  |\n",
      "| neutral  |    10   | 0.04719875395289565 |   0.9995280124604711  |\n",
      "| positive |    9    | 0.04247887855760608 |   0.9995752112144239  |\n",
      "|   Sum    |  21187  |                     |          1.0          |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                            Zugfahrt                           |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  18958  | 89.47939774389955  | 0.10520602256100442 |\n",
      "| positive |   371   | 1.7510737716524283 |  0.9824892622834758 |\n",
      "| negative |   1706  | 8.052107424363996  |   0.91947892575636  |\n",
      "| neutral  |   152   | 0.7174210600840137 |  0.9928257893991599 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                  Sonstige_Unregelmässigkeiten                  |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|   n/a    |  19483  |  91.95733232642658  | 0.08042667673573423 |\n",
      "| negative |   1582  |  7.4668428753480915 |  0.9253315712465191 |\n",
      "| positive |    49   | 0.23127389436918866 |  0.9976872610563081 |\n",
      "| neutral  |    73   |  0.3445509038561382 |  0.9965544909614387 |\n",
      "|   Sum    |  21187  |                     |         1.0         |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                        Reisen_mit_Kindern                        |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight     |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|   n/a    |  21132  |  99.74040685325907   | 0.002595931467409218 |\n",
      "| positive |    8    | 0.037759003162316514 |  0.9996224099683768  |\n",
      "| neutral  |    17   | 0.08023788171992259  |  0.9991976211828008  |\n",
      "| negative |    30   | 0.14159626185868693  |  0.9985840373814131  |\n",
      "|   Sum    |  21187  |                      |         1.0          |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                              QR-Code                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21185  |  99.99056024920942   | 9.439750790574131e-05 |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "| neutral  |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Ticketkauf                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  20429  |  96.4223344503705  | 0.03577665549629494 |\n",
      "| negative |   505   | 2.3835370746212297 |  0.9761646292537877 |\n",
      "| neutral  |   137   | 0.6466229291546703 |  0.9935337707084533 |\n",
      "| positive |   116   | 0.5475055458535895 |  0.9945249445414641 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                  Service_und_Kundenbetreuung                  |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  20589  | 97.17751451361684  | 0.02822485486383164 |\n",
      "| negative |   388   | 1.831311653372351  |  0.9816868834662765 |\n",
      "| positive |   146   | 0.6891018077122764 |  0.9931089819228772 |\n",
      "| neutral  |    64   | 0.3020720252985321 |  0.9969792797470147 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                   Auslastung_und_Platzangebot                   |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20868  |  98.49435974890262  | 0.015056402510973732 |\n",
      "| negative |   261   |  1.2318874781705764 |  0.9876811252182942  |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| neutral  |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------+\n",
      "|                          Allgemein                           |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy  |     Class Weight    |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "| neutral  |  12308  | 58.09222636522395 | 0.41907773634776047 |\n",
      "|   n/a    |   6176  | 29.14995044130835 |  0.7085004955869165 |\n",
      "| negative |   1922  | 9.071600509746542 |  0.9092839949025345 |\n",
      "| positive |   781   |  3.68622268372115 |  0.9631377731627885 |\n",
      "|   Sum    |  21187  |                   |         1.0         |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                         Barrierefreiheit                        |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  21097  |  99.57521121442394  | 0.004247887855760579 |\n",
      "| positive |    20   |  0.0943975079057913 |  0.999056024920942   |\n",
      "| neutral  |    16   | 0.07551800632463303 |  0.9992448199367536  |\n",
      "| negative |    54   |  0.2548732713456365 |  0.9974512672865437  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Gepäck                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21164  |  99.89144286590835   | 0.0010855713409165801 |\n",
      "| neutral  |    10   | 0.04719875395289565  |   0.9995280124604711  |\n",
      "| negative |    12   | 0.056638504743474774 |   0.9994336149525652  |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pre_training - DEBUG - 20 initialized\n",
      "pre_training - DEBUG - Initilize parameters with nn.init.xavier_uniform_\n",
      "pre_training - DEBUG - Tagger initialized\n",
      "pre_training - INFO - JointAspectTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(67041, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((67041, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=24891744\n",
      "  (taggers): ModuleList(\n",
      "    (0): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (1): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (2): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (3): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (4): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (5): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (6): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (7): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (8): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (9): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (10): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (11): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (12): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (13): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (14): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (15): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (16): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (17): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (18): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (19): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "  ), weights=((300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,)), parameters=9030080\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 33.921.824\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (300x38x1). Calculated output size: (300x-57x1). Output size is too small at c:\\a\\w\\1\\s\\tmp_conda_3.6_105809\\conda\\conda-bld\\pytorch_1544094150554\\work\\aten\\src\\thnn\\generic/SpatialDilatedMaxPooling.c:51",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9a47e7970af0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Load model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f7335149dfab>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(dataset, hp, experiment_name)\u001b[0m\n\u001b[0;32m     13\u001b[0m                         \u001b[0mexperiment_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0menable_tensorboard\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                         verbose=True)\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\models\\transformer\\train.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, loss, optimizer, hyperparameters, dataset, experiment_name, enable_tensorboard, verbose)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                         \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'long'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_training\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\misc\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device, dtype)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\models\\jointAspectTagger.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;31m# provide the result to each aspect tagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect_tagger\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                         \u001b[0mtagging_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maspect_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                         \u001b[0mtagging_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagging_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Studium\\Studium\\6. Semester\\MA\\Project\\ABSA-Transformer\\models\\softmax_output.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask, *args)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                                        \u001b[1;31m# [batch_size, 1, num_words, model_size] -> [batch_size, num_filters, num_words - padding, 1] e.g. [12, 300, 96, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                                     \u001b[1;31m# [batch_size, num_filters, num_words - padding, 1] -> [batch_size, num_filters, 1, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# [batch_size, num_filters] -> [batch_size, classes] e.g. [12, 4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    146\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    147\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;31m# type: (Tensor, BroadcastingList2[int], Optional[BroadcastingList2[int]], BroadcastingList2[int], BroadcastingList2[int], bool, bool) -> Tensor  # noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     return max_pool2d_with_indices(\n\u001b[1;32m--> 425\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)[0]\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m max_pool2d = torch._jit_internal.boolean_dispatch(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmax_pool2d_with_indices\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0m_stride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d_with_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (300x38x1). Calculated output size: (300x-57x1). Output size is too small at c:\\a\\w\\1\\s\\tmp_conda_3.6_105809\\conda\\conda-bld\\pytorch_1544094150554\\work\\aten\\src\\thnn\\generic/SpatialDilatedMaxPooling.c:51"
     ]
    }
   ],
   "source": [
    "dataset_logger = logging.getLogger('data_loader')\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "logger.debug('Load dataset')\n",
    "dataset = load(hp, dataset_logger)\n",
    "logger.debug('dataset loaded')\n",
    "logger.debug('Load model')\n",
    "trainer = load_model(dataset, hp, experiment_name)\n",
    "logger.debug('model loaded')\n",
    "\n",
    "logger.debug('Begin training')\n",
    "model = None\n",
    "try:\n",
    "    result = trainer.train(use_cuda=hp.use_cuda, perform_evaluation=False)\n",
    "    model = result['model']\n",
    "except Exception as err:\n",
    "    logger.exception(\"Could not complete iteration \" + str(optim_iteration))\n",
    "    print(f'Could not complete iteration {optim_iteration} because of {str(err)}')\n",
    "    continue\n",
    "\n",
    "# perform evaluation and log results\n",
    "result = None\n",
    "try:\n",
    "    result = trainer.perform_final_evaluation(use_test_set=False, verbose=False)\n",
    "except Exception as err:\n",
    "    logger.exception(\"Could not complete iteration evaluation for it \" + str(optim_iteration))\n",
    "    print(f'Could not complete iteration {optim_iteration} evaluation because of {str(err)}')\n",
    "    continue\n",
    "\n",
    "it_f1 = result[1][1]\n",
    "if best_f1 < it_f1:\n",
    "    best_f1 = it_f1\n",
    "    best_model = model\n",
    "    best_hp = copy.copy(hp)\n",
    "    best_iteration = optim_iteration\n",
    "    print('+-------------------------------------------------+')\n",
    "    print(f'Best Valid Result: {best_f1}')\n",
    "    print('+-------------------------------------------------+')\n",
    "else:\n",
    "    print(f'\\nValid Result: {best_f1}\\n')    \n",
    "print('\\n\\n###################################################\\n')\n",
    "    \n",
    "print('Best iteration: ' + str(best_iteration))\n",
    "print('Best f1: ' + str(best_f1))\n",
    "print('Best HP:')\n",
    "print(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
