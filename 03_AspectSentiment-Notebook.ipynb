{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "from data.data_loader import Dataset\n",
    "from data.germeval2017 import germeval2017_dataset\n",
    "\n",
    "from misc.preferences import PREFERENCES\n",
    "from misc.run_configuration import get_default_params, randomize_params\n",
    "from misc import utils\n",
    "\n",
    "from optimizer import get_default_optimizer\n",
    "from criterion import NllLoss, LossCombiner\n",
    "\n",
    "from models.transformer.encoder import TransformerEncoder\n",
    "from models.softmax_output import SoftmaxOutputLayerWithCommentWiseClass\n",
    "from models.transformer_tagger import TransformerTagger\n",
    "from models.jointAspectTagger import JointAspectTagger\n",
    "from models.transformer.train import Trainer\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFERENCES.defaults(\n",
    "    data_root='./data/germeval2017',\n",
    "    data_train='train_v1.4.tsv',    \n",
    "    data_validation='dev_v1.4.tsv',\n",
    "    data_test='test_TIMESTAMP1.tsv',\n",
    "    early_stopping='highest_5_F1'\n",
    ")\n",
    "def load(hp, logger):\n",
    "    dataset = Dataset(\n",
    "        'germeval',\n",
    "        logger,\n",
    "        hp,\n",
    "        source_index=0,\n",
    "        target_vocab_index=2,\n",
    "        data_path=PREFERENCES.data_root,\n",
    "        train_file=PREFERENCES.data_train,\n",
    "        valid_file=PREFERENCES.data_validation,\n",
    "        test_file=PREFERENCES.data_test,\n",
    "        file_format='.tsv',\n",
    "        init_token=None,\n",
    "        eos_token=None\n",
    "    )\n",
    "    dataset.load_data(germeval2017_dataset, verbose=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dataset, hp, experiment_name):\n",
    "    loss = LossCombiner(4, dataset.class_weights, NllLoss)\n",
    "    transformer = TransformerEncoder(dataset.source_embedding,\n",
    "                                     hyperparameters=hp)\n",
    "    model = JointAspectTagger(transformer, hp, 4, 20, dataset.target_names)\n",
    "    optimizer = get_default_optimizer(model, hp)\n",
    "    trainer = Trainer(\n",
    "                        model,\n",
    "                        loss,\n",
    "                        optimizer,\n",
    "                        hp,\n",
    "                        dataset,\n",
    "                        experiment_name,\n",
    "                        enable_tensorboard=False,\n",
    "                        verbose=True)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Conv2dLayerTest'\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path is  /data/home/felix/ABSA-Transformer/logs/Conv2dLayerTest/20190224/1\n"
     ]
    }
   ],
   "source": [
    "# get general logger just for search\n",
    "experiment_name = utils.create_loggers(experiment_name=experiment_name)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_current_git_commit()\n",
    "logger.info('Current commit: ' + utils.get_current_git_commit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|          Hyperparameters           |\n",
      "+-------------------------+----------+\n",
      "|        Parameter        |  Value   |\n",
      "+-------------------------+----------+\n",
      "|        batch_size       |    12    |\n",
      "|        model_size       |   300    |\n",
      "|    learning_rate_type   |   noam   |\n",
      "|      learning_rate      |    0     |\n",
      "|   learning_rate_warmup  |   4800   |\n",
      "|   learning_rate_factor  |    2     |\n",
      "|     optim_adam_beta1    |   0.9    |\n",
      "|     optim_adam_beta2    |   0.98   |\n",
      "|      early_stopping     |    5     |\n",
      "|         use_cuda        |   True   |\n",
      "|       n_enc_blocks      |    3     |\n",
      "|         n_heads         |    6     |\n",
      "|           d_k           |    50    |\n",
      "|           d_v           |    50    |\n",
      "|       dropout_rate      |   0.1    |\n",
      "|   pointwise_layer_size  |   2048   |\n",
      "|    output_layer_type    |   conv   |\n",
      "| output_conv_num_filters |   300    |\n",
      "| output_conv_kernel_size |    5     |\n",
      "|    output_conv_stride   |    1     |\n",
      "|   output_conv_padding   |    0     |\n",
      "| log_every_xth_iteration |    -1    |\n",
      "|        num_epochs       |    15    |\n",
      "|      embedding_type     | fasttext |\n",
      "|      embedding_name     |    6B    |\n",
      "|      embedding_dim      |   300    |\n",
      "|     clip_comments_to    |   100    |\n",
      "|         language        |    de    |\n",
      "|      use_stop_words     |   True   |\n",
      "|           seed          |    42    |\n",
      "+-------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "hp = get_default_params(use_cuda)\n",
    "hp.num_epochs = 15\n",
    "\n",
    "logger.info(hp)\n",
    "print(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|  GERM EVAL 2017 DATASET |\n",
      "+---------------+---------+\n",
      "|     Split     |   Size  |\n",
      "+---------------+---------+\n",
      "|     train     |  17043  |\n",
      "|   validation  |   2049  |\n",
      "|      test     |   2095  |\n",
      "+---------------+---------+\n",
      "+--------------------------------------+\n",
      "|           Vocabulary Stats           |\n",
      "+------------------------------+-------+\n",
      "|          Vocabulary          |  Size |\n",
      "+------------------------------+-------+\n",
      "|           comments           | 67041 |\n",
      "|      general_sentiments      |   3   |\n",
      "|      aspect_sentiments       |   4   |\n",
      "|           padding            | 23197 |\n",
      "|          Sicherheit          |   4   |\n",
      "| Sonstige_Unregelmässigkeiten |   4   |\n",
      "|          Atmosphäre          |   4   |\n",
      "|      Reisen_mit_Kindern      |   4   |\n",
      "|            Image             |   4   |\n",
      "|           QR-Code            |   3   |\n",
      "| Service_und_Kundenbetreuung  |   4   |\n",
      "|            Gepäck            |   4   |\n",
      "|          Toiletten           |   4   |\n",
      "|       Barrierefreiheit       |   4   |\n",
      "|        Informationen         |   4   |\n",
      "|   Gastronomisches_Angebot    |   4   |\n",
      "|           Zugfahrt           |   4   |\n",
      "|          Allgemein           |   4   |\n",
      "|      DB_App_und_Website      |   4   |\n",
      "|          Ticketkauf          |   4   |\n",
      "|   Komfort_und_Ausstattung    |   4   |\n",
      "| Auslastung_und_Platzangebot  |   4   |\n",
      "|         Connectivity         |   4   |\n",
      "|            Design            |   4   |\n",
      "+------------------------------+-------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                            Sicherheit                           |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight    |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "|   n/a    |  20611  |   97.2813517723132   | 0.02718648227686793 |\n",
      "| negative |   542   |  2.558172464246944   |  0.9744182753575306 |\n",
      "| positive |    22   | 0.10383725869637041  |  0.9989616274130363 |\n",
      "| neutral  |    12   | 0.056638504743474774 |  0.9994336149525652 |\n",
      "|   Sum    |  21187  |                      |         1.0         |\n",
      "+----------+---------+----------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                  Sonstige_Unregelmässigkeiten                  |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "|   n/a    |  19483  |  91.95733232642658  | 0.08042667673573423 |\n",
      "| negative |   1582  |  7.4668428753480915 |  0.9253315712465191 |\n",
      "| positive |    49   | 0.23127389436918866 |  0.9976872610563081 |\n",
      "| neutral  |    73   |  0.3445509038561382 |  0.9965544909614387 |\n",
      "|   Sum    |  21187  |                     |         1.0         |\n",
      "+----------+---------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Atmosphäre                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  19854  | 93.70840609807901  | 0.06291593901920989 |\n",
      "| negative |   1035  | 4.8850710341246995 |  0.951149289658753  |\n",
      "| positive |   133   | 0.6277434275735121 |  0.9937225657242649 |\n",
      "| neutral  |   165   | 0.7787794402227781 |  0.9922122055977722 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                        Reisen_mit_Kindern                        |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |     Class Weight     |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "|   n/a    |  21132  |  99.74040685325907   | 0.002595931467409218 |\n",
      "| positive |    8    | 0.037759003162316514 |  0.9996224099683768  |\n",
      "| neutral  |    17   | 0.08023788171992259  |  0.9991976211828008  |\n",
      "| negative |    30   | 0.14159626185868693  |  0.9985840373814131  |\n",
      "|   Sum    |  21187  |                      |         1.0          |\n",
      "+----------+---------+----------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                              Image                              |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  21129  |   99.7262472270732  | 0.002737527729267941 |\n",
      "| negative |    34   | 0.16047576343984518 |  0.9983952423656015  |\n",
      "| positive |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "| neutral  |    14   |  0.0660782555340539 |  0.9993392174446595  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                              QR-Code                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21185  |  99.99056024920942   | 9.439750790574131e-05 |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "| neutral  |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                  Service_und_Kundenbetreuung                  |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  20589  | 97.17751451361684  | 0.02822485486383164 |\n",
      "| negative |   388   | 1.831311653372351  |  0.9816868834662765 |\n",
      "| positive |   146   | 0.6891018077122764 |  0.9931089819228772 |\n",
      "| neutral  |    64   | 0.3020720252985321 |  0.9969792797470147 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Gepäck                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21164  |  99.89144286590835   | 0.0010855713409165801 |\n",
      "| neutral  |    10   | 0.04719875395289565  |   0.9995280124604711  |\n",
      "| negative |    12   | 0.056638504743474774 |   0.9994336149525652  |\n",
      "| positive |    1    | 0.004719875395289564 |   0.9999528012460471  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------+\n",
      "|                           Toiletten                            |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |    Class Weight    |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "|   n/a    |  21131  |  99.73568697786378   | 0.0026431302213622 |\n",
      "| negative |    41   | 0.19351489120687212  | 0.9980648510879313 |\n",
      "| neutral  |    13   | 0.06135838013876433  | 0.9993864161986123 |\n",
      "| positive |    2    | 0.009439750790579128 | 0.9999056024920943 |\n",
      "|   Sum    |  21187  |                      |        1.0         |\n",
      "+----------+---------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                         Barrierefreiheit                        |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  21097  |  99.57521121442394  | 0.004247887855760579 |\n",
      "| positive |    20   |  0.0943975079057913 |  0.999056024920942   |\n",
      "| neutral  |    16   | 0.07551800632463303 |  0.9992448199367536  |\n",
      "| negative |    54   |  0.2548732713456365 |  0.9974512672865437  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                          Informationen                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20765  |   98.0082125831878  | 0.019917874168121963 |\n",
      "| positive |    51   |  0.2407136451597678 |  0.9975928635484024  |\n",
      "| negative |   285   |  1.345164487657526  |  0.9865483551234248  |\n",
      "| neutral  |    86   | 0.40590928399490256 |  0.995940907160051   |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|                     Gastronomisches_Angebot                      |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |      Class Weight     |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "|   n/a    |  21136  |  99.75928635484024  | 0.0024071364515976246 |\n",
      "| negative |    32   | 0.15103601264926605 |   0.9984896398735074  |\n",
      "| neutral  |    10   | 0.04719875395289565 |   0.9995280124604711  |\n",
      "| positive |    9    | 0.04247887855760608 |   0.9995752112144239  |\n",
      "|   Sum    |  21187  |                     |          1.0          |\n",
      "+----------+---------+---------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                            Zugfahrt                           |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  18958  | 89.47939774389955  | 0.10520602256100442 |\n",
      "| positive |   371   | 1.7510737716524283 |  0.9824892622834758 |\n",
      "| negative |   1706  | 8.052107424363996  |   0.91947892575636  |\n",
      "| neutral  |   152   | 0.7174210600840137 |  0.9928257893991599 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------+\n",
      "|                          Allgemein                           |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy  |     Class Weight    |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "| neutral  |  12308  | 58.09222636522395 | 0.41907773634776047 |\n",
      "|   n/a    |   6176  | 29.14995044130835 |  0.7085004955869165 |\n",
      "| negative |   1922  | 9.071600509746542 |  0.9092839949025345 |\n",
      "| positive |   781   |  3.68622268372115 |  0.9631377731627885 |\n",
      "|   Sum    |  21187  |                   |         1.0         |\n",
      "+----------+---------+-------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                        DB_App_und_Website                       |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20951  |  98.88610940671167  | 0.011138905932883358 |\n",
      "| positive |    41   | 0.19351489120687212 |  0.9980648510879313  |\n",
      "| negative |   134   |  0.6324633029688016 |  0.993675366970312   |\n",
      "| neutral  |    61   |  0.2879123991126634 |  0.9971208760088733  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------+\n",
      "|                           Ticketkauf                          |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|  Label   | Samples |   Triv. Accuracy   |     Class Weight    |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "|   n/a    |  20429  |  96.4223344503705  | 0.03577665549629494 |\n",
      "| negative |   505   | 2.3835370746212297 |  0.9761646292537877 |\n",
      "| neutral  |   137   | 0.6466229291546703 |  0.9935337707084533 |\n",
      "| positive |   116   | 0.5475055458535895 |  0.9945249445414641 |\n",
      "|   Sum    |  21187  |                    |         1.0         |\n",
      "+----------+---------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                     Komfort_und_Ausstattung                     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20989  |  99.06546467173266  | 0.009345353282673385 |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| negative |   117   |  0.5522254212488791 |  0.9944777457875112  |\n",
      "| neutral  |    33   | 0.15575588804455562 |  0.9984424411195545  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                   Auslastung_und_Platzangebot                   |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20868  |  98.49435974890262  | 0.015056402510973732 |\n",
      "| negative |   261   |  1.2318874781705764 |  0.9876811252182942  |\n",
      "| positive |    48   |  0.2265540189738991 |  0.997734459810261   |\n",
      "| neutral  |    10   | 0.04719875395289565 |  0.9995280124604711  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------+\n",
      "|                           Connectivity                          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy   |     Class Weight     |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "|   n/a    |  20871  |   98.5085193750885  | 0.014914806249115009 |\n",
      "| positive |    69   |  0.3256714022749799 |  0.9967432859772501  |\n",
      "| negative |   197   |  0.9298154528720441 |  0.9907018454712796  |\n",
      "| neutral  |    50   | 0.23599376976447822 |  0.9976400623023552  |\n",
      "|   Sum    |  21187  |                     |         1.0          |\n",
      "+----------+---------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|                               Design                              |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|  Label   | Samples |    Triv. Accuracy    |      Class Weight     |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "|   n/a    |  21148  |   99.8159248595837   | 0.0018407514041629547 |\n",
      "| negative |    18   | 0.08495775711521215  |   0.9991504224288479  |\n",
      "| positive |    19   | 0.08967763251050172  |   0.999103223674895   |\n",
      "| neutral  |    2    | 0.009439750790579128 |   0.9999056024920943  |\n",
      "|   Sum    |  21187  |                      |          1.0          |\n",
      "+----------+---------+----------------------+-----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - DEBUG - 20 initialized\n",
      "pre_training - DEBUG - Initilize parameters with nn.init.xavier_uniform_\n",
      "pre_training - DEBUG - Tagger initialized\n",
      "pre_training - INFO - JointAspectTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(67041, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((67041, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=24891744\n",
      "  (taggers): ModuleList(\n",
      "    (0): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (1): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (2): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (3): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (4): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (5): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (6): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (7): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (8): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (9): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (10): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (11): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (12): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (13): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (14): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (15): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (16): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (17): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (18): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (19): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "  ), weights=((300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,)), parameters=9030080\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 33,921,824\n",
      "==================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1             [-1, 100, 300]      20,112,300\n",
      "           Dropout-2             [-1, 100, 300]               0\n",
      "PositionalEncoding2-3             [-1, 100, 300]               0\n",
      "            Linear-4             [-1, 100, 300]          90,000\n",
      "            Linear-5             [-1, 100, 300]          90,000\n",
      "            Linear-6             [-1, 100, 300]          90,000\n",
      "           Dropout-7             [-1, 100, 100]               0\n",
      "ScaledDotProductAttentionLayer-8              [-1, 100, 50]               0\n",
      "            Linear-9             [-1, 100, 300]          90,000\n",
      "          Dropout-10             [-1, 100, 300]               0\n",
      "        LayerNorm-11             [-1, 100, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-12             [-1, 100, 300]               0\n",
      "           Linear-13            [-1, 100, 2048]         616,448\n",
      "           Linear-14             [-1, 100, 300]         614,700\n",
      "          Dropout-15             [-1, 100, 300]               0\n",
      "        LayerNorm-16             [-1, 100, 300]               0\n",
      "     EncoderBlock-17             [-1, 100, 300]               0\n",
      "           Linear-18             [-1, 100, 300]          90,000\n",
      "           Linear-19             [-1, 100, 300]          90,000\n",
      "           Linear-20             [-1, 100, 300]          90,000\n",
      "          Dropout-21             [-1, 100, 100]               0\n",
      "ScaledDotProductAttentionLayer-22              [-1, 100, 50]               0\n",
      "           Linear-23             [-1, 100, 300]          90,000\n",
      "          Dropout-24             [-1, 100, 300]               0\n",
      "        LayerNorm-25             [-1, 100, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-26             [-1, 100, 300]               0\n",
      "           Linear-27            [-1, 100, 2048]         616,448\n",
      "           Linear-28             [-1, 100, 300]         614,700\n",
      "          Dropout-29             [-1, 100, 300]               0\n",
      "        LayerNorm-30             [-1, 100, 300]               0\n",
      "     EncoderBlock-31             [-1, 100, 300]               0\n",
      "           Linear-32             [-1, 100, 300]          90,000\n",
      "           Linear-33             [-1, 100, 300]          90,000\n",
      "           Linear-34             [-1, 100, 300]          90,000\n",
      "          Dropout-35             [-1, 100, 100]               0\n",
      "ScaledDotProductAttentionLayer-36              [-1, 100, 50]               0\n",
      "           Linear-37             [-1, 100, 300]          90,000\n",
      "          Dropout-38             [-1, 100, 300]               0\n",
      "        LayerNorm-39             [-1, 100, 300]               0\n",
      "MultiHeadedSelfAttentionLayer-40             [-1, 100, 300]               0\n",
      "           Linear-41            [-1, 100, 2048]         616,448\n",
      "           Linear-42             [-1, 100, 300]         614,700\n",
      "          Dropout-43             [-1, 100, 300]               0\n",
      "        LayerNorm-44             [-1, 100, 300]               0\n",
      "     EncoderBlock-45             [-1, 100, 300]               0\n",
      "TransformerEncoder-46             [-1, 100, 300]               0\n",
      "           Conv2d-47           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-48           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-49            [-1, 300, 1, 1]               0\n",
      "           Linear-50                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-51                    [-1, 4]               0\n",
      "           Conv2d-52           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-53           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-54            [-1, 300, 1, 1]               0\n",
      "           Linear-55                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-56                    [-1, 4]               0\n",
      "           Conv2d-57           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-58           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-59            [-1, 300, 1, 1]               0\n",
      "           Linear-60                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-61                    [-1, 4]               0\n",
      "           Conv2d-62           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-63           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-64            [-1, 300, 1, 1]               0\n",
      "           Linear-65                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-66                    [-1, 4]               0\n",
      "           Conv2d-67           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-68           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-69            [-1, 300, 1, 1]               0\n",
      "           Linear-70                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-71                    [-1, 4]               0\n",
      "           Conv2d-72           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-73           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-74            [-1, 300, 1, 1]               0\n",
      "           Linear-75                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-76                    [-1, 4]               0\n",
      "           Conv2d-77           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-78           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-79            [-1, 300, 1, 1]               0\n",
      "           Linear-80                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-81                    [-1, 4]               0\n",
      "           Conv2d-82           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-83           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-84            [-1, 300, 1, 1]               0\n",
      "           Linear-85                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-86                    [-1, 4]               0\n",
      "           Conv2d-87           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-88           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-89            [-1, 300, 1, 1]               0\n",
      "           Linear-90                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-91                    [-1, 4]               0\n",
      "           Conv2d-92           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-93           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-94            [-1, 300, 1, 1]               0\n",
      "           Linear-95                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-96                    [-1, 4]               0\n",
      "           Conv2d-97           [-1, 300, 96, 1]         450,300\n",
      "             ReLU-98           [-1, 300, 96, 1]               0\n",
      "        MaxPool2d-99            [-1, 300, 1, 1]               0\n",
      "          Linear-100                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-101                    [-1, 4]               0\n",
      "          Conv2d-102           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-103           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-104            [-1, 300, 1, 1]               0\n",
      "          Linear-105                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-106                    [-1, 4]               0\n",
      "          Conv2d-107           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-108           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-109            [-1, 300, 1, 1]               0\n",
      "          Linear-110                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-111                    [-1, 4]               0\n",
      "          Conv2d-112           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-113           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-114            [-1, 300, 1, 1]               0\n",
      "          Linear-115                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-116                    [-1, 4]               0\n",
      "          Conv2d-117           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-118           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-119            [-1, 300, 1, 1]               0\n",
      "          Linear-120                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-121                    [-1, 4]               0\n",
      "          Conv2d-122           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-123           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-124            [-1, 300, 1, 1]               0\n",
      "          Linear-125                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-126                    [-1, 4]               0\n",
      "          Conv2d-127           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-128           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-129            [-1, 300, 1, 1]               0\n",
      "          Linear-130                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-131                    [-1, 4]               0\n",
      "          Conv2d-132           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-133           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-134            [-1, 300, 1, 1]               0\n",
      "          Linear-135                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-136                    [-1, 4]               0\n",
      "          Conv2d-137           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-138           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-139            [-1, 300, 1, 1]               0\n",
      "          Linear-140                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-141                    [-1, 4]               0\n",
      "          Conv2d-142           [-1, 300, 96, 1]         450,300\n",
      "            ReLU-143           [-1, 300, 96, 1]               0\n",
      "       MaxPool2d-144            [-1, 300, 1, 1]               0\n",
      "          Linear-145                    [-1, 4]           1,204\n",
      "ConvSoftmaxOutputLayerWithCommentWiseClass-146                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 33,915,824\n",
      "Trainable params: 33,915,824\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 22.34\n",
      "Params size (MB): 129.38\n",
      "Estimated Total Size (MB): 151.71\n",
      "----------------------------------------------------------------\n",
      "pre_training - INFO - JointAspectTagger (\n",
      "  (encoder): TransformerEncoder(\n",
      "    (src_embeddings): Embedding(67041, 300)\n",
      "    (positional_encoding): PositionalEncoding2(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder_blocks): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (self_attention_layer): MultiHeadedSelfAttentionLayer(\n",
      "          (query_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (key_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (value_projections): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (attention_layer): ScaledDotProductAttentionLayer(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_0): Linear(in_features=300, out_features=300, bias=False)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (feed_forward_layer): PointWiseFCLayer(\n",
      "          (layer_norm): LayerNorm()\n",
      "          (w_1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm()\n",
      "  ), weights=((67041, 300), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300, 300), (300, 300), (300, 300), (300,), (300,), (300, 300), (300,), (300,), (2048, 300), (2048,), (300, 2048), (300,), (300,), (300,), (300,), (300,)), parameters=24891744\n",
      "  (taggers): ModuleList(\n",
      "    (0): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (1): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (2): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (3): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (4): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (5): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (6): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (7): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (8): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (9): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (10): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (11): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (12): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (13): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (14): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (15): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (16): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (17): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (18): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "    (19): ConvSoftmaxOutputLayerWithCommentWiseClass(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (pooling): MaxPool2d(kernel_size=(96, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (output_projection): Linear(in_features=300, out_features=4, bias=True)\n",
      "    )\n",
      "  ), weights=((300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,), (300, 1, 5, 300), (300,), (4, 300), (4,)), parameters=9030080\n",
      ")\n",
      "==================================\n",
      "Total Number of parameters: 33,921,824\n",
      "==================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - Classes: ['n/a', 'neutral', 'negative', 'positive']\n",
      "pre_training - DEBUG - train with cuda support\n",
      "pre_training - INFO - 1421 Iterations per epoch with batch size of 12\n",
      "pre_training - INFO - Total iterations: 21315\n",
      "pre_training - INFO - START training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1421/1421 [04:17<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EP\t# IT\ttr loss\t\tval loss\tf1\t\tacc\t\tduration / total time\n",
      "1\t1421\t10.23\t\t\u001b[32m9.55\t\t\u001b[32m0.244\u001b[0m\t\t0.959\t\t4.29m - 4.3m / 0.0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/1421 [08:34<30:31:38, 77.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t2842\t10.24\t\t\u001b[37m10.70\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 8.6m / 64.3m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/1421 [12:51<30:31:38, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t4263\t10.25\t\t\u001b[32m9.78\t\t\u001b[37m0.240\u001b[0m\t\t0.932\t\t4.28m - 12.9m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1421/1421 [17:07<00:00, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t5684\t10.14\t\t\u001b[32m9.42\t\t\u001b[32m0.244\u001b[0m\t\t0.959\t\t4.28m - 17.1m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/1421 [21:25<30:31:38, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t7105\t9.90\t\t\u001b[32m9.61\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 21.4m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/1421 [25:41<30:31:38, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t8526\t9.85\t\t\u001b[37m10.06\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 25.7m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/1421 [29:58<30:31:38, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t9947\t9.84\t\t\u001b[32m9.12\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 30.0m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/1421 [34:15<30:31:38, 77.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t11368\t9.86\t\t\u001b[32m9.26\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 34.3m / 64.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1421/1421 [38:31<00:00, 77.34s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t12789\t9.78\t\t\u001b[32m8.97\t\t\u001b[37m0.244\u001b[0m\t\t0.959\t\t4.28m - 38.5m / 64.2m\n",
      "pre_training - INFO - Perform final model evaluation\n",
      "pre_training - DEBUG - --- Train Scores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - TRAIN loss:\t9.547267971703237\n",
      "pre_training - INFO - TRAIN f1-s:\t0.24403683939570603\n",
      "pre_training - INFO - TRAIN accuracy:\t0.958325998943848\n",
      "pre_training - DEBUG - --- Valid Scores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - Perform final model evaluation\n",
      "pre_training - DEBUG - --- Train Scores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_training - INFO - TRAIN loss:\t9.56523290626773\n",
      "pre_training - INFO - TRAIN f1-s:\t0.24403683939570603\n",
      "pre_training - INFO - TRAIN accuracy:\t0.958325998943848\n",
      "pre_training - DEBUG - --- Valid Scores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not complete iterationevaluation because of Dimension out of range (expected to be in range of [-1, 0], but got 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset_logger = logging.getLogger('data_loader')\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "logger.debug('Load dataset')\n",
    "dataset = load(hp, dataset_logger)\n",
    "logger.debug('dataset loaded')\n",
    "logger.debug('Load model')\n",
    "trainer = load_model(dataset, hp, experiment_name)\n",
    "logger.debug('model loaded')\n",
    "\n",
    "logger.debug('Begin training')\n",
    "model = None\n",
    "try:\n",
    "    result = trainer.train(use_cuda=hp.use_cuda, perform_evaluation=True)\n",
    "    model = result['model']\n",
    "except Exception as err:\n",
    "    logger.exception(\"Could not complete iteration because of \" + str(err))\n",
    "    print(f'Could not complete iteration because of {str(err)}')\n",
    "\n",
    "# perform evaluation and log results\n",
    "result = None\n",
    "try:\n",
    "    result = trainer.perform_final_evaluation(use_test_set=False, verbose=True)\n",
    "except Exception as err:\n",
    "    logger.exception(\"Could not complete iteration evaluation for it \" + str(err))\n",
    "    print(f'Could not complete iterationevaluation because of {str(err)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
