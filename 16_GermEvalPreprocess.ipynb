{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "from tqdm.autonotebook import tqdm\n",
    "import re\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hunspell\n",
    "hobj = hunspell.HunSpell('/Library/Spelling/de_DE.dic', '/Library/Spelling/de_DE.aff')\n",
    "known_words = ['@DB_Bahn', 'ÖPNV', 'Hashtag', 'GDL', 'Hbf', 'Fahrplanwechsel', 'co2', 'Waitrose', '<URL>', 'certifier', 'TLDR', 'Coca~Cola', 'Quora', 'sci-fi']\n",
    "\n",
    "for w in known_words:\n",
    "    hobj.add(w)\n",
    "    \n",
    "# also add the english one\n",
    "hobj_en = hunspell.HunSpell('/Library/Spelling/en_US.dic', '/Library/Spelling/en_US.aff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Das ist ein Text  mit einer URL <URL>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_regex = r'(?:http(s)?:\\/\\/)?[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&\\(\\)\\*\\+,;=.]+'\n",
    "\n",
    "def replace_urls_regex(sentence: str, url_token: str = '<URL>') -> str:\n",
    "    return re.sub(url_regex, url_token, sentence)\n",
    "\n",
    "def replace_urls(words, url_token: str = '<URL>'):\n",
    "    return [url_token if (w.lower().startswith('www') or w.lower().startswith('http')) else w for w in words]\n",
    "\n",
    "\n",
    "def clean_text_without_sp(row) -> str:\n",
    "    sent = ''\n",
    "    try:\n",
    "        sent = row['text']\n",
    "        sent = replace_urls_regex(sent)    \n",
    "\n",
    "        #print(sent)\n",
    "        to_remove = [',', '(', ')', ':', '?', '&', '/', '*', '!', ';', '\"', '.', '+']\n",
    "        for tr in to_remove:\n",
    "            sent = sent.replace(tr, ' ')\n",
    "\n",
    "        sent = sent.replace('€™', \"'\")\n",
    "        sent = sent.replace('�', \"'\")\n",
    "        sent = en_contraction_removal(sent)\n",
    "        sent = sent.replace(\"'\", ' ')\n",
    "    except Exception as err:\n",
    "        print('Could not clean sentence: ' + str(err))\n",
    "        \n",
    "        try:\n",
    "            sent = row['text']\n",
    "            return sent\n",
    "        except Exception as err:\n",
    "            print('Could not get sentence from row. Returning empty sentence: ' + str(err))\n",
    "            return ''\n",
    "    return sent\n",
    "\n",
    "def clean_text(row) -> str:\n",
    "    sent = ''\n",
    "    try:\n",
    "        sent = spellcheck_sentence(row)\n",
    "    except Exception as err:\n",
    "        print('Could not spellcheck sentence: ' + str(err))\n",
    "        \n",
    "        try:\n",
    "            sent = row['text']\n",
    "            return sent\n",
    "        except Exception as err:\n",
    "            print('Could not get sentence from row. Returning empty sentence: ' + str(err))\n",
    "            return ''\n",
    "    return sent\n",
    "        \n",
    "\n",
    "def spellcheck_sentence(row) -> str:\n",
    "    sent = row['text']\n",
    "    sent = replace_urls_regex(sent)\n",
    "\n",
    "\n",
    "    #print(sent)\n",
    "    to_remove = [',', '(', ')', ':', '?', '&', '/', '*', '!']\n",
    "    for tr in to_remove:\n",
    "        sent = sent.replace(tr, ' ')\n",
    "        \n",
    "    sent = sent.replace('€™', \"'\")\n",
    "    sent = sent.replace('�', \"'\")\n",
    "    sent = sent.replace(\"'\", ' ')\n",
    "\n",
    "    tokens = sent.split(' ')\n",
    "    result = []\n",
    "    for t in tokens:\n",
    "        if t == ' ':\n",
    "            continue\n",
    "            \n",
    "        correct = True\n",
    "        try:\n",
    "            correct = hobj.spell(t) or hobj_en.spell(t)\n",
    "\n",
    "        except Exception as err:\n",
    "            print('Could not get spell checking for token ' + str(t))\n",
    "            # do not keep token in case of error\n",
    "            continue\n",
    "            \n",
    "        if not correct:\n",
    "            suggestions = hobj.suggest(t)\n",
    "            if not suggestions:\n",
    "                result.append(t)\n",
    "            else:\n",
    "                if suggestions[0] == 'e':\n",
    "                    result.append(t)\n",
    "                    continue\n",
    "                result.append(suggestions[0])\n",
    "                #print(f'{t} -> {suggestions[0]}')\n",
    "        else:\n",
    "            result.append(t)\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "        \n",
    "spellcheck_sentence({'text': 'Das ist ein TExt, mit einer url https://github.com/wooorm/dictionaries'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'data', 'data', 'germeval2017')\n",
    "header = ['url', 'text', 'relevance', 'document sentiment', 'aspect sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: dev_v1.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909180d2c133425291db051a04dde20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2584), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Split: train_v1.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d381253352af4e8293c6daa5a3169979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20941), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Split: test_TIMESTAMP1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba2adda16a44c5e8f0f646935c56c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2566), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Could not spellcheck sentence: expected string or bytes-like object\n",
      "Split: test_TIMESTAMP2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625b7781a48f4d5eb928c56c41955d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1842), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = ['dev_v1.4', 'train_v1.4', 'test_TIMESTAMP1', 'test_TIMESTAMP2']\n",
    "path = os.path.join(os.getcwd(), 'data', 'data', 'germeval2017')\n",
    "\n",
    "for s in splits:\n",
    "    print('Split: ' + str(s))\n",
    "    fn = os.path.join(path, s + '.tsv')\n",
    "    df = pd.read_csv(fn, sep='\\t', header=None, names=header, index_col=False) #\n",
    "    df['text'] = df.progress_apply(clean_text, axis=1)\n",
    "    \n",
    "    fn = os.path.join(path, s + '_sp.csv')\n",
    "    df.to_csv(fn, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test2 = pd.read_csv(os.path.join(path, 'test_TIMESTAMP2.tsv'), sep='\\t', header=None, names=header, index_col=False)\n",
    "test1 = pd.read_csv(os.path.join(path, 'test_TIMESTAMP1.tsv'), sep='\\t', header=None, names=header, index_col=False)\n",
    "train = pd.read_csv(os.path.join(path, 'train_v1.4.tsv'), sep='\\t', header=None, names=header, index_col=False)\n",
    "val = pd.read_csv(os.path.join(path, 'dev_v1.4.tsv'), sep='\\t', header=None, names=header, index_col=False)\n",
    "\n",
    "test1['split'] = test1.apply(lambda r: 'test1', axis=1)\n",
    "test2['split'] = test2.apply(lambda r: 'test2', axis=1)\n",
    "train['split'] = train.apply(lambda r: 'train', axis=1)\n",
    "val['split'] = val.apply(lambda r: 'val', axis=1)\n",
    "\n",
    "\n",
    "complete = test2.append(test1).append(train).append(val)\n",
    "complete              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_split = pd.DataFrame()\n",
    "\n",
    "for _, r in tqdm(complete.iterrows(), total=complete.shape[0]):\n",
    "    asp_sent = r['aspect sentiments']\n",
    "    if pd.isnull(asp_sent) or asp_sent == '':\n",
    "        complete_split = complete_split.append(r)\n",
    "        continue\n",
    "    asp_sent = asp_sent.split(\" \")\n",
    "    #print(asp_sent)\n",
    "    aspects = []\n",
    "    for as_pair in asp_sent:\n",
    "        if as_pair == '' or len(as_pair.split(':')) != 2:\n",
    "            continue\n",
    "\n",
    "        as_pair = as_pair.split(':')\n",
    "        aspect = as_pair[0]\n",
    "        \n",
    "        if len(aspect.split('#')) > 0:\n",
    "            aspect = aspect.split('#')[0]\n",
    "        \n",
    "        # prevent duplicates\n",
    "        if aspect in aspects:\n",
    "            continue\n",
    "\n",
    "        aspects.append(aspect)\n",
    "        \n",
    "        #print('\\t' + str(as_pair))\n",
    "        sentiment = as_pair[1]\n",
    "        rd = r.to_dict()\n",
    "        rd['specific_sentiment'] = sentiment\n",
    "        rd['specific_aspect'] = aspect\n",
    "        rd['asp_sent'] = f'{aspect}-{sentiment}'\n",
    "        complete_split = complete_split.append(rd, ignore_index=True)\n",
    "\n",
    "    \n",
    "complete_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_split.to_pickle(os.path.join(path, 'merge.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = complete_split['split'] == 'train'\n",
    "val_split = complete_split['split'] == 'val'\n",
    "test1_split = complete_split['split'] == 'test1'\n",
    "test2_split = complete_split['split'] == 'test2'\n",
    "\n",
    "t2_agg = complete_split[test2_split].groupby(['specific_aspect', 'specific_sentiment'], as_index=False).count().rename(columns={'asp_sent':'diachronic test'})\n",
    "t1_agg = complete_split[test1_split].groupby(['specific_aspect', 'specific_sentiment'], as_index=False).count().rename(columns={'asp_sent':'synchronic test'})\n",
    "tr_agg = complete_split[train_split].groupby(['specific_aspect', 'specific_sentiment'], as_index=False).count().rename(columns={'asp_sent':'train'})\n",
    "vl_agg = complete_split[val_split].groupby(['specific_aspect', 'specific_sentiment'], as_index=False).count().rename(columns={'asp_sent':'validation'})\n",
    "\n",
    "\n",
    "cnt_agg = t1_agg.merge(t2_agg, on=['specific_aspect', 'specific_sentiment']).merge(tr_agg, on=['specific_aspect', 'specific_sentiment']).merge(vl_agg, on=['specific_aspect', 'specific_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_agg = cnt_agg.set_index(['specific_aspect', 'specific_sentiment'])\n",
    "cnt_agg[['train', 'validation', 'synchronic test', 'diachronic test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_sum = t2_agg[['diachronic test', 'specific_aspect']].groupby('specific_aspect', as_index=False).sum()\n",
    "t1_sum = t1_agg[['synchronic test', 'specific_aspect']].groupby('specific_aspect', as_index=False).sum()\n",
    "tr_sum = tr_agg[['train', 'specific_aspect']].groupby('specific_aspect', as_index=False).sum()\n",
    "va_sum = vl_agg[['validation', 'specific_aspect']].groupby('specific_aspect', as_index=False).sum()\n",
    "va_sum.sort_values(by='specific_aspect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = t1_sum.merge(t2_sum, on=['specific_aspect']).merge(tr_sum, on=['specific_aspect']).merge(va_sum, on=['specific_aspect'])\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
