\chapter{\abstractname}

In this master's thesis we propose a novel neural network architecture for \acrfull{absa}. This architecture is based on the Google transformer introduced in 2017~\cite{Vaswani2017} and inspired by the words of Schmitt et al.~\cite{Schmitt2018}.
\medskip

The model we propose classifies multilabel aspect based sentiment end-to-end. To the best of our knowledge this is the first model which uses a transformer for aspect based sentiment detection.
\medskip

Furthermore, this thesis explores transfer- and multitask learning. We show that multitask learning is capable of augmenting data with auxiliary tasks, thereby boosting model performance. For transfer learning we develop a large scale amazon review dataset which we use to achieve significant performance increases.
\medskip

We evaluate and benchmark our proposed architecture on four datasets and show that the proposed \acrfull{absat} model achieves very competitive results on all datasets.

