% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{Blitzer2007}{inproceedings}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=4cf8cf8b1e08936da7cbd269f4327216}{%
           family={Blitzer},
           familyi={B\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=fad798cd3972b70e217b653e07abc99d}{%
           family={Dredze},
           familyi={D\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=3ef139cfd819ad7d3af54f3d2e9507b9}{%
           family={Pereira},
           familyi={P\bibinitperiod},
           given={Fernando},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Prague, Czech Republic}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{2a209d9caa4702f4911fe2bbf586a95c}
      \strng{fullhash}{2a209d9caa4702f4911fe2bbf586a95c}
      \strng{bibnamehash}{2a209d9caa4702f4911fe2bbf586a95c}
      \strng{authorbibnamehash}{2a209d9caa4702f4911fe2bbf586a95c}
      \strng{authornamehash}{2a209d9caa4702f4911fe2bbf586a95c}
      \strng{authorfullhash}{2a209d9caa4702f4911fe2bbf586a95c}
      \field{sortinit}{B}
      \field{sortinithash}{276475738cc058478c1677046f857703}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30{\%} over the original SCL algorithm and 46{\%} over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains.}
      \field{annotation}{introduction domain adaptation}
      \field{booktitle}{Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics}
      \field{title}{{Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification}}
      \field{year}{2007}
      \field{pages}{440\bibrangedash 447}
      \range{pages}{8}
      \verb{file}
      \verb :C$\backslash$:/Users/felix/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blitzer, Dredze, Pereira - 2007 - Biographies, Bollywood, Boom-boxes and Blenders Domain Adaptation for Sentiment Classification.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://ida.
      \endverb
      \verb{url}
      \verb http://ida.
      \endverb
    \endentry
    \entry{Caruana1997a}{thesis}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=599c5251d489b92dc7856277d56cb1a9}{%
           family={Caruana},
           familyi={C\bibinitperiod},
           given={Rich},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {Carnegie Melon University}%
      }
      \strng{namehash}{599c5251d489b92dc7856277d56cb1a9}
      \strng{fullhash}{599c5251d489b92dc7856277d56cb1a9}
      \strng{bibnamehash}{599c5251d489b92dc7856277d56cb1a9}
      \strng{authorbibnamehash}{599c5251d489b92dc7856277d56cb1a9}
      \strng{authornamehash}{599c5251d489b92dc7856277d56cb1a9}
      \strng{authorfullhash}{599c5251d489b92dc7856277d56cb1a9}
      \field{sortinit}{C}
      \field{sortinithash}{963e9d84a3da2344e8833203de5aed05}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Multitask Learning}}
      \field{type}{Ph.D thesis}
      \field{year}{1997}
      \verb{file}
      \verb :C$\backslash$:/Users/felix/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Caruana - 1997 - Multitask Learning.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://www8.cs.umu.se/research/ifor/dl/LEARNING/multitask learning.pdf
      \endverb
      \verb{url}
      \verb http://www8.cs.umu.se/research/ifor/dl/LEARNING/multitask%20learning.pdf
      \endverb
    \endentry
    \entry{Caruana1993}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=2965a10236a9abe0c21d7d05358c7a2d}{%
           family={Caruana},
           familyi={C\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2965a10236a9abe0c21d7d05358c7a2d}
      \strng{fullhash}{2965a10236a9abe0c21d7d05358c7a2d}
      \strng{bibnamehash}{2965a10236a9abe0c21d7d05358c7a2d}
      \strng{authorbibnamehash}{2965a10236a9abe0c21d7d05358c7a2d}
      \strng{authornamehash}{2965a10236a9abe0c21d7d05358c7a2d}
      \strng{authorfullhash}{2965a10236a9abe0c21d7d05358c7a2d}
      \field{sortinit}{C}
      \field{sortinithash}{963e9d84a3da2344e8833203de5aed05}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING}
      \field{title}{{Multitask Learning: A Knowledge-Based Source of Inductive Bias}}
      \field{year}{1993}
      \field{pages}{41\bibrangedash 48}
      \range{pages}{8}
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.3196
      \endverb
      \verb{url}
      \verb http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.3196
      \endverb
    \endentry
    \entry{He2016}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=1b8a48b9ddb1c09f1c48bd467d99488a}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Ruining},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=24f98302ee924662159ce29687c18e4e}{%
           family={McAuley},
           familyi={M\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{fcd9fe5c698fb1a95b86c14df5013495}
      \strng{fullhash}{fcd9fe5c698fb1a95b86c14df5013495}
      \strng{bibnamehash}{fcd9fe5c698fb1a95b86c14df5013495}
      \strng{authorbibnamehash}{fcd9fe5c698fb1a95b86c14df5013495}
      \strng{authornamehash}{fcd9fe5c698fb1a95b86c14df5013495}
      \strng{authorfullhash}{fcd9fe5c698fb1a95b86c14df5013495}
      \field{sortinit}{H}
      \field{sortinithash}{5f15a7bc777ad49ff15aa4d2831b1681}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Building a successful recommender system depends on understanding both the dimensions of people's preferences as well as their dynamics. In certain domains, such as fashion, modeling such preferences can be incredibly difficult, due to the need to simultaneously model the visual appearance of products as well as their evolution over time. The subtle semantics and non-linear dynamics of fashion evolution raise unique challenges especially considering the sparsity and large scale of the underlying datasets. In this paper we build novel models for the One-Class Collaborative Filtering setting, where our goal is to estimate users' fashion-aware personalized ranking functions based on their past feedback. To uncover the complex and evolving visual factors that people consider when evaluating products, our method combines high-level visual features extracted from a deep convolutional neural network, users' past feedback, as well as evolving trends within the community. Experimentally we evaluate our method on two large real-world datasets from Amazon.com, where we show it to outperform state-of-the-art personalized ranking measures, and also use it to visualize the high-level fashion trends across the 11-year span of our dataset.}
      \field{eprinttype}{arXiv}
      \field{isbn}{9781450341431}
      \field{title}{{Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering}}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1145/2872427.2883037
      \endverb
      \verb{eprint}
      \verb 1602.01585
      \endverb
      \verb{file}
      \verb :C$\backslash$:/Users/felix/OneDrive/Desktop/1602.01585.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1602.01585{\%}0Ahttp://dx.doi.org/10.1145/2872427.2883037
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1602.01585%7B%5C%%7D0Ahttp://dx.doi.org/10.1145/2872427.2883037
      \endverb
      \keyw{fashion evolution,personalized ranking,recommender systems}
    \endentry
    \entry{Iyer1999}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=45f090d988ecb270e6a2c5523880020f}{%
           family={Iyer},
           familyi={I\bibinitperiod},
           given={Mahesh\bibnamedelima S.},
           giveni={M\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=a5094db438940abc6cbb77546c49dc00}{%
           family={Rhinehart},
           familyi={R\bibinitperiod},
           given={R.\bibnamedelimi Russell},
           giveni={R\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ca76a1fe1142513355b4e3785b60ec15}
      \strng{fullhash}{ca76a1fe1142513355b4e3785b60ec15}
      \strng{bibnamehash}{ca76a1fe1142513355b4e3785b60ec15}
      \strng{authorbibnamehash}{ca76a1fe1142513355b4e3785b60ec15}
      \strng{authornamehash}{ca76a1fe1142513355b4e3785b60ec15}
      \strng{authorfullhash}{ca76a1fe1142513355b4e3785b60ec15}
      \field{sortinit}{I}
      \field{sortinithash}{320bc8fe8101b9376f9f21cd507de0e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Conventional neural network training algorithms often get stuck in local minima. To find the global optimum, training is conventionally repeated with 10, or so, random starting values for the weights. Here we develop an analytical procedure to determine how many times a neural network needs to be trained, with random starting weights, to ensure that the best of those is within a desirable lower percentile of all possible trainings, with a certain level of confidence. The theoretical developments are validated by experimental results. While applied to neural network training, the method is generally applicable to nonlinear optimization.}
      \field{issn}{10459227}
      \field{journaltitle}{IEEE Transactions on Neural Networks}
      \field{number}{2}
      \field{title}{{A method to determine the required number of neural-network training repetitions}}
      \field{volume}{10}
      \field{year}{1999}
      \field{pages}{427\bibrangedash 432}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/72.750573
      \endverb
      \verb{file}
      \verb :C$\backslash$:/Users/felix/Downloads/00750573.pdf:pdf
      \endverb
      \keyw{Neural-network training,Steady-state identification,Weakest-link-in-a-chain}
    \endentry
    \entry{LeCun;1990}{article}{}
      \name{author}{6}{}{%
        {{uniquename=0,uniquepart=base,hash=769a6bb10ee7c5d8025d7ded064e2a29}{%
           family={LeCun;},
           familyi={L\bibinitperiod},
           given={Y},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7eacb03f7d28612977f50d8cb1be0bad}{%
           family={Boser},
           familyi={B\bibinitperiod},
           given={B},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=4f138434f743ff4d54b0b36a04662329}{%
           family={Denker},
           familyi={D\bibinitperiod},
           given={John\bibnamedelima S},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=bda766234c11a6558f113fbc70b3a162}{%
           family={Howard},
           familyi={H\bibinitperiod},
           given={R\bibnamedelima E},
           giveni={R\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=4ac80f1eb17df2440de877aa4f54e932}{%
           family={Habbard},
           familyi={H\bibinitperiod},
           given={W},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9789716909ac1531cb255742d7b1068b}{%
           family={Jackel},
           familyi={J\bibinitperiod},
           given={L\bibnamedelima D},
           giveni={L\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1e02fea53989bdfc1c5cb28b1803f3ae}
      \strng{fullhash}{94294e2ffdfbef05c4a8c40eaa4fddae}
      \strng{bibnamehash}{94294e2ffdfbef05c4a8c40eaa4fddae}
      \strng{authorbibnamehash}{94294e2ffdfbef05c4a8c40eaa4fddae}
      \strng{authornamehash}{1e02fea53989bdfc1c5cb28b1803f3ae}
      \strng{authorfullhash}{94294e2ffdfbef05c4a8c40eaa4fddae}
      \field{sortinit}{L}
      \field{sortinithash}{2c7981aaabc885868aba60f0c09ee20f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1{\%} error rate and about a 9{\%} reject rate on zipcode digits provided by the U.S. Postal Service.}
      \field{eprinttype}{arXiv}
      \field{isbn}{1-55860-100-7}
      \field{issn}{1524-4725}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{title}{{Handwritten Digit Recognition with a Back-Propagation Network}}
      \field{year}{1990}
      \field{pages}{396\bibrangedash 404}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1111/dsu.12130
      \endverb
      \verb{eprint}
      \verb 1004.3732
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://papers.nips.cc/paper/293-handwritten-digit-recognition-with-a-back-propagation-network.pdf http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5076{\&}rep=rep1{\&}type=pdf
      \endverb
      \verb{url}
      \verb http://papers.nips.cc/paper/293-handwritten-digit-recognition-with-a-back-propagation-network.pdf%20http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076%7B%5C%%7D5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5076%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf
      \endverb
    \endentry
    \entry{Levenshtein1966}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=245f012ddc9a48f0cfc990bd487f595c}{%
           family={Levenshtein},
           familyi={L\bibinitperiod},
           given={V.I.},
           giveni={V\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{245f012ddc9a48f0cfc990bd487f595c}
      \strng{fullhash}{245f012ddc9a48f0cfc990bd487f595c}
      \strng{bibnamehash}{245f012ddc9a48f0cfc990bd487f595c}
      \strng{authorbibnamehash}{245f012ddc9a48f0cfc990bd487f595c}
      \strng{authornamehash}{245f012ddc9a48f0cfc990bd487f595c}
      \strng{authorfullhash}{245f012ddc9a48f0cfc990bd487f595c}
      \field{sortinit}{L}
      \field{sortinithash}{2c7981aaabc885868aba60f0c09ee20f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Insertions and Reversals. Sov}
      \field{title}{{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}}
      \field{volume}{6}
      \field{year}{1966}
      \field{pages}{707\bibrangedash 710}
      \range{pages}{4}
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf
      \endverb
      \verb{url}
      \verb https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf
      \endverb
    \endentry
    \entry{McAuley2013a}{inproceedings}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=24f98302ee924662159ce29687c18e4e}{%
           family={McAuley},
           familyi={M\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=900d107125ff0ca84698cb909e4f6c51}{%
           family={Leskovec},
           familyi={L\bibinitperiod},
           given={Jure},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Rio de Janeiro, Brazil}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{fullhash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{bibnamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authorbibnamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authornamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authorfullhash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \field{sortinit}{M}
      \field{sortinithash}{cfd219b90152c06204fab207bc6c7cab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recommending products to consumers means not only understanding their tastes, but also understanding their level of experience. For example, it would be a mistake to recommend the iconic film Seven Samurai simply because a user enjoys other action movies; rather, we might conclude that they will eventually enjoy it -- once they are ready. The same is true for beers, wines, gourmet foods -- or any products where users have acquired tastes: the `best' products may not be the most `accessible'. Thus our goal in this paper is to recommend products that a user will enjoy now, while acknowledging that their tastes may have changed over time, and may change again in the future. We model how tastes change due to the very act of consuming more products -- in other words, as users become more experienced. We develop a latent factor recommendation system that explicitly accounts for each user's level of experience. We find that such a model not only leads to better recommendations, but also allows us to study the role of user experience and expertise on a novel dataset of fifteen million beer, wine, food, and movie reviews.}
      \field{booktitle}{WWW '13 Proceedings of the 22Nd International Conference on World Wide Web}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{title}{{From Amateurs to Connoisseurs: Modeling the Evolution of User Expertise through Online Reviews}}
      \field{year}{2013}
      \field{pages}{897\bibrangedash 908}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/2488388.2488466
      \endverb
      \verb{eprint}
      \verb 1303.4402
      \endverb
      \verb{file}
      \verb :C$\backslash$:/Users/felix/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McAuley, Leskovec - 2013 - From Amateurs to Connoisseurs Modeling the Evolution of User Expertise through Online Reviews.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1303.4402
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1303.4402
      \endverb
      \keyw{expertise,recommender systems,user modeling}
    \endentry
    \entry{McAuley2013}{inproceedings}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=24f98302ee924662159ce29687c18e4e}{%
           family={McAuley},
           familyi={M\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=900d107125ff0ca84698cb909e4f6c51}{%
           family={Leskovec},
           familyi={L\bibinitperiod},
           given={Jure},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Hong Kong, China}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{fullhash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{bibnamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authorbibnamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authornamehash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \strng{authorfullhash}{bbbd2d32814b9c62099e9b96f3c8e78c}
      \field{sortinit}{M}
      \field{sortinithash}{cfd219b90152c06204fab207bc6c7cab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wiz- ards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we ob- tain highly interpretable textual labels for latent rating dimensions, which helps us to ‘justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the informa- tion present in review text; this is especially true for new products and users, who may have too few ratings to model their latent fac- tors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.}
      \field{booktitle}{RecSys '13 Proceedings of the 7th ACM conference on Recommender systems}
      \field{isbn}{9781450324090}
      \field{title}{{Hidden Factors and Hidden Topics: Understanding Rating Dimensions with Review Text}}
      \field{year}{2013}
      \field{pages}{165\bibrangedash 172}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2507157.2507163
      \endverb
      \verb{file}
      \verb :C$\backslash$:/Users/felix/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mcauley, Leskovec - Unknown - Hidden Factors and Hidden Topics Understanding Rating Dimensions with Review Text.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://dx.doi.org/10.1145/2507157.2507163.
      \endverb
      \verb{url}
      \verb http://dx.doi.org/10.1145/2507157.2507163.
      \endverb
      \keyw{recommender systems,topic models}
    \endentry
    \entry{McAuley2015}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=24f98302ee924662159ce29687c18e4e}{%
           family={McAuley},
           familyi={M\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d3d8dd6d94d65c683e17bbbc8a84da47}{%
           family={Targett},
           familyi={T\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=4babe5a0322188f1800f7bf84fa9898e}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Qinfeng},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b53a0ea70213607fcdf8c0d7e4f957c8}{%
           family={Hengel},
           familyi={H\bibinitperiod},
           given={Anton},
           giveni={A\bibinitperiod},
           givenun=0,
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod},
           prefixun=0}}%
      }
      \strng{namehash}{a5c4f433396f437b34ee954748697db3}
      \strng{fullhash}{a5c4f433396f437b34ee954748697db3}
      \strng{bibnamehash}{a5c4f433396f437b34ee954748697db3}
      \strng{authorbibnamehash}{a5c4f433396f437b34ee954748697db3}
      \strng{authornamehash}{a5c4f433396f437b34ee954748697db3}
      \strng{authorfullhash}{a5c4f433396f437b34ee954748697db3}
      \field{sortinit}{M}
      \field{sortinithash}{cfd219b90152c06204fab207bc6c7cab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being complementary (such as a pair of jeans and a matching shirt). This information guides many of the choices that people make, from buying clothes to their interactions with each other. We seek here to model this human sense of the relationships between objects based on their appearance. Our approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within. We cast this as a network inference problem defined on graphs of related images, and provide a large-scale dataset for the training and evaluation of the same. The system we develop is capable of recommending which clothes and accessories will go well together (and which will not), amongst a host of other applications.}
      \field{eprinttype}{arXiv}
      \field{title}{{Image-based Recommendations on Styles and Substitutes}}
      \field{year}{2015}
      \field{pages}{1\bibrangedash 11}
      \range{pages}{11}
      \verb{eprint}
      \verb 1506.04757
      \endverb
      \verb{file}
      \verb :C$\backslash$:/Users/felix/OneDrive/Desktop/1506.04757.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1506.04757
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1506.04757
      \endverb
    \endentry
    \entry{Plank}{report}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=63bd895d4fbba2d503bc308d763e44d4}{%
           family={Plank},
           familyi={P\bibinitperiod},
           given={Barbara},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b874f93d29ad9151e52501b113f21077}{%
           family={S{ø}gaard},
           familyi={S\bibinitperiod},
           given={Anders},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=33b00f3e2f4f1bb310f1cf8d4a4c500a}{%
           family={Goldberg},
           familyi={G\bibinitperiod},
           given={Yoav},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ffcd48d9d479b2df55f8a166126f031d}
      \strng{fullhash}{ffcd48d9d479b2df55f8a166126f031d}
      \strng{bibnamehash}{ffcd48d9d479b2df55f8a166126f031d}
      \strng{authorbibnamehash}{ffcd48d9d479b2df55f8a166126f031d}
      \strng{authornamehash}{ffcd48d9d479b2df55f8a166126f031d}
      \strng{authorfullhash}{ffcd48d9d479b2df55f8a166126f031d}
      \field{sortinit}{P}
      \field{sortinithash}{8d51b3d5b78d75b54308d706b9bbe285}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Bidirectional long short-term memory (bi-LSTM) networks have recently proven successful for various NLP sequence mod-eling tasks, but little is known about their reliance to input representations, target languages, data set size, and label noise. We address these issues and evaluate bi-LSTMs with word, character, and unicode byte embeddings for POS tagging. We compare bi-LSTMs to traditional POS taggers across languages and data sizes. We also present a novel bi-LSTM model, which combines the POS tagging loss function with an auxiliary loss function that accounts for rare words. The model obtains state-of-the-art performance across 22 languages, and works especially well for morphologically complex languages. Our analysis suggests that bi-LSTMs are less sensitive to training data size and label corruptions (at small noise levels) than previously assumed.}
      \field{annotation}{Predicting POS-tags along with word frequencies}
      \field{eprinttype}{arXiv}
      \field{title}{{Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss}}
      \field{type}{techreport}
      \verb{eprint}
      \verb 1604.05529v3
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb https://github.com/clab/cnn
      \endverb
      \verb{url}
      \verb https://github.com/clab/cnn
      \endverb
    \endentry
    \entry{Pratt1993}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=940038165be71c04e157c5a41f5dc09b}{%
           family={Pratt},
           familyi={P\bibinitperiod},
           given={L\bibnamedelima Y},
           giveni={L\bibinitperiod\bibinitdelim Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{940038165be71c04e157c5a41f5dc09b}
      \strng{fullhash}{940038165be71c04e157c5a41f5dc09b}
      \strng{bibnamehash}{940038165be71c04e157c5a41f5dc09b}
      \strng{authorbibnamehash}{940038165be71c04e157c5a41f5dc09b}
      \strng{authornamehash}{940038165be71c04e157c5a41f5dc09b}
      \strng{authorfullhash}{940038165be71c04e157c5a41f5dc09b}
      \field{sortinit}{P}
      \field{sortinithash}{8d51b3d5b78d75b54308d706b9bbe285}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Previously, we have introduced the idea of neural network transfer, where learning on a target problem is sped up by using the weights obtained from a network trained for a related source task. Here, we present a new algorithm. called Discriminability-Based Transfer (DBT), which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly. Several experiments demonstrate that target networks initialized via DBT learn significantly faster than networks initialized randomly.}
      \field{journaltitle}{Advances in neural information processing systems}
      \field{title}{{Discriminability-Based Transfer between Neural Networks}}
      \field{year}{1993}
      \field{pages}{204\bibrangedash 211}
      \range{pages}{8}
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://papers.nips.cc/paper/641-discriminability-based-transfer-between-neural-networks.pdf
      \endverb
      \verb{url}
      \verb http://papers.nips.cc/paper/641-discriminability-based-transfer-between-neural-networks.pdf
      \endverb
    \endentry
    \entry{Ramsundar2015}{unpublished}{}
      \name{author}{6}{}{%
        {{uniquename=0,uniquepart=base,hash=6846cc99295752b57e920fdc36e377f2}{%
           family={Ramsundar},
           familyi={R\bibinitperiod},
           given={Bharath},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=6b69d0b1ec0a3e7eab2f9f716a2f1b52}{%
           family={Kearnes},
           familyi={K\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=875f84466ebe1e6693e13c1aff3f4f42}{%
           family={Riley},
           familyi={R\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=814593e049561ed80f4209a83b937bda}{%
           family={Webster},
           familyi={W\bibinitperiod},
           given={Dale},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=327b53d3391f639f85cf99daac339c6a}{%
           family={Konerding},
           familyi={K\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=8b199ddaf6c3a6930287f84fc29a82dd}{%
           family={Pande},
           familyi={P\bibinitperiod},
           given={Vijay},
           giveni={V\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{7ceed5b76a1fd26aaaf2620b7ee60ece}
      \strng{fullhash}{c2f5e5e022ac7f20d1298b841cad0993}
      \strng{bibnamehash}{c2f5e5e022ac7f20d1298b841cad0993}
      \strng{authorbibnamehash}{c2f5e5e022ac7f20d1298b841cad0993}
      \strng{authornamehash}{7ceed5b76a1fd26aaaf2620b7ee60ece}
      \strng{authorfullhash}{c2f5e5e022ac7f20d1298b841cad0993}
      \field{sortinit}{R}
      \field{sortinithash}{da6b42bd3ab22fee61abed031ee405f7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Massively multitask neural architectures provide a learning framework for drug discovery that synthesizes information from many distinct biological sources. To train these architectures at scale, we gather large amounts of data from public sources to create a dataset of nearly 40 million measurements across more than 200 biological targets. We investigate several aspects of the multitask framework by performing a series of empirical studies and obtain some interesting results: (1) massively multitask networks obtain predictive accuracies significantly better than single-task methods, (2) the predictive power of multitask networks improves as additional tasks and data are added, (3) the total amount of data and the total number of tasks both contribute significantly to multitask improvement, and (4) multitask networks afford limited transferability to tasks not in the training set. Our results underscore the need for greater data sharing and further algorithmic innovation to accelerate the drug discovery process.}
      \field{annotation}{more tasks -{>} better performance compared to single}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{title}{{Massively Multitask Networks for Drug Discovery}}
      \field{year}{2015}
      \verb{eprint}
      \verb 1502.02072
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1502.02072
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1502.02072
      \endverb
    \endentry
    \entry{Rei2017}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=bd651b0a99d219fbbcf0b23d89a85e2e}{%
           family={Rei},
           familyi={R\bibinitperiod},
           given={Marek},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \strng{fullhash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \strng{bibnamehash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \strng{authorbibnamehash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \strng{authornamehash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \strng{authorfullhash}{bd651b0a99d219fbbcf0b23d89a85e2e}
      \field{sortinit}{R}
      \field{sortinithash}{da6b42bd3ab22fee61abed031ee405f7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.}
      \field{annotation}{used multiple tasks and word prediction to improve performance. LSTM}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{title}{{Semi-supervised Multitask Learning for Sequence Labeling}}
      \field{year}{2017}
      \verb{eprint}
      \verb 1704.07156
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1704.07156
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1704.07156
      \endverb
    \endentry
    \entry{Ruder2017}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=b468248a20d75c52ee742f4592c2569f}{%
           family={Ruder},
           familyi={R\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{fullhash}{b468248a20d75c52ee742f4592c2569f}
      \strng{bibnamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authorbibnamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authornamehash}{b468248a20d75c52ee742f4592c2569f}
      \strng{authorfullhash}{b468248a20d75c52ee742f4592c2569f}
      \field{sortinit}{R}
      \field{sortinithash}{da6b42bd3ab22fee61abed031ee405f7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{title}{{An Overview of Multi-Task Learning in Deep Neural Networks}}
      \field{year}{2017}
      \verb{eprint}
      \verb 1706.05098
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.05098
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.05098
      \endverb
    \endentry
    \entry{Sang2003}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=78af0c309adbb2a1b1a0099e4e58e30a}{%
           family={Sang},
           familyi={S\bibinitperiod},
           given={Erik\bibnamedelimb F.\bibnamedelimi Tjong\bibnamedelima Kim},
           giveni={E\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim T\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d76edcbb6f4130ac14c37bf980191905}{%
           family={{De Meulder}},
           familyi={D\bibinitperiod},
           given={Fien},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \strng{fullhash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \strng{bibnamehash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \strng{authorbibnamehash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \strng{authornamehash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \strng{authorfullhash}{ad6b60b5c2cb86783ba02c559cfadcea}
      \field{sortinit}{S}
      \field{sortinithash}{322b1d5276f2f6c1bccdcd15920dbee6}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{title}{{Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition}}
      \field{year}{2003}
      \verb{eprint}
      \verb 0306050
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb http://lcg-www.uia.ac.be/conll2003/ner/ http://arxiv.org/abs/cs/0306050
      \endverb
      \verb{url}
      \verb http://lcg-www.uia.ac.be/conll2003/ner/%20http://arxiv.org/abs/cs/0306050
      \endverb
    \endentry
    \entry{Toutanova2007}{inproceedings}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=b92aa283415413bb8d2a1548716d0c7d}{%
           family={Toutanova},
           familyi={T\bibinitperiod},
           given={Kristina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9fb237891a1517d36109c68767dd6fae}{%
           family={Klein},
           familyi={K\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=1261894eaefc186bfeabf336e05e6294}{%
           family={Manning},
           familyi={M\bibinitperiod},
           given={Christopher\bibnamedelima D},
           giveni={C\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=300d4990e626d975e0c28630444f63c3}{%
           family={Singer},
           familyi={S\bibinitperiod},
           given={Yoram},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5782462bc6938878547f0c49c6bb7261}
      \strng{fullhash}{5782462bc6938878547f0c49c6bb7261}
      \strng{bibnamehash}{5782462bc6938878547f0c49c6bb7261}
      \strng{authorbibnamehash}{5782462bc6938878547f0c49c6bb7261}
      \strng{authornamehash}{5782462bc6938878547f0c49c6bb7261}
      \strng{authorfullhash}{5782462bc6938878547f0c49c6bb7261}
      \field{sortinit}{T}
      \field{sortinithash}{6f7aff9db9dcfeb7f95fd5bbd2f78df9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) ﬁne-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24{\%} accuracy on the Penn Treebank WSJ, an error reduction of 4.4{\%} on the best previous single automatically learned tagging result}
      \field{title}{{Feature-rich part-of-speech tagging with a cyclic dependency network}}
      \field{year}{2007}
      \field{pages}{173\bibrangedash 180}
      \range{pages}{8}
      \verb{doi}
      \verb 10.3115/1073445.1073478
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb https://nlp.stanford.edu/{~}manning/papers/tagging.pdf
      \endverb
      \verb{url}
      \verb https://nlp.stanford.edu/%7B~%7Dmanning/papers/tagging.pdf
      \endverb
    \endentry
    \entry{Wojatzki}{inproceedings}{}
      \name{author}{5}{}{%
        {{uniquename=0,uniquepart=base,hash=a2c8e311473de30e3f6cbaaf47b9cb95}{%
           family={Wojatzki},
           familyi={W\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=ef7ee212acdccc3d74d41d898bd4cb62}{%
           family={Ruppert},
           familyi={R\bibinitperiod},
           given={Eugen},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e579d61b899afa5979e9652af0fe1808}{%
           family={Holschneider},
           familyi={H\bibinitperiod},
           given={Sarah},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d2bddcda907ea93d3a82a0623d8d0930}{%
           family={Zesch},
           familyi={Z\bibinitperiod},
           given={Torsten},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=786eca9f4966307b17cae6c3bba98905}{%
           family={Biemann},
           familyi={B\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8bbd00d972f21c5d562f5781bf9c87b5}
      \strng{fullhash}{a634b0dddccd4d827259620c9a118e61}
      \strng{bibnamehash}{a634b0dddccd4d827259620c9a118e61}
      \strng{authorbibnamehash}{a634b0dddccd4d827259620c9a118e61}
      \strng{authornamehash}{8bbd00d972f21c5d562f5781bf9c87b5}
      \strng{authorfullhash}{a634b0dddccd4d827259620c9a118e61}
      \field{sortinit}{W}
      \field{sortinithash}{ecb89ff85896a47dc313960773ac311d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes the GermEval 2017 shared task on Aspect-Based Sentiment Analysis that consists of four subtasks: rel-evance, document-level sentiment polarity, aspect-level polarity ad opinion target ex-traction. System performance is measured on two evaluation sets – one from the same time period as the training and development set, and a second one, which contains data from a later time period. We describe the subtasks and the data in detail and provide the shared task results. Overall, the shared task attracted over 50 system runs from 8 teams.}
      \field{booktitle}{Proceedings of the GermEval 2017 – Shared Task on Aspect-based Sentiment in Social Media Customer Feedback}
      \field{title}{{GermEval 2017: Shared Task on Aspect-based Sentiment in Social Media Customer Feedback}}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 12}
      \range{pages}{12}
      \verb{file}
      \verb :C$\backslash$:/Users/felix/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wojatzki et al. - Unknown - GermEval 2017 Shared Task on Aspect-based Sentiment in Social Media Customer Feedback.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://www.ltl.uni-due.de/http://lt.informatik.uni-hamburg.de https://www.ltl.uni-due.de/wp-content/uploads/germeval-2017.pdf
      \endverb
      \verb{url}
      \verb http://www.ltl.uni-due.de/http://lt.informatik.uni-hamburg.de%20https://www.ltl.uni-due.de/wp-content/uploads/germeval-2017.pdf
      \endverb
    \endentry
    \entry{Zhang2017a}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=9a4f4a1ff661cd600eb26523a5ba8bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=55242d2a60270145342841e4d4238da0}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \strng{fullhash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \strng{bibnamehash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \strng{authorbibnamehash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \strng{authornamehash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \strng{authorfullhash}{6cd6b62eb7a185a0d85f22af0ef449f2}
      \field{sortinit}{Z}
      \field{sortinithash}{156173bd08b075d7295bc3e0f4735a04}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL. First, we classify different MTL algorithms into several categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach, and decomposition approach, and then discuss the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, batch MTL models are difficult to handle this situation and online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing are reviewed to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works. Finally, we present theoretical analyses and discuss several future directions for MTL.}
      \field{eprinttype}{arXiv}
      \field{title}{{A Survey on Multi-Task Learning}}
      \field{year}{2017}
      \verb{eprint}
      \verb 1707.08114
      \endverb
      \verb{file}
      \verb ::
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1707.08114.pdf http://arxiv.org/abs/1707.08114
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1707.08114.pdf%20http://arxiv.org/abs/1707.08114
      \endverb
      \keyw{Artificial Intelligence !,Index Terms-Multi-Task Learning,Machine Learning}
    \endentry
  \enddatalist
\endrefsection
\endinput

